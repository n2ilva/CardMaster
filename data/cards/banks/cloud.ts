import type { SeedCard } from "../generator";

type UserLevel = "Fácil" | "Médio" | "Difícil";

// ─── Cloud · 12 categorias × 3 níveis × 7 questões (rodada 4/30) ───

export const cloudBank: Record<string, Record<UserLevel, SeedCard[]>> = {
  // ── Arquitetura em Nuvem ──
  "Arquitetura em Nuvem": {
    Fácil: [
      {
        q: "Qual modelo de serviço em nuvem fornece infraestrutura virtualizada (servidores, rede e armazenamento) sob demanda?",
        o: ["IaaS", "PaaS", "SaaS", "FaaS"],
        c: 0,
        e: "IaaS (Infrastructure as a Service) entrega recursos de infraestrutura virtualizados pela internet. O provedor gerencia o hardware físico enquanto o cliente controla sistemas operacionais, armazenamento e aplicações.",
        x: "Ao usar Amazon EC2, você aluga máquinas virtuais (IaaS) e instala o SO e aplicações desejadas, sem comprar servidores físicos.",
      },
      {
        q: "Qual modelo de implantação em nuvem combina recursos de nuvem pública e infraestrutura on-premises?",
        o: ["Nuvem híbrida", "Nuvem pública", "Nuvem privada", "Multi-cloud"],
        c: 0,
        e: "A nuvem híbrida integra nuvem pública (AWS, Azure, GCP) com infraestrutura on-premises ou nuvem privada, permitindo que dados e aplicações transitem entre ambientes conforme necessidades de custo, conformidade ou desempenho.",
        x: "Uma empresa mantém dados sensíveis no datacenter local (on-premises) e usa AWS para workloads de alta demanda sazonal (Black Friday), conectando os ambientes via VPN ou Direct Connect.",
      },
      {
        q: "Qual é a principal diferença entre escalabilidade vertical e horizontal na nuvem?",
        o: [
          "Vertical aumenta recursos de uma máquina; horizontal adiciona mais máquinas",
          "Vertical adiciona máquinas; horizontal aumenta CPU",
          "Ambas são idênticas",
          "Vertical é automática; horizontal é manual",
        ],
        c: 0,
        e: "Escalabilidade vertical (scale up/down) significa aumentar CPU, RAM ou disco de uma única instância. Escalabilidade horizontal (scale out/in) significa adicionar ou remover instâncias. Horizontal é preferida na nuvem por não ter limite de hardware e permitir alta disponibilidade.",
        x: "Vertical: trocar t3.micro (1 vCPU, 1GB RAM) por t3.xlarge (4 vCPU, 16GB). Horizontal: manter t3.micro mas rodar 10 instâncias atrás de um load balancer.",
      },
      {
        q: "O que é uma região (region) em um provedor de nuvem?",
        o: [
          "Localização geográfica composta por múltiplas zonas de disponibilidade",
          "Tipo de máquina virtual",
          "Nível de suporte ao cliente",
          "Plano de pagamento",
        ],
        c: 0,
        e: "Uma região é uma localização geográfica (ex: us-east-1, Brazil South) composta por múltiplas Availability Zones (AZs) — datacenters fisicamente separados. Escolher a região mais próxima dos usuários reduz latência. Dados não são replicados entre regiões automaticamente.",
        x: "AWS tem 30+ regiões globais. Brazil South (São Paulo) tem 3 AZs. Se sua app atende só o Brasil, use essa região para menor latência (~10ms vs ~150ms de us-east-1).",
      },
      {
        q: "O que é multi-cloud e qual sua vantagem sobre usar um único provedor?",
        o: [
          "Usar serviços de múltiplos provedores de nuvem para evitar vendor lock-in e aumentar resiliência",
          "Usar várias regiões do mesmo provedor",
          "Ter múltiplas contas no mesmo provedor",
          "Usar nuvem privada e pública do mesmo fornecedor",
        ],
        c: 0,
        e: "Multi-cloud usa dois ou mais provedores (AWS + Azure, GCP + AWS). Vantagens: evitar dependência de um fornecedor (vendor lock-in), usar o melhor serviço de cada provedor, e aumentar resiliência contra falhas de um provedor inteiro.",
        x: "Empresa usa AWS para compute (EC2/Lambda), GCP BigQuery para analytics e Azure AD para identidade. Se AWS tiver outage, analytics e auth continuam funcionando.",
      },
      {
        q: "O que é PaaS (Platform as a Service) e como difere de IaaS?",
        o: [
          "PaaS fornece plataforma gerenciada para deploy de apps sem gerenciar infraestrutura; IaaS exige gerenciar SO e middleware",
          "PaaS é mais barato que IaaS em todos os casos",
          "PaaS e IaaS são sinônimos",
          "PaaS requer servidores físicos próprios",
        ],
        c: 0,
        e: "PaaS abstrai infraestrutura: você faz deploy do código e a plataforma gerencia SO, runtime, patches e escalabilidade. IaaS entrega VMs/rede onde você controla tudo acima do hypervisor.",
        x: "PaaS: Heroku, AWS Elastic Beanstalk, Azure App Service — deploy com git push. IaaS: EC2, Azure VM — precisa instalar SO, configurar nginx, manter patches.",
      },
      {
        q: "O que é uma Availability Zone (AZ) em provedores de nuvem?",
        o: [
          "Datacenter ou grupo de datacenters isolados dentro de uma região",
          "Zona horária do servidor",
          "Região geográfica do provedor",
          "Nível de SLA contratado",
        ],
        c: 0,
        e: "Uma AZ é um ou mais datacenters com energia, rede e refrigeração independentes dentro de uma região. Distribuir recursos em múltiplas AZs aumenta disponibilidade: se uma AZ falhar, as outras continuam operando.",
        x: "us-east-1 tem 6 AZs (us-east-1a a 1f). App em 3 AZs: se uma falhar (incêndio, enchente), 2/3 do capacity continua. RDS Multi-AZ: failover automático em ~60s para AZ secundária.",
      },
    ],
    Médio: [
      {
        q: "Em uma arquitetura multi-region na nuvem, qual é a principal vantagem de replicar dados entre regiões geográficas distintas?",
        o: [
          "Reduzir latência e aumentar disponibilidade",
          "Diminuir custos de armazenamento",
          "Eliminar a necessidade de backups",
          "Aumentar a velocidade de CPU das instâncias",
        ],
        c: 0,
        e: "Replicação multi-region diminui a latência para usuários em diferentes locais geográficos e aumenta a disponibilidade, pois se uma região inteira falhar, outra pode assumir o tráfego.",
        x: "Um e-commerce global replica seu banco no us-east-1 e eu-west-1. Usuários europeus acessam a réplica local com ~20ms em vez de ~120ms do servidor americano.",
      },
      {
        q: "O que é um SLA (Service Level Agreement) de 99,99% de disponibilidade e quanto tempo de indisponibilidade ele permite por ano?",
        o: [
          "Aproximadamente 52 minutos por ano",
          "Aproximadamente 8,7 horas por ano",
          "Zero minutos por ano",
          "Aproximadamente 3,6 dias por ano",
        ],
        c: 0,
        e: "99,99% (quatro noves) permite 0,01% de downtime: 365,25 × 24 × 60 × 0,0001 ≈ 52,6 minutos/ano. Para comparação: 99,9% (três noves) ≈ 8,76 horas/ano e 99,999% (cinco noves) ≈ 5,26 minutos/ano.",
        x: "AWS garante SLA de 99,99% para EC2 multi-AZ. Se o downtime ultrapassar 52 min/ano, o cliente pode solicitar créditos de serviço.",
      },
      {
        q: "Qual é a função de um API Gateway em uma arquitetura de microsserviços na nuvem?",
        o: [
          "Ponto único de entrada que roteia, autentica e controla tráfego para microsserviços",
          "Armazenar dados dos microsserviços",
          "Compilar o código de todos os serviços",
          "Substituir o load balancer",
        ],
        c: 0,
        e: "O API Gateway atua como ponto de entrada único (single entry point) para todos os microsserviços, centralizando responsabilidades como autenticação, rate limiting, roteamento, transformação de requisições e observabilidade.",
        x: "Amazon API Gateway recebe GET /produtos e roteia para o microsserviço de catálogo; POST /pedidos vai para o microsserviço de pedidos. Ambos passam pela mesma autenticação JWT no gateway.",
      },
      {
        q: "O que é auto-scaling na nuvem e como ele funciona?",
        o: [
          "Ajuste automático da quantidade de recursos baseado na demanda atual",
          "Escalar manualmente adicionando servidores",
          "Atualizar software automaticamente",
          "Backup automático de dados",
        ],
        c: 0,
        e: "Auto-scaling monitora métricas (CPU, requisições, fila) e ajusta automaticamente o número de instâncias. Scale out: adiciona instâncias quando demanda sobe. Scale in: remove quando demanda cai. Garante desempenho nos picos e economia nos vales.",
        x: "AWS Auto Scaling Group: min=2, max=20, target CPU=70%. Dia normal: 3 instâncias. Black Friday: escala para 18. Madrugada: volta para 2. Sem intervenção manual.",
      },
      {
        q: "O que é um load balancer e qual seu papel em arquiteturas de nuvem?",
        o: [
          "Distribui tráfego entre múltiplas instâncias para equilibrar carga e garantir disponibilidade",
          "Armazena cache de dados",
          "Criptografa dados em trânsito",
          "Gerencia DNS",
        ],
        c: 0,
        e: "Load balancer distribui requisições entre múltiplos servidores/instâncias. Se uma instância falhar, o LB redireciona o tráfego para as saudáveis (health checks). Tipos: L4 (TCP/UDP) e L7 (HTTP - pode rotear por URL, header).",
        x: "AWS ALB (Application Load Balancer): distribui requests HTTP entre 5 instâncias EC2. Health check: GET /health a cada 30s. Se instância não responder 3 vezes, é removida do pool.",
      },
      {
        q: "O que é um CDN (Content Delivery Network) e qual seu papel na nuvem?",
        o: [
          "Rede de servidores distribuídos que entrega conteúdo a partir do ponto mais próximo do usuário",
          "Rede privada entre datacenters",
          "Serviço de DNS avançado",
          "Tipo de banco de dados distribuído",
        ],
        c: 0,
        e: "CDN cacheia conteúdo (imagens, vídeos, JS/CSS, APIs) em edge locations ao redor do mundo. Reduz latência, descarrega o origin server e protege contra DDoS. Exemplos: CloudFront (AWS), Cloud CDN (GCP), Azure CDN.",
        x: "Sem CDN: usuário no Japão baixa imagem de servidor em SP (~250ms). Com CloudFront: edge location em Tokyo serve a imagem cacheada (~15ms). Cache hit ratio de 95% = origin recebe só 5% das requests.",
      },
      {
        q: "O que é um Service Mesh e quando é usado em arquiteturas cloud?",
        o: [
          "Camada de infraestrutura para gerenciar comunicação entre microsserviços com observabilidade e segurança",
          "Tipo de rede física entre servidores",
          "Serviço de deploy automático",
          "Framework de frontend",
        ],
        c: 0,
        e: "Service mesh (Istio, Linkerd, AWS App Mesh) adiciona sidecar proxies a cada microsserviço para gerenciar tráfego: mTLS automático, circuit breakers, retries, observabilidade (métricas, traces). Sem alterar código da aplicação.",
        x: "Istio injeta sidecar Envoy em cada pod Kubernetes. Tráfego entre microsserviços passa pelo Envoy que aplica: mTLS (criptografia), retry (3x), timeout (5s), canary routing (10% para v2).",
      },
    ],
    Difícil: [
      {
        q: "No padrão de resiliência 'bulkhead', qual é o objetivo principal ao isolar componentes de um sistema distribuído em nuvem?",
        o: [
          "Evitar que a falha de um componente se propague para os demais",
          "Aumentar o throughput total do sistema",
          "Reduzir o custo de infraestrutura",
          "Simplificar o deploy contínuo",
        ],
        c: 0,
        e: "O padrão Bulkhead (antepara) isola recursos — como pools de threads ou conexões — de modo que a falha ou sobrecarga em um serviço não esgote os recursos usados por outros serviços, limitando o raio de impacto.",
        x: "Em um microsserviço de pagamentos, você cria um pool de 20 threads exclusivo; se ele travar, o pool de 30 threads do serviço de catálogo continua operando normalmente.",
      },
      {
        q: "O que é o padrão Circuit Breaker em sistemas distribuídos na nuvem e quando ele é ativado?",
        o: [
          "Interrompe chamadas a um serviço instável após falhas consecutivas, evitando cascata de erros",
          "Desliga fisicamente servidores defeituosos",
          "Balanceia carga entre serviços",
          "Criptografa comunicação entre microsserviços",
        ],
        c: 0,
        e: "O Circuit Breaker monitora falhas em chamadas a um serviço. Após um limiar de falhas (ex.: 5 erros em 10s), o circuito 'abre' e bloqueia novas chamadas por um período, retornando fallback imediato. Após o timeout, tenta uma chamada de teste (half-open) para verificar se o serviço se recuperou.",
        x: "Estados: Closed (normal) → Open (bloqueando, após 5 falhas) → Half-Open (testa 1 requisição). Se o teste passar, volta a Closed. Bibliotecas: Resilience4j (Java), Polly (.NET), opossum (Node.js).",
      },
      {
        q: "Qual é a diferença entre RTO (Recovery Time Objective) e RPO (Recovery Point Objective) em um plano de disaster recovery na nuvem?",
        o: [
          "RTO é o tempo máximo aceitável para restaurar o serviço; RPO é a perda máxima de dados aceitável",
          "São sinônimos para tempo de backup",
          "RTO trata de dados e RPO de serviços",
          "RTO é automático e RPO é manual",
        ],
        c: 0,
        e: "RTO (Recovery Time Objective): quanto tempo o sistema pode ficar fora do ar. RPO (Recovery Point Objective): quanto tempo de dados pode ser perdido (ex: últimos 15 min). Estratégias: Backup & Restore (RTO alto, barato), Pilot Light, Warm Standby, Multi-site Active-Active (RTO baixo, caro).",
        x: "E-commerce: RTO = 1h, RPO = 15min. Banco financeiro: RTO = 5min, RPO = 0. Quanto menor RTO/RPO, mais caro — multi-site active-active custa ~3x mais que backup & restore.",
      },
      {
        q: "O que é o padrão Saga em microsserviços distribuídos na nuvem?",
        o: [
          "Padrão para gerenciar transações distribuídas usando sequência de transações locais com compensações",
          "Tipo de banco de dados distribuído",
          "Protocolo de caching",
          "Framework de testes",
        ],
        c: 0,
        e: "O padrão Saga divide uma transação distribuída em transações locais em cada microsserviço. Se uma etapa falhar, ações compensatórias desfazem as anteriores. Tipos: Coreografia (eventos) e Orquestração (coordenador central, ex: Step Functions).",
        x: "Saga de pedido: 1) Reservar estoque → 2) Cobrar pagamento → 3) Enviar. Se pagamento falha, compensação desfaz reserva do estoque. Orquestração: Step Functions controla a sequência.",
      },
      {
        q: "O que é o CAP Theorem e como ele afeta decisões de arquitetura em nuvem?",
        o: [
          "Um sistema distribuído pode garantir no máximo 2 de 3: Consistência, Disponibilidade e Tolerância a Partição",
          "Framework de segurança com 3 pilares",
          "Método de escalabilidade",
          "Protocolo de rede",
        ],
        c: 0,
        e: "CAP Theorem (Brewer): em caso de partição de rede (P), você deve escolher entre Consistência (C — todos os nós veem o mesmo dado) e Disponibilidade (A — toda requisição recebe resposta). CP: DynamoDB strong consistency. AP: Cassandra eventual consistency.",
        x: "DynamoDB strongly consistent read: sempre dados atualizados (CP), mas pode dar erro se nó indisponível. Eventually consistent read: sempre responde (AP), mas pode retornar dado desatualizado por ~1s.",
      },
      {
        q: "O que é o padrão CQRS (Command Query Responsibility Segregation) em arquiteturas cloud?",
        o: [
          "Separar modelos de leitura e escrita para otimizar cada um independentemente",
          "Protocolo de cache distribuído",
          "Tipo de banco de dados relacional",
          "Padrão de autenticação em microsserviços",
        ],
        c: 0,
        e: "CQRS separa operações de Command (escrita/mutação) e Query (leitura). O modelo de escrita pode usar banco normalizado (PostgreSQL), enquanto leitura usa modelo desnormalizado (ElasticSearch, DynamoDB). Sincronização via eventos.",
        x: "E-commerce: POST /pedidos grava em PostgreSQL (transacional). GET /produtos/busca lê do ElasticSearch (rápido, full-text). Evento 'ProdutoAtualizado' sincroniza PostgreSQL → ElasticSearch via SQS/SNS.",
      },
      {
        q: "O que é o padrão Strangler Fig para migração de sistemas para nuvem?",
        o: [
          "Migrar gradualmente funcionalidades do sistema legado para novos microsserviços, até substituí-lo completamente",
          "Desligar o sistema legado antes de migrar",
          "Manter dois sistemas idênticos rodando indefinidamente",
          "Reescrever todo o sistema simultaneamente",
        ],
        c: 0,
        e: "Strangler Fig: roteia tráfego seletivamente do monolito para novos serviços. Com o tempo, cada funcionalidade é migrada até que o monolito seja desligado. Usa API gateway ou proxy como router. Minimiza risco vs big-bang rewrite.",
        x: "Monolito: /users, /orders, /payments. Fase 1: criar microsserviço de payments, proxy roteia /payments para ele. Fase 2: /orders migrado. Fase 3: /users migrado → monolito desligado.",
      },
    ],
  },

  // ── AWS — Fundamentos ──
  "AWS — Fundamentos": {
    Fácil: [
      {
        q: "Qual serviço da AWS é utilizado para armazenar objetos (arquivos) de forma durável e escalável?",
        o: ["Amazon S3", "Amazon EC2", "Amazon RDS", "Amazon VPC"],
        c: 0,
        e: "O Amazon S3 (Simple Storage Service) é um serviço de armazenamento de objetos com durabilidade de 99,999999999% (11 noves). Ele armazena qualquer tipo de arquivo como objetos em buckets.",
        x: "Você cria um bucket chamado 'meu-app-imagens' e faz upload de fotos via SDK: s3.putObject({ Bucket: 'meu-app-imagens', Key: 'foto.jpg', Body: fileBuffer }).",
      },
      {
        q: "Qual serviço da AWS gerencia bancos de dados relacionais, cuidando de backups, patches e alta disponibilidade automaticamente?",
        o: ["Amazon RDS", "Amazon DynamoDB", "Amazon S3", "Amazon ElastiCache"],
        c: 0,
        e: "O Amazon RDS (Relational Database Service) é um serviço gerenciado que suporta MySQL, PostgreSQL, MariaDB, Oracle e SQL Server. A AWS cuida de backups automáticos, patching, failover Multi-AZ e read replicas.",
        x: "aws rds create-db-instance --db-instance-identifier meu-banco --engine postgres --db-instance-class db.t3.micro --master-username admin --master-user-password senhaForte123 — cria um PostgreSQL gerenciado.",
      },
      {
        q: "Qual é a função do Amazon VPC (Virtual Private Cloud)?",
        o: [
          "Criar uma rede virtual isolada na AWS para lançar recursos",
          "Armazenar arquivos estáticos",
          "Gerenciar containers Docker",
          "Monitorar custos da conta AWS",
        ],
        c: 0,
        e: "O Amazon VPC permite criar uma rede virtual logicamente isolada na nuvem AWS, com controle total sobre faixas de IP, sub-redes, route tables, internet gateways e security groups.",
        x: "Crie VPC com CIDR 10.0.0.0/16, sub-rede pública 10.0.1.0/24 (com internet gateway) para web servers e sub-rede privada 10.0.2.0/24 (sem IG) para banco de dados.",
      },
      {
        q: "Qual serviço AWS permite enviar notificações push, e-mails e SMS a partir de um tópico centralizado?",
        o: ["Amazon SNS", "Amazon SQS", "Amazon SES", "Amazon Pinpoint"],
        c: 0,
        e: "O Amazon SNS (Simple Notification Service) é um serviço pub/sub gerenciado. Um tópico pode ter milhares de assinantes (Lambda, SQS, e-mail, SMS, HTTP). Quando uma mensagem é publicada no tópico, todos os assinantes a recebem simultaneamente.",
        x: "aws sns publish --topic-arn arn:aws:sns:us-east-1:123:alertas --message 'Servidor fora do ar!' — envia para todos os assinantes: e-mail do CTO + SMS do SRE + Lambda de auto-healing.",
      },
      {
        q: "O que é o Amazon CloudWatch e para que serve?",
        o: [
          "Serviço de monitoramento que coleta métricas, logs e alarmes para recursos AWS",
          "Serviço de deploy automático",
          "Banco de dados em memória",
          "Ferramenta de versionamento de código",
        ],
        c: 0,
        e: "CloudWatch coleta e visualiza métricas (CPU, rede, custom metrics), armazena logs (CloudWatch Logs), cria alarmes (ex: CPU > 80% → notificar) e dashboards. É o serviço central de monitoramento da AWS.",
        x: "aws cloudwatch put-metric-alarm --alarm-name CPUAlta --metric-name CPUUtilization --threshold 80 --comparison-operator GreaterThanThreshold — cria alarme que dispara quando CPU > 80%.",
      },
      {
        q: "O que é o Amazon EC2 (Elastic Compute Cloud)?",
        o: [
          "Serviço que fornece servidores virtuais (instâncias) com capacidade computacional redimensionável",
          "Serviço de armazenamento de arquivos",
          "Banco de dados gerenciado",
          "Ferramenta de deploy de containers",
        ],
        c: 0,
        e: "EC2 permite lançar máquinas virtuais (instâncias) em minutos, escolhendo SO, tipo de CPU/RAM, armazenamento EBS e rede. Você paga por hora ou segundo de uso. É o serviço de computação mais fundamental da AWS.",
        x: "Lançar instância: aws ec2 run-instances --image-id ami-abc123 --instance-type t3.micro --key-name minha-chave. Modelos de preço: On-Demand, Reserved, Spot (até 90% desconto).",
      },
      {
        q: "O que é o AWS IAM (Identity and Access Management)?",
        o: [
          "Serviço gratuito para gerenciar usuários, grupos, roles e permissões de acesso aos recursos AWS",
          "Serviço de banco de dados de identidades",
          "Ferramenta de monitoramento de segurança",
          "VPN gerenciada pela AWS",
        ],
        c: 0,
        e: "IAM controla QUEM pode fazer O QUÊ nos recursos AWS. Componentes: Users (pessoas), Groups (conjuntos de users), Roles (assumidas por serviços), Policies (JSON definindo permissões). Princípio do menor privilégio: dar apenas o necessário.",
        x: "Policy: { Effect: 'Allow', Action: 's3:GetObject', Resource: 'arn:aws:s3:::meu-bucket/*' } → permite apenas leitura de objetos em um bucket específico. MFA obrigatório para conta root.",
      },
    ],
    Médio: [
      {
        q: "Qual tipo de instância EC2 é mais adequado para cargas de trabalho que exigem alto desempenho de CPU, como modelagem científica?",
        o: [
          "Compute Optimized (C)",
          "Memory Optimized (R)",
          "Storage Optimized (I)",
          "General Purpose (T)",
        ],
        c: 0,
        e: "Instâncias Compute Optimized (família C, como c5.xlarge) possuem processadores de alta frequência e são ideais para workloads CPU-intensive como computação científica, modelagem financeira e encoding de vídeo.",
        x: "Para rodar simulações de Monte Carlo, você escolhe c5.4xlarge com 16 vCPUs de alta frequência, em vez de t3.xlarge que tem CPU com burst limitado.",
      },
      {
        q: "No Amazon S3, qual classe de armazenamento é mais econômica para dados acessados raramente, mas que precisam estar disponíveis em milissegundos?",
        o: [
          "S3 Standard-IA",
          "S3 Glacier",
          "S3 Standard",
          "S3 Glacier Deep Archive",
        ],
        c: 0,
        e: "S3 Standard-IA (Infrequent Access) tem custo de armazenamento menor que Standard, mas cobra por acesso. Dados ficam disponíveis instantaneamente (milissegundos). Glacier leva minutos a horas para recuperar e é para arquivamento de longo prazo.",
        x: "Logs de auditoria acessados 1-2x/mês: Standard-IA (0.0125 USD/GB). Dados acessados diariamente: Standard (0.023 USD/GB). Backups antigos: Glacier (~0.004 USD/GB).",
      },
      {
        q: "Qual é a diferença entre Security Group e Network ACL na AWS?",
        o: [
          "SG é stateful e opera por instância; NACL é stateless e opera por sub-rede",
          "São idênticos",
          "NACL é stateful e SG stateless",
          "SG opera na sub-rede e NACL na instância",
        ],
        c: 0,
        e: "Security Group: stateful (resposta automática), opera na instância, permite apenas regras Allow. Network ACL: stateless (regras de entrada e saída independentes), opera na sub-rede, permite regras Allow e Deny com numeração de prioridade.",
        x: "SG: 'permitir TCP 443 de 0.0.0.0/0' — a resposta de saída é automática. NACL: precisa de regra de entrada E saída separadas. NACL é a primeira linha de defesa (sub-rede), SG é a segunda (instância).",
      },
      {
        q: "O que são Reserved Instances e Savings Plans na AWS e quando usá-los?",
        o: [
          "Compromissos de 1 ou 3 anos com desconto de até 72% em instâncias EC2",
          "Instâncias gratuitas para testes",
          "Instâncias com prioridade de rede",
          "Planos de suporte técnico",
        ],
        c: 0,
        e: "Reserved Instances (RI) e Savings Plans oferecem descontos de até 72% vs On-Demand em troca de compromisso de 1 ou 3 anos. RI: tipo/região fixos. Savings Plans: mais flexíveis (qualquer tipo/região). Ideal para workloads previsíveis e estáveis.",
        x: "EC2 On-Demand: $0.046/h. RI 1 ano all-upfront: $0.028/h (39% desconto). Savings Plan 3 anos: $0.019/h (59% desconto). Para servidor de banco 24/7, RI economiza ~$158/ano por instância.",
      },
      {
        q: "O que é o Amazon Route 53 e quais funcionalidades oferece?",
        o: [
          "Serviço DNS gerenciado com health checks, roteamento geográfico e failover",
          "Proxy reverso para EC2",
          "CDN da AWS",
          "Firewall de rede",
        ],
        c: 0,
        e: "Route 53 é o serviço de DNS escalável da AWS. Oferece: registro de domínios, resolução DNS com SLA 100%, health checks, e políticas de roteamento (simple, weighted, latency-based, geolocation, failover).",
        x: "Route 53 com failover: health check monitora servidor primário. Se falhar, DNS automaticamente resolve para servidor secundário em outra região. Latency-based: resolve para a região com menor latência para o usuário.",
      },
      {
        q: "O que é o Amazon DynamoDB e quando usá-lo em vez de RDS?",
        o: [
          "Banco NoSQL serverless de chave-valor/documento; ideal para alta escala com latência consistente de milissegundos",
          "Banco relacional gerenciado",
          "Armazenamento de arquivos",
          "Serviço de filas de mensagens",
        ],
        c: 0,
        e: "DynamoDB é NoSQL serverless com latência de um dígito de milissegundo em qualquer escala. Usar quando: esquema flexível, alta throughput, acesso por chave primária. RDS: queries complexas (JOINs), transações ACID, esquema relacional.",
        x: "DynamoDB: sessões de usuário, carrinho de compras, IoT events (milhões de writes/s). RDS: relatórios financeiros com JOINs complexos. DynamoDB DAX: cache in-memory para leituras em microssegundos.",
      },
      {
        q: "O que são Spot Instances na AWS e qual o risco?",
        o: [
          "Instâncias EC2 com até 90% de desconto, mas podem ser interrompidas pela AWS com aviso de 2 minutos",
          "Instâncias gratuitas para testing",
          "Instâncias com garantia de disponibilidade 100%",
          "Instâncias reservadas por 3 anos",
        ],
        c: 0,
        e: "Spot Instances usam capacidade ociosa da AWS com desconto de até 90%. A AWS pode reclamar a instância com 2 min de aviso quando precisar da capacidade. Ideal para workloads tolerantes a interrupção: batch processing, CI/CD, ML training.",
        x: "On-Demand c5.xlarge: $0.17/h. Spot: ~$0.05/h (70% desconto). Estratégia: misturar On-Demand + Spot em ASG. Spot Fleet diversifica entre tipos (c5, m5, r5) e AZs para reduzir interrupções.",
      },
    ],
    Difícil: [
      {
        q: "Em uma política IAM da AWS, qual elemento define explicitamente as ações que são negadas, tendo prioridade sobre qualquer Allow?",
        o: [
          "Explicit Deny no campo Effect",
          "Principal",
          "Resource com wildcard",
          "Condition com IpAddress",
        ],
        c: 0,
        e: "Na avaliação de políticas IAM, um Deny explícito sempre prevalece sobre qualquer Allow. Se qualquer política anexada ao principal contiver Effect: Deny para uma ação, ela será negada independentemente de outras políticas permissivas.",
        x: '{ "Effect": "Deny", "Action": "s3:DeleteBucket", "Resource": "*" } impede exclusão de qualquer bucket, mesmo que outra política conceda s3:* Allow.',
      },
      {
        q: "Na AWS, o que é o AWS Organizations e como SCPs (Service Control Policies) diferem de IAM Policies?",
        o: [
          "SCPs definem limites máximos de permissão para contas inteiras; IAM Policies concedem permissões dentro desses limites",
          "São a mesma coisa",
          "IAM é para organizações e SCP para usuários",
          "SCPs substituem completamente IAM",
        ],
        c: 0,
        e: "AWS Organizations gerencia múltiplas contas AWS. SCPs são guardrails que definem o TETO de permissões para contas/OUs — não concedem acesso, apenas limitam. IAM Policies DENTRO da conta concedem permissões efetivas, que não podem exceder o que a SCP permite.",
        x: "SCP na OU 'Produção': Deny ec2:TerminateInstances. Mesmo que um admin IAM na conta tenha ec2:*, ele NÃO consegue terminar instâncias — a SCP é o teto.",
      },
      {
        q: "O que é o AWS Well-Architected Framework e quais são seus pilares?",
        o: [
          "Framework com 6 pilares: Excelência Operacional, Segurança, Confiabilidade, Eficiência de Performance, Otimização de Custos e Sustentabilidade",
          "Ferramenta de deploy automático com 3 pilares",
          "Serviço de monitoramento com 4 pilares",
          "Framework de migração com 5 pilares",
        ],
        c: 0,
        e: "O Well-Architected Framework é um conjunto de boas práticas organizado em 6 pilares para projetar e operar workloads confiáveis, seguros, eficientes e econômicos na nuvem. A Sustentabilidade foi adicionada como 6º pilar em 2021.",
        x: "Use o AWS Well-Architected Tool para executar reviews contra os 6 pilares e receber recomendações. Exemplo: pilar de Confiabilidade recomenda multi-AZ para bancos de dados críticos.",
      },
      {
        q: "O que é o AWS CloudTrail e por que é essencial para segurança e auditoria?",
        o: [
          "Serviço que registra todas as chamadas de API feitas na conta AWS para auditoria",
          "Ferramenta de monitoramento de métricas",
          "CDN para distribuição de logs",
          "Serviço de backup automático",
        ],
        c: 0,
        e: "CloudTrail registra toda chamada de API na conta AWS: quem fez, quando, de onde, o quê. Essencial para auditoria, investigação de incidentes e compliance. Eventos são armazenados por padrão 90 dias (console) ou indefinidamente em S3.",
        x: "CloudTrail registrou: 'IAM user 'dev-joao' chamou ec2:TerminateInstances às 03:47 do IP 198.51.100.5 para instância i-abc123'. Investigação: credencial comprometida, 2FA não estava ativo.",
      },
      {
        q: "Qual é a diferença entre o AWS Config e o AWS CloudTrail?",
        o: [
          "CloudTrail registra AÇÕES (quem fez o quê); Config registra ESTADO dos recursos ao longo do tempo",
          "São o mesmo serviço",
          "CloudTrail é para estado e Config para ações",
          "Config substitui CloudTrail",
        ],
        c: 0,
        e: "CloudTrail: log de API calls (ações). AWS Config: snapshot contínuo do estado e configuração dos recursos. Config Rules avaliam se recursos estão em compliance (ex: 'todo bucket deve ter encryption'). Juntos: CloudTrail mostra quem mudou, Config mostra o antes e depois.",
        x: "Security group aberto para 0.0.0.0/0:22. Config rule detecta non-compliance. CloudTrail mostra: user 'junior-dev' executou authorize-security-group-ingress às 14:20. Remediação automática: Config auto-remediation reverte.",
      },
      {
        q: "O que é o AWS Control Tower e como gerencia ambientes multi-account?",
        o: [
          "Serviço que configura e governa um ambiente multi-account seguro com guardrails automatizados",
          "Painel de custos da AWS",
          "Serviço de migração de dados",
          "Ferramenta de debug de aplicações",
        ],
        c: 0,
        e: "Control Tower automatiza a criação de um landing zone com Organizations, SSO, CloudTrail centralizado e guardrails (SCPs + Config Rules). Guardrails: preventivos (SCP bloqueiam ações) e detectivos (Config Rules alertam violações).",
        x: "Control Tower cria: Log Archive account (logs centralizados), Audit account (segurança), sandbox OU. Guardrail: 'Disallow changes to CloudTrail' — nenhuma conta pode desativar auditoria.",
      },
      {
        q: "O que é o AWS Cost Explorer e como ajuda na otimização de custos?",
        o: [
          "Ferramenta de visualização e análise de custos com recomendações de otimização",
          "Serviço de deploy automático",
          "Ferramenta de monitoramento de performance",
          "Serviço de backup gerenciado",
        ],
        c: 0,
        e: "Cost Explorer oferece dashboards de gastos por serviço, conta, região, tag. Mostra tendências, previsões e recomendações de RI/Savings Plans. Permite criar relatórios customizados e alertas de budget.",
        x: "Cost Explorer mostra: EC2 é 60% do gasto, 30% das instâncias têm CPU < 5% (oversized). Recomendação: downsizar de m5.2xlarge para m5.large = economia de $200/mês. Budgets: alerta quando gasto > $1000/mês.",
      },
    ],
  },

  // ── AWS — Serviços Avançados ──
  "AWS — Serviços Avançados": {
    Fácil: [
      {
        q: "Qual serviço da AWS permite executar consultas SQL interativas diretamente em dados armazenados no S3, sem precisar de um servidor de banco de dados?",
        o: [
          "Amazon Athena",
          "Amazon Redshift",
          "Amazon DynamoDB",
          "Amazon Aurora",
        ],
        c: 0,
        e: "O Amazon Athena é um serviço serverless de consulta interativa que usa SQL padrão para analisar dados diretamente no S3. Você paga apenas pelas consultas executadas, sem necessidade de provisionar infraestrutura.",
        x: "SELECT count(*) FROM s3_logs WHERE status = 404 — essa query roda no Athena sobre arquivos Parquet no S3 sem nenhum banco configurado.",
      },
      {
        q: "Qual serviço da AWS permite busca e análise de logs em tempo real de forma gerenciada?",
        o: [
          "Amazon OpenSearch Service",
          "Amazon Athena",
          "Amazon S3 Select",
          "AWS Glue",
        ],
        c: 0,
        e: "O Amazon OpenSearch Service (antigo Elasticsearch Service) é um serviço gerenciado para busca, análise e visualização de logs e dados em tempo real. Integra-se com Kibana/OpenSearch Dashboards para visualização e com Logstash/Fluentd para ingestão.",
        x: "Envie logs do CloudWatch para OpenSearch via subscription filter. Crie dashboards no OpenSearch Dashboards para visualizar erros 5xx em tempo real com alertas.",
      },
      {
        q: "Qual serviço AWS é usado para processar streams de dados em tempo real, como dados de IoT ou clickstream?",
        o: [
          "Amazon Kinesis Data Streams",
          "Amazon SQS",
          "Amazon SNS",
          "AWS Batch",
        ],
        c: 0,
        e: "O Amazon Kinesis Data Streams captura e processa grandes volumes de dados em tempo real (streams). Diferente do SQS (mensageria assíncrona), o Kinesis permite processar dados ordenados com múltiplos consumidores simultaneamente, ideal para analytics em tempo real.",
        x: "Dispositivos IoT enviam 10.000 eventos/seg para um stream Kinesis com 10 shards. Um consumer Lambda processa em tempo real e outro consumer grava no S3 para análise histórica.",
      },
      {
        q: "Qual serviço AWS é usado para transferir dados de data warehouse e análise OLAP em petabytes?",
        o: [
          "Amazon Redshift",
          "Amazon RDS",
          "Amazon DynamoDB",
          "Amazon ElastiCache",
        ],
        c: 0,
        e: "Amazon Redshift é um data warehouse colunar totalmente gerenciado para análise OLAP em petabytes. Usa Massively Parallel Processing (MPP) e armazenamento colunar comprimido. Redshift Spectrum permite queries em dados no S3 sem importá-los.",
        x: "Redshift cluster: 4 nós ra3.xlplus. Query: SELECT product, SUM(revenue) FROM sales WHERE year=2025 GROUP BY product — processa 500GB de dados em 8 segundos usando MPP.",
      },
      {
        q: "O que é o AWS Glue e para que serve?",
        o: [
          "Serviço serverless de ETL que descobre, prepara e combina dados para análise",
          "Cola para colar snapshots de EC2",
          "Serviço de CDN",
          "Proxy de APIs",
        ],
        c: 0,
        e: "AWS Glue é um serviço ETL (Extract, Transform, Load) serverless. O Glue Crawler descobre e cataloga dados no S3/RDS automaticamente. O Glue Data Catalog é um metastore central para Athena, Redshift e EMR.",
        x: "Glue Crawler escaneia CSVs no S3 → cria tabela no Data Catalog com schema inferido → Athena consulta via SQL sem setup. Glue ETL Job transforma dados JSON → Parquet para otimizar queries.",
      },
      {
        q: "O que é o Amazon SQS (Simple Queue Service)?",
        o: [
          "Serviço de filas de mensagens gerenciado para desacoplar componentes de aplicações distribuídas",
          "Serviço de notificação push",
          "Banco de dados de mensagens",
          "CDN para mensagens",
        ],
        c: 0,
        e: "SQS é um serviço de filas totalmente gerenciado que permite desacoplar producers e consumers. Mensagens ficam na fila até serem processadas. Integra-se com Lambda, EC2 e ECS. Dead Letter Queue (DLQ) captura mensagens que falharam repetidamente.",
        x: "Fluxo: usuário faz pedido → API publica na fila SQS → Lambda consome a mensagem → processa pagamento. Se API recebe 1000 pedidos/seg, SQS absorve o pico e Lambda processa no ritmo possível.",
      },
      {
        q: "O que é o AWS Lambda e qual a diferença para EC2?",
        o: [
          "Serviço serverless que executa código sem gerenciar servidores; EC2 requer gerenciar instâncias",
          "Lambda é mais potente que EC2",
          "EC2 é serverless e Lambda não",
          "Lambda substitui bancos de dados",
        ],
        c: 0,
        e: "Lambda executa código em resposta a eventos (API Gateway, S3, SQS) sem provisionar servidores. Paga por execução (ms). Timeout máx: 15 min. EC2: servidor full, paga por hora, sem limite de tempo. Lambda para funções curtas; EC2 para workloads longas.",
        x: "Lambda: redimensionar imagem quando upload no S3. 200ms de execução com 256MB RAM = ~$0.000000833. EC2 t3.micro 24/7: ~$8.50/mês mesmo ocioso. Lambda ideal para cargas intermitentes.",
      },
    ],
    Médio: [
      {
        q: "No Amazon SQS, qual é a diferença fundamental entre filas Standard e FIFO?",
        o: [
          "FIFO garante ordem exata e entrega única; Standard oferece maior throughput sem garantia de ordem",
          "Standard é mais caro que FIFO",
          "FIFO suporta mensagens maiores que Standard",
          "Standard não permite Dead Letter Queue",
        ],
        c: 0,
        e: "Filas FIFO (First-In-First-Out) garantem que as mensagens sejam processadas exatamente uma vez e na ordem exata de envio, com throughput de até 3.000 msg/s com batching. Filas Standard oferecem throughput praticamente ilimitado, mas podem entregar mensagens duplicadas e fora de ordem.",
        x: "Para processar pedidos financeiros onde a ordem importa, use SQS FIFO (minha-fila.fifo). Para notificações por e-mail onde duplicatas são aceitáveis, use Standard.",
      },
      {
        q: "Qual é a função do Amazon EventBridge (antigo CloudWatch Events) em arquiteturas orientadas a eventos?",
        o: [
          "Barramento de eventos serverless que roteia eventos entre serviços AWS, SaaS e aplicações personalizadas",
          "Banco de dados de eventos",
          "Serviço de filas de mensagens",
          "CDN para distribuição de eventos",
        ],
        c: 0,
        e: "O EventBridge é um event bus serverless que recebe eventos de serviços AWS (ex: estado de EC2 mudou), aplicações SaaS (Zendesk, Datadog) e eventos customizados, roteando-os para targets (Lambda, SQS, Step Functions) baseado em regras de padrão (event patterns).",
        x: "Regra: quando EC2 instanceState = 'stopped' → invocar Lambda de notificação. Pattern: { 'source': ['aws.ec2'], 'detail-type': ['EC2 Instance State-change Notification'], 'detail': { 'state': ['stopped'] } }.",
      },
      {
        q: "No Amazon DynamoDB, o que são GSIs (Global Secondary Indexes) e quando usá-los?",
        o: [
          "Índices com partition key diferente da tabela principal, permitindo queries por atributos alternativos",
          "Backups globais do banco",
          "Réplicas em outras regiões",
          "Cache em memória para queries frequentes",
        ],
        c: 0,
        e: "GSI permite criar índices com uma partition key e sort key diferentes da tabela base, habilitando queries eficientes por atributos que não são a chave primária. Cada GSI é uma projeção esparsada da tabela com throughput provisionado independente.",
        x: "Tabela 'Pedidos' com PK=pedidoId. GSI 'por-cliente': PK=clienteId, SK=dataPedido. Query 'todos pedidos do cliente X ordenados por data' usa o GSI em vez de scan na tabela.",
      },
      {
        q: "O que é o Amazon ElastiCache e quando usar Redis vs Memcached?",
        o: [
          "Serviço de cache em memória gerenciado; Redis para estruturas complexas, Memcached para cache simples",
          "Serviço de armazenamento em disco",
          "CDN para conteúdo estático",
          "Banco NoSQL gerenciado",
        ],
        c: 0,
        e: "ElastiCache oferece Redis e Memcached gerenciados. Redis: persistência, replicação, Pub/Sub, tipos complexos (sorted sets, hashes), Lua scripting. Memcached: multi-thread, mais simples, apenas key-value volátil. Redis é mais versátil; Memcached para cache puro horizontal.",
        x: "Redis para sessões de usuário com TTL: SET session:abc123 '{\"userId\":42}' EX 3600. Memcached para cache de queries SQL simples: SET query_hash result. Redis suporta cluster com sharding automático.",
      },
      {
        q: "O que é o AWS CloudFront e para que serve?",
        o: [
          "CDN global que distribui conteúdo em edge locations para reduzir latência",
          "Firewall de aplicação web",
          "Serviço de DNS",
          "Balanceador de carga regional",
        ],
        c: 0,
        e: "CloudFront é CDN da AWS com 400+ PoPs (Points of Presence) globais. Cacheia conteúdo estático (imagens, CSS, JS) e dinâmico próximo ao usuário. Integra-se com S3, ALB, EC2 e Lambda@Edge. Suporta HTTPS, HTTP/3 e WebSocket.",
        x: "Origem S3 no us-east-1. Usuário no Brasil acessa via CloudFront PoP em São Paulo (~5ms) em vez de ir ao S3 diretamente (~150ms). Invalidation: aws cloudfront create-invalidation --paths '/img/*'.",
      },
      {
        q: "O que é o Amazon EKS (Elastic Kubernetes Service)?",
        o: [
          "Serviço gerenciado de Kubernetes que opera o control plane sem gerenciamento manual",
          "Serviço de email da AWS",
          "Ferramenta de ETL",
          "CDN para containers",
        ],
        c: 0,
        e: "EKS gerencia o control plane do Kubernetes (API server, etcd, scheduler) com SLA 99,95%. Você gerencia os worker nodes (EC2 ou Fargate). Integra com IAM, ALB, CloudWatch, VPC nativamente.",
        x: "eksctl create cluster --name meu-cluster --region us-east-1 --nodegroup-name workers --node-type t3.medium --nodes 3. kubectl apply -f deployment.yaml — mesmo workflow K8s, infra gerenciada pela AWS.",
      },
      {
        q: "O que é o Amazon SNS vs SQS e quando usar cada um?",
        o: [
          "SNS é pub/sub (fan-out para múltiplos assinantes); SQS é fila (um consumer por mensagem)",
          "São idênticos",
          "SQS é pub/sub e SNS é fila",
          "SNS substitui SQS completamente",
        ],
        c: 0,
        e: "SNS (pub/sub): uma mensagem vai para MÚLTIPLOS assinantes simultaneamente (Lambda, SQS, email). SQS (fila): mensagem vai para UM consumer. Padrão fan-out: SNS publica → múltiplas filas SQS assinam → cada fila processa independentemente.",
        x: "Pedido recebido → SNS publica 'PedidoCriado'. Assinantes: SQS-pagamento (processa cobrança), SQS-estoque (reserva itens), SQS-email (envia confirmação). Fan-out: cada serviço recebe a mesma mensagem.",
      },
    ],
    Difícil: [
      {
        q: "Ao configurar o AWS Step Functions com o padrão 'Map State' para processamento paralelo, qual é o limite padrão de execuções concorrentes e como otimizá-lo?",
        o: [
          "40 iterações concorrentes por padrão; usar MaxConcurrency para ajustar",
          "Sem limite; usar Retry para controlar",
          "10 iterações; usar Parallel State em vez de Map",
          "100 iterações; ativar Express Workflows",
        ],
        c: 0,
        e: "O Map State do Step Functions processa itens em paralelo com MaxConcurrency padrão de 40. Você pode ajustar esse valor para controlar o paralelismo e evitar throttling em serviços downstream. Para volumes massivos, Express Workflows são recomendados.",
        x: '{ "Type": "Map", "MaxConcurrency": 100, "Iterator": { ... } } — processa até 100 itens simultaneamente de um array de entrada.',
      },
      {
        q: "No AWS Lambda, o que são Lambda Layers e qual problema elas resolvem?",
        o: [
          "Pacotes compartilhados de código/dependências reutilizáveis entre múltiplas funções Lambda",
          "Camadas de segurança adicionais",
          "Níveis de log do CloudWatch",
          "Tiers de preço do Lambda",
        ],
        c: 0,
        e: "Lambda Layers são arquivos ZIP contendo bibliotecas, runtimes customizados ou dados compartilhados. Até 5 layers por função. Evitam duplicação de código/dependências entre funções, reduzem tamanho do pacote de deploy e facilitam atualizações centralizadas.",
        x: "Crie uma layer 'shared-utils' com lodash e moment.js. Associe a 20 funções Lambda. Ao atualizar lodash, publique nova versão da layer — todas as funções usam a versão atualizada sem redeploy individual.",
      },
      {
        q: "Como o Amazon Aurora Serverless v2 gerencia a escalabilidade e quando utilizá-lo em vez do Aurora provisionado?",
        o: [
          "Escala automaticamente capacidade de leitura/escrita em incrementos granulares (ACUs) baseado na demanda",
          "Desliga completamente quando sem tráfego",
          "Apenas escala leituras, não escritas",
          "Requer configuração manual de auto-scaling",
        ],
        c: 0,
        e: "Aurora Serverless v2 escala em incrementos de 0.5 ACU (Aurora Capacity Units), respondendo a mudanças de carga em segundos. Diferente do provisionado (tamanho fixo de instância), adapta-se automaticamente a picos e vales de demanda. Ideal para workloads imprevisíveis ou intermitentes.",
        x: "Config: min 0.5 ACU, max 64 ACU. Noite: 0.5 ACU (~$0.06/h). Pico: 32 ACU (~$3.84/h). Vs provisionado db.r5.4xlarge fixo a $2.74/h 24/7. Serverless economiza 60% para cargas variáveis.",
      },
      {
        q: "O que é o AWS ECS Fargate e como difere do ECS com EC2 launch type?",
        o: [
          "Fargate é serverless para contêineres — sem gerenciar instâncias EC2; EC2 launch type requer gerenciar o cluster",
          "São idênticos",
          "EC2 launch type é serverless",
          "Fargate não suporta Docker",
        ],
        c: 0,
        e: "ECS Fargate: serverless, você define CPU/memória por tarefa e a AWS provisiona infraestrutura automaticamente. ECS EC2: você gerencia instâncias EC2 do cluster (AMI, scaling, patching). Fargate é mais simples; EC2 dá mais controle e pode ser mais econômico para workloads grandes.",
        x: "Fargate: task com 1 vCPU + 2GB RAM → AWS aloca automaticamente, zero gerenciamento de servidor. EC2 launch type: crie ASG com c5.xlarge, gerencie AMI, configure draining. Use Fargate para simplicidade, EC2 para controle de custo.",
      },
      {
        q: "O que são AWS Step Functions e quando usá-las?",
        o: [
          "Serviço de orquestração visual para coordenar múltiplos serviços AWS em workflows",
          "Funções Lambda com mais timeout",
          "Framework de testes de integração",
          "CI/CD nativo da AWS",
        ],
        c: 0,
        e: "Step Functions orquestram workflows com estados: Task, Choice (if/else), Parallel, Map (loop), Wait. Integram-se nativamente com Lambda, ECS, SNS, SQS, DynamoDB. Dois tipos: Standard (até 1 ano, exatamente uma vez) e Express (até 5 min, alta taxa).",
        x: "Workflow de processamento de pedido: StartState → ValidarPedido (Lambda) → Choice (estoque?) → Sim: CobrarPagamento → EnviarEmail → End. Não: NotificarSemEstoque → End. Tudo visual e com retry automático.",
      },
      {
        q: "O que é o AWS Lake Formation e como simplifica a criação de data lakes?",
        o: [
          "Serviço que automatiza coleta, limpeza, cataloging e segurança de dados em um data lake no S3",
          "Serviço de criação de bancos relacionais",
          "Ferramenta de backup para S3",
          "CDN para dados analíticos",
        ],
        c: 0,
        e: "Lake Formation automatiza: ingestão de dados de múltiplas fontes, transformação ETL, cataloging (Glue Data Catalog), e controle de acesso granular (column-level security). Centraliza governança do data lake.",
        x: "Sem Lake Formation: configuração manual de Glue crawlers + IAM policies + S3 bucket policies para cada tabela. Com Lake Formation: interface visual para dar permissão 'usuário X pode ver colunas A,B da tabela Y'.",
      },
      {
        q: "O que é o padrão de Event Sourcing e como se complementa com CQRS na AWS?",
        o: [
          "Armazenar todos os eventos de mutação como fonte de verdade; CQRS separa modelos de leitura e escrita",
          "Backup baseado em eventos do CloudTrail",
          "Cache de eventos no ElastiCache",
          "Streaming de vídeo em tempo real",
        ],
        c: 0,
        e: "Event Sourcing persiste cada mudança de estado como evento imutável (append-only log). O estado atual é reconstruído reproduzindo eventos. Combinado com CQRS: eventos são a fonte de escrita; projections materializam views otimizadas para leitura.",
        x: "Conta bancária: eventos [Aberta(R$0), Depósito(R$100), Saque(R$30), Depósito(R$50)]. Saldo = replay: 0+100-30+50 = R$120. AWS: Kinesis (event store) + DynamoDB (read model) + Lambda (projections).",
      },
    ],
  },

  // ── Azure — Fundamentos ──
  "Azure — Fundamentos": {
    Fácil: [
      {
        q: "No Microsoft Azure, qual é o nome do serviço que permite criar e gerenciar máquinas virtuais na nuvem?",
        o: [
          "Azure Virtual Machines",
          "Azure Functions",
          "Azure Blob Storage",
          "Azure SQL Database",
        ],
        c: 0,
        e: "Azure Virtual Machines é o serviço IaaS do Azure que permite provisionar VMs com Windows ou Linux, escolhendo tamanho, região e imagem do sistema operacional.",
        x: "Você cria uma VM pelo portal: az vm create --name minhaVM --image UbuntuLTS --size Standard_B2s --resource-group meuGrupo.",
      },
      {
        q: "No Azure, qual serviço é equivalente ao Amazon S3 para armazenamento de objetos?",
        o: [
          "Azure Blob Storage",
          "Azure Files",
          "Azure Disk Storage",
          "Azure Table Storage",
        ],
        c: 0,
        e: "O Azure Blob Storage armazena objetos (blobs) de forma massiva e escalável. Suporta tiers de acesso: Hot (acesso frequente), Cool (acesso esporádico) e Archive (arquivamento). É o serviço de armazenamento de objetos do Azure, análogo ao S3.",
        x: "az storage blob upload --container-name imagens --file foto.jpg --name foto.jpg --account-name meuStorage — faz upload de um arquivo para o Blob Storage.",
      },
      {
        q: "O que são as Availability Zones (Zonas de Disponibilidade) do Azure?",
        o: [
          "Datacenters fisicamente separados dentro de uma mesma região Azure",
          "Regiões diferentes do Azure",
          "Tipos de assinatura",
          "Níveis de suporte",
        ],
        c: 0,
        e: "Availability Zones são locais fisicamente separados (datacenters independentes) dentro de uma região Azure, cada um com energia, refrigeração e rede independentes. Distribuir recursos entre zonas protege contra falhas de datacenter individual.",
        x: "Região 'Brazil South' tem 3 AZs. Crie VM1 na AZ1 e VM2 na AZ2 com Load Balancer. Se AZ1 falhar, VM2 continua respondendo. SLA sobe de 99,9% (single VM) para 99,99% (multi-AZ).",
      },
      {
        q: "O que é o Azure App Service e qual tipo de aplicação ele hospeda?",
        o: [
          "Serviço PaaS para hospedar aplicações web, APIs e back-ends sem gerenciar infraestrutura",
          "Serviço de máquinas virtuais",
          "Banco de dados gerenciado",
          "CDN do Azure",
        ],
        c: 0,
        e: "Azure App Service é PaaS que hospeda apps web em .NET, Java, Node.js, Python e PHP. Oferece auto-scaling, deploy slots (staging/prod), SSL gerenciado e integração com CI/CD. Sem gerenciar SO ou servidor.",
        x: "az webapp up --name minha-api --runtime 'NODE:18-lts' --sku B1 — deploya um app Node.js no App Service com plano Basic, incluindo SSL gratuito e domínio customizado.",
      },
      {
        q: "O que é o Azure SQL Database e como difere de SQL Server em uma VM?",
        o: [
          "Banco relacional PaaS gerenciado pelo Azure; VM dá controle total mas requer gerenciar o servidor",
          "São idênticos",
          "VM é gerenciada e PaaS não",
          "Azure SQL não suporta T-SQL",
        ],
        c: 0,
        e: "Azure SQL Database: PaaS, Azure gerencia patching, backups, HA. Você configura DTUs/vCores. SQL Server em VM: IaaS, controle total (versão, configurações avançadas), mas você gerencia SO e patches. PaaS para simplicidade; VM para customização máxima.",
        x: "Azure SQL Database: backup automático com retenção de 7-35 dias, geo-replication com 1 clique, escalar de 2 a 128 vCores sem downtime. SQL em VM: precisa configurar Always On AG manualmente.",
      },
      {
        q: "O que é o Azure Resource Manager (ARM)?",
        o: [
          "Camada de gerenciamento que permite criar, atualizar e excluir recursos Azure via templates declarativos",
          "Gerenciador de memória RAM das VMs",
          "Ferramenta de monitoramento",
          "Banco de dados gerenciado",
        ],
        c: 0,
        e: "ARM é o plano de gerenciamento do Azure. Todas as requisições (portal, CLI, SDK) passam pelo ARM. ARM Templates (JSON) ou Bicep permitem deploy declarativo e reproduzível de infraestrutura (Infrastructure as Code).",
        x: "ARM Template define: VM + VNet + NSG + IP público em JSON. az deployment group create --template-file main.bicep — cria todos os recursos de uma vez. Idempotente: rodar 2x não duplica recursos.",
      },
      {
        q: "O que é o Azure Cosmos DB?",
        o: [
          "Banco de dados NoSQL distribuído globalmente com múltiplos modelos de consistência",
          "Banco relacional gerenciado",
          "Serviço de cache em memória",
          "Data warehouse",
        ],
        c: 0,
        e: "Cosmos DB é NoSQL multi-modelo (document, key-value, graph, column-family) com distribuição global, SLA de 99,999%, latência <10ms p99. 5 níveis de consistência: Strong, Bounded Staleness, Session, Consistent Prefix, Eventual.",
        x: "Cosmos DB com API MongoDB: app existente migra sem alterar código. Replicação global: dados em Brazil South + East US + West Europe. Consistência Session: mesma sessão sempre lê o que escreveu.",
      },
    ],
    Médio: [
      {
        q: "No Azure, qual recurso permite agrupar e gerenciar todos os serviços relacionados a um projeto, aplicando políticas e controle de acesso de forma centralizada?",
        o: [
          "Resource Group",
          "Management Group",
          "Subscription",
          "Azure AD Tenant",
        ],
        c: 0,
        e: "Resource Group é um contêiner lógico que agrupa recursos relacionados do Azure (VMs, bancos, redes). Permite gerenciamento conjunto, aplicação de tags, políticas de acesso RBAC e exclusão em massa de todos os recursos do grupo.",
        x: "Crie o grupo 'rg-ecommerce-prod' e coloque nele a VM, o SQL Database e o App Service do projeto. Para excluir tudo: az group delete --name rg-ecommerce-prod.",
      },
      {
        q: "No Azure, o que é o Azure Active Directory (Entra ID) e qual sua função principal?",
        o: [
          "Serviço de identidade e acesso baseado na nuvem para autenticação e autorização",
          "Servidor de banco de dados",
          "Serviço de armazenamento de arquivos",
          "Firewall de rede",
        ],
        c: 0,
        e: "O Azure AD (renomeado para Microsoft Entra ID) é o serviço de identidade na nuvem da Microsoft. Gerencia autenticação SSO, MFA, acesso condicional, e integra-se com Microsoft 365, Azure e milhares de aplicações SaaS via protocolos OAuth 2.0 e SAML.",
        x: "Funcionários fazem login com MFA no Azure AD. O Conditional Access permite: 'se dispositivo não é gerenciado, bloqueie acesso ao SharePoint'. SSO permite acesso ao Salesforce, Slack e portal interno com uma única credencial.",
      },
      {
        q: "Qual é a função do Azure Key Vault?",
        o: [
          "Gerenciar segredos, chaves criptográficas e certificados de forma centralizada e segura",
          "Armazenar backups criptografados",
          "Criar redes virtuais seguras",
          "Monitorar ameaças de segurança",
        ],
        c: 0,
        e: "O Azure Key Vault armazena e gerencia segredos (connection strings, API keys), chaves criptográficas (RSA, EC) e certificados TLS/SSL. Usa HSMs para proteger chaves. Integra-se com Azure RBAC para controle de acesso granular.",
        x: "Em vez de hardcoded: const connStr = 'Server=...;Password=123', use: const connStr = await keyVaultClient.getSecret('db-connection-string'). Segredos são rotacionados sem alterar o código.",
      },
      {
        q: "No Azure, o que são NSGs (Network Security Groups) e como funcionam?",
        o: [
          "Regras de firewall que filtram tráfego de rede para recursos Azure por IP, porta e protocolo",
          "Grupos de recursos para networking",
          "Backups de configuração de rede",
          "VPNs automáticas",
        ],
        c: 0,
        e: "NSGs contêm regras de segurança (Allow/Deny) com prioridade numérica, filtradas por IP de origem/destino, porta e protocolo. Podem ser associados a sub-redes ou NICs individuais. Regras são avaliadas por prioridade (menor número = maior prioridade).",
        x: "NSG na sub-rede web: regra 100 Allow TCP 443 de Internet (HTTPS), regra 200 Allow TCP 80 de Internet (HTTP), regra 300 Deny * de Internet (bloqueia o resto). Regras Azure padrão permitem tráfego interno da VNet.",
      },
      {
        q: "O que é o Azure Monitor e quais dados ele coleta?",
        o: [
          "Plataforma de monitoramento que coleta métricas, logs e traces de recursos Azure",
          "Ferramenta de deploy automático",
          "Gerenciador de identidades",
          "CDN para logs",
        ],
        c: 0,
        e: "Azure Monitor coleta: métricas (CPU, memória, requests), logs de atividade (quem fez o quê), logs de diagnóstico (performance detalhada), e Application Insights (APM para apps). Integra-se com Log Analytics (KQL), alertas e dashboards.",
        x: "Azure Monitor → Application Insights: latência p95 = 340ms, taxa de erro 2.1%. Alerta: 'se requests falhando > 5% por 5 min, notifique no Teams'. Log Analytics KQL: AzureActivity | where OperationName == 'Delete'.",
      },
      {
        q: "O que é o Azure DevOps e quais serviços oferece?",
        o: [
          "Plataforma de DevOps com repos Git, pipelines CI/CD, boards, test plans e artefatos",
          "Serviço de hospedagem de VMs",
          "Banco de dados para DevOps",
          "CDN para código-fonte",
        ],
        c: 0,
        e: "Azure DevOps oferece: Repos (Git), Pipelines (CI/CD), Boards (Kanban/Scrum), Test Plans e Artifacts (pacotes npm/Maven). Alternativa: GitHub Actions integrado ao Azure. Suporta deploy para qualquer cloud.",
        x: "Pipeline YAML: trigger em push na main → build Node.js → npm test → Docker build → push ACR → deploy no AKS. Azure Boards: backlog com sprints, linked a pull requests e builds.",
      },
      {
        q: "O que é o Azure RBAC (Role-Based Access Control)?",
        o: [
          "Sistema de permissões baseado em roles atribuídas a usuários, grupos ou service principals",
          "Firewall de rede baseado em regras",
          "Sistema de backup baseado em roles",
          "Tipo de criptografia",
        ],
        c: 0,
        e: "RBAC atribui roles (Owner, Contributor, Reader, custom) a principals (usuários, grupos, managed identities) em um escopo (management group, subscription, resource group, recurso). Principle of least privilege: dar só o necessário.",
        x: "az role assignment create --role 'Contributor' --assignee user@empresa.com --scope /subscriptions/abc/resourceGroups/rg-prod. Usuário pode criar/editar recursos no rg-prod, mas não deletar a subscription.",
      },
    ],
    Difícil: [
      {
        q: "No Azure Policy, qual é a diferença entre os efeitos 'Deny' e 'DeployIfNotExists'?",
        o: [
          "Deny bloqueia a criação do recurso; DeployIfNotExists cria automaticamente um recurso complementar se ausente",
          "Deny e DeployIfNotExists fazem a mesma coisa",
          "DeployIfNotExists bloqueia e Deny corrige",
          "Deny é para tags e DeployIfNotExists para redes",
        ],
        c: 0,
        e: "O efeito Deny impede a criação ou alteração de recursos que não cumprem a política. Já DeployIfNotExists verifica se um recurso complementar existe (ex.: extensão de diagnóstico) e, se não existir, o cria automaticamente via template ARM durante a avaliação.",
        x: "Política Deny: impede VMs sem tag 'CentroCusto'. Política DeployIfNotExists: se uma VM não tiver o Azure Monitor Agent instalado, a política dispara um deployment que instala automaticamente.",
      },
      {
        q: "No Azure, qual é o papel do Azure Landing Zone e quais componentes ele padroniza?",
        o: [
          "Arquitetura pré-configurada com networking, identidade, governança e segurança para escalar na nuvem",
          "Zona de DNS para domínios públicos",
          "Região geográfica prioritária para deploy",
          "Ferramenta de migração de servidores on-premises",
        ],
        c: 0,
        e: "Azure Landing Zone é uma arquitetura de referência que padroniza Management Groups, Subscriptions, Networking (hub-spoke), Identity (Entra ID), Governance (Policy, Blueprints) e Security (Defender for Cloud). Permite que novas workloads sejam lançadas em um ambiente pré-configurado e compliant.",
        x: "Landing Zone inclui: Hub VNet com Firewall + Bastion, Spoke VNets para workloads, Policy assignments para compliance, Log Analytics centralizado, RBAC por subscription. Novas equipes recebem uma subscription pronta com guardrails.",
      },
      {
        q: "Como funciona o Azure Private Link e qual problema de segurança ele resolve?",
        o: [
          "Permite acessar serviços PaaS via IP privado na VNet, sem expor tráfego à internet pública",
          "Cria VPNs entre regiões",
          "Criptografa dados em repouso",
          "Gerencia certificados SSL",
        ],
        c: 0,
        e: "O Azure Private Link cria um private endpoint na sua VNet com um IP privado que se conecta diretamente ao serviço PaaS (Storage, SQL Database, etc.). O tráfego nunca sai da rede backbone da Microsoft, eliminando exposição à internet pública e reduzindo a superfície de ataque.",
        x: "Sem Private Link: App → Internet → Storage Account (IP público). Com Private Link: App → 10.0.1.5 (private endpoint) → Storage Account. O Storage pode ter 'Deny public access' ativado, acessível apenas via VNet.",
      },
      {
        q: "O que é o Azure Bastion e por que usá-lo em vez de expor SSH/RDP diretamente?",
        o: [
          "Serviço PaaS que fornece acesso seguro SSH/RDP a VMs via navegador sem expor portas à internet",
          "VPN client-to-site",
          "Firewall de rede virtual",
          "Load balancer para SSH",
        ],
        c: 0,
        e: "Azure Bastion é um PaaS que serve como jump host gerenciado. Conecta a VMs via RDP/SSH pelo portal Azure (navegador), sem precisar de IP público na VM ou abrir portas 22/3389 para a internet. Elimina exposição da superfície de ataque.",
        x: "Sem Bastion: VM com IP público + NSG permitindo 22/0.0.0.0 = risco de brute force. Com Bastion: VM sem IP público, acesso via portal Azure → Bastion → SSH, tráfego via TLS pelo backbone Microsoft.",
      },
      {
        q: "O que é o Azure Cost Management e como ajuda a otimizar gastos en nuvem?",
        o: [
          "Ferramenta que analisa gastos, cria orçamentos e recomenda otimizações de custo",
          "Plano de desconto por volume",
          "Cálculo automático de ROI",
          "Estimativa de custos de migração",
        ],
        c: 0,
        e: "Azure Cost Management permite: visualizar custos por recurso/tag/subscription, criar budgets com alertas (ex: notificar quando atingir 80%), forecast de gastos e Azure Advisor recomendações (ex: reduzir VM ociosa, comprar Reserved Instances).",
        x: "Budget mensal: R$5.000. Alerta em 80% (R$4.000). Advisor: 'VM Standard_D4 com 10% CPU média → redimensionar para Standard_B2s, economia de R$800/mês'. Cost analysis: 45% compute, 30% storage, 15% networking.",
      },
      {
        q: "O que é o Azure Arc e como estende o gerenciamento além do Azure?",
        o: [
          "Serviço que projeta gerenciamento Azure (policies, RBAC, monitoring) para servidores on-prem e multi-cloud",
          "Tipo de rede virtual do Azure",
          "Ferramenta de migração de VMs",
          "CDN global do Azure",
        ],
        c: 0,
        e: "Azure Arc estende o plano de controle do Azure para fora do Azure: servidores on-premises, VMs em AWS/GCP, e clusters Kubernetes. Permite aplicar Azure Policy, RBAC, Monitor e Defender for Cloud a recursos não-Azure.",
        x: "Servidor Linux on-prem registrado no Arc: aparece no portal Azure, recebe Azure Policy (compliance), Azure Monitor (métricas/logs), Defender for Cloud (vulnerabilidades). Gestão unificada híbrida.",
      },
      {
        q: "Como funciona o Azure Front Door e quando usá-lo?",
        o: [
          "Serviço global de load balancing L7 com WAF, cache e aceleração para aplicações distribuídas",
          "Firewall de rede L4",
          "VPN entre regiões Azure",
          "DNS privado",
        ],
        c: 0,
        e: "Azure Front Door opera na borda global da Microsoft: roteamento inteligente (latência, prioridade, peso), TLS offloading, caching, WAF integrado. Ideal para apps multi-região que precisam de failover global e baixa latência.",
        x: "App em Brazil South + East US. Front Door roteia usuários brasileiros para Brazil South (20ms) e americanos para East US (15ms). Se Brazil South cair, failover automático para East US em <30s.",
      },
    ],
  },

  // ── Azure — Serviços Avançados ──
  "Azure — Serviços Avançados": {
    Fácil: [
      {
        q: "Qual serviço do Azure permite criar aplicações web e APIs sem gerenciar a infraestrutura do servidor?",
        o: [
          "Azure App Service",
          "Azure Virtual Machines",
          "Azure Disk Storage",
          "Azure VPN Gateway",
        ],
        c: 0,
        e: "O Azure App Service é um serviço PaaS que hospeda aplicações web, APIs REST e back-ends móveis. Suporta .NET, Java, Node.js, Python e PHP, com escalonamento automático e deploy integrado.",
        x: "az webapp create --name meu-api --plan meuPlano --runtime 'NODE:18-lts' — cria uma aplicação Node.js sem configurar servidor.",
      },
      {
        q: "Qual serviço do Azure permite executar funções de código sem servidor, acionadas por eventos?",
        o: [
          "Azure Functions",
          "Azure App Service",
          "Azure Batch",
          "Azure Logic Apps",
        ],
        c: 0,
        e: "O Azure Functions é o serviço FaaS (Function as a Service) do Azure. Executa código sob demanda em resposta a triggers: HTTP, Timer, Blob Storage, Queue, Event Hub. Cobra apenas pelo tempo de execução (consumption plan).",
        x: "Uma Azure Function dispara quando um blob é adicionado ao container 'uploads': @BlobTrigger('uploads/{name}') — processa a imagem automaticamente sem servidor dedicado.",
      },
      {
        q: "O que é o Azure DevOps e quais serviços ele oferece?",
        o: [
          "Plataforma completa com Boards, Repos, Pipelines, Test Plans e Artifacts",
          "Apenas controle de versão",
          "Apenas CI/CD",
          "Serviço de monitoramento",
        ],
        c: 0,
        e: "Azure DevOps é uma suíte de ferramentas de desenvolvimento: Azure Boards (gestão ágil), Azure Repos (Git), Azure Pipelines (CI/CD), Azure Test Plans (testes) e Azure Artifacts (pacotes). Integra-se com GitHub e ferramentas de terceiros.",
        x: "Crie um projeto no Azure DevOps, use Boards com Scrum, Repos para código, Pipelines com YAML para build/deploy e Artifacts para publicar pacotes npm internos.",
      },
      {
        q: "Qual serviço Azure é usado para processar e analisar grandes volumes de dados de forma serverless?",
        o: [
          "Azure Synapse Analytics",
          "Azure Blob Storage",
          "Azure App Service",
          "Azure Functions",
        ],
        c: 0,
        e: "Azure Synapse Analytics (antigo SQL Data Warehouse) unifica big data e data warehousing. Oferece SQL pools (dedicado e serverless), Apache Spark pools, pipelines de integração de dados e integração com Power BI. Tudo em uma plataforma.",
        x: "Synapse serverless SQL: query direta em Parquet no Data Lake sem provisionar infra. Spark pool: processa 1TB de logs com PySpark. Pipeline: orquestra ETL do Blob para SQL pool dedicado.",
      },
      {
        q: "O que é o Azure Container Instances (ACI) e quando usá-lo?",
        o: [
          "Serviço para rodar contêineres individualmente sem orquestração, ideal para tarefas simples",
          "Kubernetes gerenciado",
          "Registry de imagens Docker",
          "VM com Docker pré-instalado",
        ],
        c: 0,
        e: "ACI roda contêineres sob demanda sem gerenciar VMs ou clusters. Ideal para tarefas pontuais (batch, CI, testes), sidecar containers e burst from AKS (virtual nodes). Não tem orquestração — para workloads complexos, use AKS.",
        x: "az container create --name meu-batch --image meuacr.azurecr.io/batch:v1 --cpu 2 --memory 4 --restart-policy Never — roda um job de processamento e para ao finalizar. Sem cluster para gerenciar.",
      },
      {
        q: "O que é o Azure Key Vault e para que serve?",
        o: [
          "Serviço para armazenar e gerenciar secrets, chaves de criptografia e certificados de forma centralizada",
          "Cofre físico para discos de backup",
          "Banco de dados criptografado",
          "Gerenciador de senhas pessoal",
        ],
        c: 0,
        e: "Azure Key Vault armazena secrets (connection strings, API keys), chaves de criptografia (RSA, EC) e certificados TLS. Acesso via RBAC e Azure AD. HSM-backed para compliance. Rotação automática de secrets integrada com serviços Azure.",
        x: "az keyvault secret set --vault-name meu-vault --name DB-CONN --value 'Server=...'. App Service lê: @Microsoft.KeyVault(SecretUri=https://meu-vault.vault.azure.net/secrets/DB-CONN). Zero secrets no app settings.",
      },
      {
        q: "O que é o Azure Service Bus e quando usá-lo?",
        o: [
          "Serviço de mensageria enterprise com filas e tópicos pub/sub para comunicação assíncrona confiável",
          "Ônibus de rede entre VNets",
          "CDN para APIs",
          "Serviço de DNS",
        ],
        c: 0,
        e: "Service Bus oferece filas (point-to-point) e tópicos (pub/sub) com garantias enterprise: FIFO, deduplicação, sessões, dead-letter, transações. Ideal para integração entre microsserviços que requerem entrega garantida e ordenação.",
        x: "Fila: pedido criado → mensagem na fila → serviço de pagamento consome. Tópico: evento 'PedidoAprovado' → assinantes: estoque (reserva), email (confirma), analytics (registra). Entrega garantida com retry.",
      },
    ],
    Médio: [
      {
        q: "No Azure Cosmos DB, o que representa a unidade 'Request Unit' (RU)?",
        o: [
          "Uma medida normalizada de throughput que combina CPU, memória e IOPS",
          "O número de documentos lidos por segundo",
          "A quantidade de armazenamento em GB",
          "O número de réplicas ativas",
        ],
        c: 0,
        e: "Request Unit (RU) é a moeda de throughput do Cosmos DB. Uma leitura pontual de um documento de 1 KB custa 1 RU. Operações mais complexas (queries, escritas) consomem mais RUs. Você provisiona RU/s por contêiner ou banco.",
        x: "Se você provisiona 400 RU/s e cada leitura custa 1 RU, pode fazer ~400 leituras/s. Uma query com filtro pode custar 5 RUs, permitindo ~80 queries/s.",
      },
      {
        q: "No Azure, o que é um Managed Identity e como ele melhora a segurança?",
        o: [
          "Identidade gerenciada pelo Azure AD que elimina necessidade de armazenar credenciais no código",
          "Conta de usuário para administradores",
          "Tipo de criptografia para discos",
          "Certificado SSL automático",
        ],
        c: 0,
        e: "Managed Identity é uma identidade Azure AD atribuída automaticamente a recursos (VMs, App Services, Functions). O Azure gerencia a rotação de credenciais. O recurso se autentica no Azure AD sem secrets, connection strings ou certificados no código.",
        x: "App Service com System-Assigned Managed Identity: const credential = new DefaultAzureCredential(); const secret = await client.getSecret('minha-key'). Zero secrets no código ou variáveis de ambiente.",
      },
      {
        q: "Qual serviço Azure permite orquestrar workflows complexos de forma visual, integrando centenas de conectores SaaS e serviços Azure?",
        o: [
          "Azure Logic Apps",
          "Azure Functions",
          "Azure Data Factory",
          "Azure Automation",
        ],
        c: 0,
        e: "Azure Logic Apps é um serviço de integração serverless com designer visual e 400+ conectores (Office 365, Salesforce, SAP, etc.). Permite criar workflows automatizados sem código, orquestrando ações entre diferentes sistemas.",
        x: "Workflow: quando e-mail com anexo chega no Outlook → salvar no SharePoint → notificar no Teams → criar tarefa no Jira. Tudo configurado visualmente sem código.",
      },
      {
        q: "O que é o Azure Kubernetes Service (AKS) e o que ele gerencia automaticamente?",
        o: [
          "Kubernetes gerenciado onde o Azure administra o control plane e você gerencia os nós worker",
          "Docker Compose gerenciado",
          "Serverless para contêineres como Cloud Run",
          "VM com kubectl pré-instalado",
        ],
        c: 0,
        e: "AKS é Kubernetes gerenciado: Azure gerencia o control plane (API server, etcd, scheduler, controller manager) gratuitamente. Você gerencia node pools (VMs worker). Integra com Azure AD, Monitor, Policy e Container Registry.",
        x: "az aks create --name meu-cluster --node-count 3 --enable-managed-identity — cria cluster K8s com 3 nós. Control plane: zero custo e zero gerenciamento. Scale: az aks scale --node-count 10.",
      },
      {
        q: "O que é o Azure Data Factory e para que é utilizado?",
        o: [
          "Serviço de integração de dados que orquestra pipelines ETL/ELT entre diversas fontes",
          "Banco de dados fabril",
          "Serviço de machine learning",
          "Ferramenta de BI",
        ],
        c: 0,
        e: "Azure Data Factory (ADF) é um serviço de integração de dados (ETL/ELT) com 90+ conectores (SQL, S3, Salesforce, SAP). Pipelines visuais orquestram atividades de cópia, transformação (Mapping Data Flows) e controle (If, ForEach, Wait).",
        x: "Pipeline ADF: Copy Activity (CSV do Blob → staging SQL) → Data Flow (limpar/transformar) → Copy (staging → produção). Trigger: rodar todo dia às 2h. Monitor: visualizar execuções e erros.",
      },
      {
        q: "O que é o Azure Event Grid e como ele difere do Event Hub?",
        o: [
          "Event Grid é roteamento de eventos discretos (reativo); Event Hub é ingestão massiva de streaming em tempo real",
          "São idênticos",
          "Event Hub é para eventos discretos",
          "Event Grid faz streaming",
        ],
        c: 0,
        e: "Event Grid: eventos discretos (blob criado, resource alterado) → roteamento para handlers (Functions, Logic Apps). Event Hub: streaming de alta vazão (milhões/s) para telemetria, logs, IoT. Event Grid é reativo; Event Hub é ingestão massiva.",
        x: "Event Grid: blob criado no Storage → Function processa imagem. Event Hub: 10.000 dispositivos IoT enviando telemetria/s → Stream Analytics agrega → Power BI exibe dashboard real-time.",
      },
      {
        q: "O que é o Azure Cache for Redis e quando usá-lo?",
        o: [
          "Serviço gerenciado de cache em memória baseado em Redis para acelerar acesso a dados frequentes",
          "Banco de dados relacional em cache",
          "CDN para arquivos estáticos",
          "Serviço de backup incremental",
        ],
        c: 0,
        e: "Azure Cache for Redis é Redis totalmente gerenciado: cache (session store, page cache), broker de mensagens (pub/sub) e data store temporário. Tiers: Basic (dev), Standard (replicado), Premium (cluster, VNet, persistência).",
        x: "App autenticado: session no Redis (TTL 30min) em vez de bank query toda request. Latência: Redis <1ms vs SQL ~20ms. Pattern cache-aside: busca no Redis → miss → busca no SQL → grava no Redis → retorna.",
      },
    ],
    Difícil: [
      {
        q: "No Azure Service Fabric, qual é a diferença entre Stateless Services e Stateful Services em termos de gerenciamento de estado e particionamento?",
        o: [
          "Stateful Services mantêm estado replicado em partições locais; Stateless dependem de armazenamento externo",
          "Não há diferença funcional",
          "Stateless tem particionamento e Stateful não",
          "Stateful Services não suportam réplicas",
        ],
        c: 0,
        e: "Stateful Services no Service Fabric mantêm o estado diretamente na memória com réplicas distribuídas entre nós, usando particionamento para escalar. Stateless Services não mantêm estado local e dependem de bancos externos. Stateful elimina a latência de acesso ao estado externo.",
        x: "Um serviço de carrinho de compras Stateful armazena o carrinho na partição do usuário (hash do userId). 3 réplicas garantem durabilidade sem precisar de Redis externo.",
      },
      {
        q: "No Azure, como o Azure Front Door se diferencia do Azure Application Gateway em termos de escopo e funcionalidades?",
        o: [
          "Front Door é global (anycast) com WAF, CDN e roteamento multi-região; App Gateway é regional com WAF e balanceamento L7",
          "São idênticos",
          "App Gateway é global e Front Door regional",
          "Front Door é apenas CDN",
        ],
        c: 0,
        e: "Azure Front Door opera globalmente via anycast, oferecendo CDN, WAF, SSL offloading e roteamento inteligente entre regiões. Azure Application Gateway opera dentro de uma região, fornecendo balanceamento L7 com WAF, SSL termination e URL-based routing para backends regionais.",
        x: "Front Door: usuários do Brasil são roteados para Brazil South, europeus para West Europe (menor latência). App Gateway: dentro de Brazil South, distribui tráfego entre VMs do pool backend com health probes.",
      },
      {
        q: "O que são Durable Functions no Azure e qual problema elas resolvem que Azure Functions comuns não resolvem?",
        o: [
          "Permitem orquestrar workflows stateful com estado preservado entre execuções de Functions",
          "São functions com mais memória",
          "Functions com timeout ilimitado",
          "Functions com GPU dedicada",
        ],
        c: 0,
        e: "Durable Functions estendem Azure Functions com padrões stateful: orchestration (sequência), fan-out/fan-in (paralelo), human interaction (aguardar aprovação) e monitoring (polling periódico). O estado é gerenciado automaticamente via Azure Storage, permitindo workflows de longa duração.",
        x: "Padão fan-out/fan-in: const tasks = cities.map(c => context.df.callActivity('GetWeather', c)); const results = await context.df.Task.all(tasks); — busca clima de 50 cidades em paralelo e aguarda todas.",
      },
      {
        q: "O que são Availability Sets e como diferem de Availability Zones?",
        o: [
          "Availability Sets protegem contra falhas de rack/host dentro de um datacenter; Zones protegem contra falhas de datacenter inteiro",
          "São sinônimos",
          "Sets são mais resilientes que Zones",
          "Zones são dentro de um rack",
        ],
        c: 0,
        e: "Availability Set: distribui VMs entre fault domains (racks) e update domains dentro de um datacenter. SLA: 99.95%. Availability Zone: datacenters fisicamente separados na mesma região. SLA: 99.99%. Zones oferecem proteção maior contra desastres.",
        x: "Availability Set: 2 fault domains → VMs em racks diferentes, se 1 rack cai o outro funciona. Availability Zones: VMs em datacenters com energia/rede independentes. Para alta disponibilidade crítica, use Zones.",
      },
      {
        q: "O que é o Azure Arc e qual problema ele resolve?",
        o: [
          "Estende serviços Azure (governance, policy, monitoring) para recursos on-premises e multi-cloud",
          "CDN global do Azure",
          "Ferramenta de migração de VMs",
          "Serviço de DNS",
        ],
        c: 0,
        e: "Azure Arc permite gerenciar servidores, clusters Kubernetes e bancos de dados fora do Azure com as mesmas ferramentas (Azure Policy, Monitor, RBAC). Suporta on-premises, AWS, GCP e edge. Visão unificada de todos os recursos no portal Azure.",
        x: "Servidor Linux on-premises registrado no Azure Arc: aplique Azure Policy para compliance, colete logs com Azure Monitor, gerencie via portal Azure como se fosse uma VM Azure nativa.",
      },
      {
        q: "Como funciona o Azure Private Link e qual problema de segurança ele resolve?",
        o: [
          "Cria endpoint privado na VNet para acessar serviços PaaS via rede privada da Microsoft, eliminando exposição à internet",
          "VPN entre Azure e on-premises",
          "Criptografia de disco",
          "Antivírus para VMs",
        ],
        c: 0,
        e: "Private Link cria um Private Endpoint (NIC privada) na sua VNet que mapeia para um serviço PaaS (Storage, SQL, Cosmos DB). O tráfego permanece na rede backbone da Microsoft, nunca trafega pela internet pública. Elimina exfiltração de dados via DNS.",
        x: "Sem Private Link: App → Internet → storage.blob.core.windows.net (IP público). Com Private Link: App → 10.0.1.5 (private endpoint) → rede backbone MS → Storage. NSG + Private DNS Zone completam isolamento.",
      },
      {
        q: "O que é o Azure Bicep e como se compara com ARM Templates?",
        o: [
          "DSL declarativa que compila para ARM Templates JSON, com sintaxe mais limpa e modular",
          "Linguagem de programação imperativa",
          "Ferramenta de monitoramento",
          "Alternativa ao Terraform incompatível com Azure",
        ],
        c: 0,
        e: "Bicep é uma DSL (Domain-Specific Language) que transpila para ARM JSON. Vantagens: sintaxe concisa (~60% menos código), modules reutilizáveis, detecção de erros em tempo de compilation, IntelliSense nativo no VS Code. É a evolução recomendada dos ARM Templates.",
        x: "Bicep: resource sa 'Microsoft.Storage/storageAccounts@2023-01-01' = { name: 'meustore', location: 'brazilsouth', sku: { name: 'Standard_LRS' }, kind: 'StorageV2' }. Equivale a ~40 linhas de ARM JSON.",
      },
    ],
  },

  // ── Containers e Kubernetes ──
  "Containers e Kubernetes": {
    Fácil: [
      {
        q: "Qual comando Docker é utilizado para criar uma imagem a partir de um Dockerfile?",
        o: ["docker build", "docker run", "docker pull", "docker create"],
        c: 0,
        e: "O comando 'docker build' lê as instruções do Dockerfile (FROM, COPY, RUN, etc.) e cria uma imagem de contêiner camada por camada. O flag -t permite nomear e taguear a imagem resultante.",
        x: "docker build -t meu-app:1.0 . — constrói a imagem 'meu-app' com tag '1.0' usando o Dockerfile do diretório atual.",
      },
      {
        q: "Qual é a diferença entre um contêiner Docker e uma máquina virtual?",
        o: [
          "Contêiner compartilha o kernel do host e é mais leve; VM virtualiza hardware completo com SO próprio",
          "São a mesma coisa",
          "VM é mais leve que contêiner",
          "Contêiner tem SO completo embutido",
        ],
        c: 0,
        e: "Contêineres compartilham o kernel do sistema operacional host, isolando apenas o processo e suas dependências (libs, bins). São leves (MBs) e iniciam em segundos. VMs virtualizam hardware completo com hypervisor e SO próprio, são pesadas (GBs) e levam minutos para iniciar.",
        x: "Uma imagem Alpine Linux Docker tem ~5MB e inicia em <1s. Uma VM Ubuntu completa tem ~2GB e leva ~30s para bootar. Em um servidor, cabem centenas de contêineres vs dezenas de VMs.",
      },
      {
        q: "O que é um Dockerfile e qual instrução define a imagem base?",
        o: [
          "FROM define a imagem base do contêiner",
          "RUN define a imagem base",
          "CMD define a imagem base",
          "COPY define a imagem base",
        ],
        c: 0,
        e: "Um Dockerfile é um arquivo de texto com instruções para construir uma imagem Docker. FROM é a primeira instrução e define a imagem base. Outras instruções: COPY (copiar arquivos), RUN (executar comandos), EXPOSE (portas), CMD (comando padrão ao rodar).",
        x: "FROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --production\nCOPY . .\nEXPOSE 3000\nCMD ['node', 'server.js'] — Dockerfile para app Node.js.",
      },
      {
        q: "O que é o Docker Compose e para que serve?",
        o: [
          "Ferramenta que define e executa múltiplos contêineres com um arquivo YAML",
          "Linguagem de programação para Docker",
          "Orquestrador de produção como Kubernetes",
          "Sistema de build de imagens",
        ],
        c: 0,
        e: "Docker Compose usa um docker-compose.yml para definir múltiplos serviços (contêineres), redes e volumes. Ideal para ambientes de desenvolvimento local com vários serviços (app + banco + cache). Não é recomendado para produção em escala.",
        x: "services:\n  app:\n    build: .\n    ports: ['3000:3000']\n  db:\n    image: postgres:15\n    environment: { POSTGRES_PASSWORD: 'dev' }\n  redis:\n    image: redis:7\nComando: docker compose up -d.",
      },
      {
        q: "O que é um container registry e para que serve?",
        o: [
          "Repositório centralizado para armazenar e distribuir imagens de contêineres",
          "Ferramenta de execução de contêineres",
          "Sistema operacional para contêineres",
          "Orquestrador de clusters",
        ],
        c: 0,
        e: "Container registry armazena imagens Docker versionadas. Públicos: Docker Hub. Privados: Amazon ECR, Azure ACR, Google Artifact Registry, GitHub Container Registry. Push (upload) e pull (download) imagens. Integra-se com CI/CD para build → push → deploy.",
        x: "docker build -t meuacr.azurecr.io/api:v2 . && docker push meuacr.azurecr.io/api:v2 — builda e envia para o Azure Container Registry. Kubernetes faz pull desta imagem no deploy.",
      },
      {
        q: "O que são Docker volumes e por que são importantes?",
        o: [
          "Mecanismo de persistência de dados que sobrevive ao ciclo de vida do contêiner",
          "Unidades de disco virtuais da VM",
          "Cache de imagens Docker",
          "Partições do sistema operacional",
        ],
        c: 0,
        e: "Volumes Docker persistem dados fora do filesystem do contêiner. Quando o contêiner é removido, dados no volume permanecem. Três tipos: named volumes (gerenciados pelo Docker), bind mounts (diretório do host), tmpfs (memória). Volumes são a forma recomendada.",
        x: "docker run -v pgdata:/var/lib/postgresql/data postgres:15 — dados do PostgreSQL no volume 'pgdata'. docker rm container → dados seguros. docker run -v pgdata:/var/lib/postgresql/data postgres:15 → reconecta aos mesmos dados.",
      },
      {
        q: "O que é um Pod no Kubernetes?",
        o: [
          "Menor unidade deployável que encapsula um ou mais contêineres com rede e storage compartilhados",
          "Um nó físico do cluster",
          "Uma máquina virtual completa",
          "Um namespace isolado",
        ],
        c: 0,
        e: "Pod é a unidade atômica do Kubernetes. Contém um ou mais contêineres que compartilham IP, portas, volumes e namespace de rede. Na prática, maioria dos Pods tem um contêiner principal + sidecar opcional (logging, proxy). Pods são efêmeros — não persistem após falha.",
        x: "Pod com 1 contêiner: app Node.js na porta 3000. Pod multi-container: app + Envoy sidecar (proxy) + fluentd (logs). Todos compartilham localhost e volumes. kubectl get pods → NAME: api-5d8f9, STATUS: Running.",
      },
    ],
    Médio: [
      {
        q: "No Kubernetes, qual objeto é responsável por garantir que um número especificado de réplicas de um Pod esteja sempre em execução?",
        o: ["ReplicaSet", "DaemonSet", "StatefulSet", "Job"],
        c: 0,
        e: "O ReplicaSet garante que o número desejado de réplicas de um Pod esteja rodando a qualquer momento. Se um Pod falhar, o ReplicaSet cria automaticamente um novo. Na prática, usamos Deployments que gerenciam ReplicaSets internamente.",
        x: "spec: { replicas: 3 } no ReplicaSet garante 3 Pods ativos. Se um nó cair e perder 1 Pod, o ReplicaSet agenda um novo Pod em outro nó.",
      },
      {
        q: "No Kubernetes, qual é a diferença entre um Service do tipo ClusterIP, NodePort e LoadBalancer?",
        o: [
          "ClusterIP é interno ao cluster; NodePort expõe numa porta do nó; LoadBalancer cria um LB externo",
          "São idênticos",
          "LoadBalancer é interno e ClusterIP externo",
          "NodePort substitui os outros dois",
        ],
        c: 0,
        e: "ClusterIP: IP virtual interno, acessível apenas dentro do cluster (padrão). NodePort: expõe o Service em uma porta estática (30000-32767) em cada nó do cluster. LoadBalancer: provisiona um load balancer externo do cloud provider que distribui tráfego para os nós.",
        x: "Microsserviço interno: ClusterIP (service-a.default.svc.cluster.local:80). API pública: LoadBalancer (obtém IP externo 34.95.10.5:80 no GKE). Debug: NodePort (acesso via <nodeIP>:31234).",
      },
      {
        q: "O que é um Helm Chart no Kubernetes e para que serve?",
        o: [
          "Pacote de templates Kubernetes que facilita deploy e versionamento de aplicações",
          "Ferramenta de monitoramento",
          "Tipo de volume de armazenamento",
          "Plugin de rede do cluster",
        ],
        c: 0,
        e: "Helm é o gerenciador de pacotes do Kubernetes. Um Chart é um pacote contendo templates de manifests K8s (Deployment, Service, ConfigMap, etc.) parametrizáveis via values.yaml. Permite instalar, atualizar e fazer rollback de aplicações complexas com um comando.",
        x: "helm install meu-redis bitnami/redis --set architecture=replication — instala Redis com replicação usando o Chart oficial da Bitnami, sem escrever nenhum YAML manualmente.",
      },
      {
        q: "No Kubernetes, o que é um ConfigMap e quando usá-lo?",
        o: [
          "Objeto que armazena configurações como pares chave-valor para injetar em Pods",
          "Mapa de rotas de rede",
          "Configuração do cluster",
          "Dashboard de monitoramento",
        ],
        c: 0,
        e: "ConfigMap armazena dados de configuração não-sensíveis (URLs, feature flags, configs). Injeta em Pods como variáveis de ambiente ou arquivos montados. Separa configuração do código. Para dados sensíveis (senhas, tokens), use Secret.",
        x: "apiVersion: v1\nkind: ConfigMap\ndata:\n  DATABASE_URL: 'postgres://db:5432/app'\n  LOG_LEVEL: 'info'\nPod: envFrom: - configMapRef: name: app-config. Mude a config sem rebuild da imagem.",
      },
      {
        q: "No Kubernetes, o que é um Ingress e para que serve?",
        o: [
          "Objeto que gerencia acesso externo HTTP/HTTPS ao cluster com roteamento por host/path",
          "Interface de rede interna do Pod",
          "Tipo de armazenamento persistente",
          "Sonda de saúde dos Pods",
        ],
        c: 0,
        e: "Ingress é um objeto que define regras de roteamento HTTP/HTTPS para Services internos baseado em hostname ou path. Requer um Ingress Controller (Nginx, Traefik, ALB). Centraliza TLS termination, virtual hosts e roteamento em um ponto.",
        x: "rules:\n- host: api.meuapp.com\n  http:\n    paths:\n    - path: /v1\n      backend: { service: api-v1, port: 80 }\n    - path: /v2\n      backend: { service: api-v2, port: 80 }\nTLS com cert-manager automático.",
      },
      {
        q: "No Kubernetes, o que é um Namespace e quando criar múltiplos?",
        o: [
          "Divisão lógica do cluster para isolar recursos por equipe, ambiente ou projeto",
          "Tipo de rede do Pod",
          "Volume compartilhado entre Pods",
          "Réplica do cluster inteiro",
        ],
        c: 0,
        e: "Namespaces dividem um cluster em escopos lógicos isolados. Cada namespace tem seus próprios Pods, Services, ConfigMaps. RBAC, ResourceQuotas e NetworkPolicies podem ser aplicados por namespace. Padrões: default, kube-system, kube-public.",
        x: "kubectl create namespace staging && kubectl create namespace production. Deploy no staging: kubectl apply -f app.yaml -n staging. ResourceQuota: limitar staging a 4 CPUs e 8Gi RAM para evitar consumir recursos de produção.",
      },
      {
        q: "No Kubernetes, o que é um PersistentVolumeClaim (PVC)?",
        o: [
          "Requisição de armazenamento persistente que vincula um Pod a um PersistentVolume",
          "Cache temporário do Pod",
          "Backup automático do Pod",
          "Tipo de rede persistente",
        ],
        c: 0,
        e: "PVC é uma requisição de storage que abstrai o backend de armazenamento. O PVC especifica tamanho e modo de acesso (ReadWriteOnce, ReadWriteMany). O cluster provisiona ou vincula a um PersistentVolume (PV). StorageClass permite provisionamento dinâmico.",
        x: "PVC: resources: { requests: { storage: 10Gi } }, storageClassName: 'gp3'. Pod monta o PVC: volumeMounts: [{ mountPath: '/data' }]. Se Pod reiniciar, /data persiste. AWS provisiona EBS gp3 automaticamente.",
      },
    ],
    Difícil: [
      {
        q: "Ao implementar um Service Mesh com Istio no Kubernetes, qual componente é injetado como sidecar em cada Pod para interceptar o tráfego de rede?",
        o: ["Envoy Proxy", "Pilot", "Citadel", "Galley"],
        c: 0,
        e: "O Istio injeta um proxy Envoy como sidecar container em cada Pod. O Envoy intercepta todo tráfego de entrada e saída do Pod, permitindo funcionalidades como mTLS, circuit breaking, retry, observabilidade e roteamento avançado sem alterar o código da aplicação.",
        x: "kubectl label namespace default istio-injection=enabled — todos os novos Pods no namespace recebem automaticamente o sidecar Envoy via Mutating Webhook.",
      },
      {
        q: "No Kubernetes, como o Horizontal Pod Autoscaler (HPA) funciona e quais métricas ele pode usar?",
        o: [
          "Escala automaticamente o número de Pods baseado em métricas como CPU, memória ou métricas customizadas",
          "Escala os nós do cluster",
          "Aumenta CPU dos Pods existentes",
          "Reinicia Pods com alto consumo",
        ],
        c: 0,
        e: "O HPA monitora métricas (CPU/memória via Metrics Server ou customizadas via Prometheus Adapter) e ajusta o número de réplicas do Deployment automaticamente. Verifica métricas a cada 15s (padrão) e calcula: desiredReplicas = ceil(currentReplicas × currentMetricValue / targetValue).",
        x: "apiVersion: autoscaling/v2\nspec:\n  minReplicas: 2, maxReplicas: 20\n  metrics:\n  - type: Resource\n    resource: { name: cpu, target: { type: Utilization, averageUtilization: 70 } } — escala entre 2 e 20 pods mantendo CPU média em 70%.",
      },
      {
        q: "Qual é a diferença entre Kubernetes Operators e Helm Charts para gerenciar aplicações complexas?",
        o: [
          "Operators usam controllers customizados com lógica operacional; Helm Charts são templates estáticos de manifests",
          "São idênticos",
          "Helm é mais avançado que Operators",
          "Operators substituem o kubectl",
        ],
        c: 0,
        e: "Helm Charts empacotam manifests K8s com parametrização, mas não têm lógica operacional. Operators são controladores customizados que implementam conhecimento operacional (backup, scaling, failover) usando o padrão Reconciliation Loop, reagindo automaticamente a mudanças de estado.",
        x: "Helm instala PostgreSQL, mas você faz backup manualmente. PostgreSQL Operator (Zalando) monitora o CR 'postgresql', cria réplicas, faz failover automático, agenda backups e gerencia o ciclo de vida completo.",
      },
      {
        q: "O que é um StatefulSet no Kubernetes e quando usá-lo?",
        o: [
          "Objeto para workloads stateful que requer identidade persistente, storage e ordering (ex: bancos de dados)",
          "Set de regras de firewall stateful",
          "Deployment para aplicações stateless",
          "Tipo de load balancer",
        ],
        c: 0,
        e: "StatefulSet garante: identidade estável (pod-0, pod-1), storage persistente por Pod (PVC vinculado), criação/terminadação ordenada. Ideal para bancos (PostgreSQL, MySQL), Kafka, Elasticsearch. Deployments regulares não garantem essas propriedades.",
        x: "StatefulSet 'postgres' com 3 réplicas: postgres-0 (primary), postgres-1 (replica), postgres-2 (replica). Cada um tem PVC próprio. Se postgres-1 reiniciar, reconecta ao mesmo PVC com os mesmos dados.",
      },
      {
        q: "O que é Network Policy no Kubernetes e por que é importante para segurança?",
        o: [
          "Regras que controlam comunicação de rede entre Pods, implementando microsegmentação",
          "Regras de DNS do cluster",
          "Políticas de auto-scaling",
          "Configurações de proxy",
        ],
        c: 0,
        e: "Network Policy define regras de ingress/egress entre Pods usando labels. Por padrão, todos os Pods no K8s podem se comunicar com todos (flat network). Network Policies implementam microsegmentação: só o frontend pode acessar o backend, só o backend pode acessar o banco.",
        x: "spec:\n  podSelector: { matchLabels: { app: database } }\n  ingress:\n  - from:\n    - podSelector: { matchLabels: { app: backend } }\n    ports: [{ port: 5432 }]\nApenas Pods com label app=backend podem acessar o banco na porta 5432.",
      },
      {
        q: "O que é o padrão Sidecar no Kubernetes e quais são os casos de uso comuns?",
        o: [
          "Contêiner auxiliar no mesmo Pod que complementa o contêiner principal com funcionalidades transversais",
          "Pod que roda ao lado de outro Pod",
          "Réplica de backup do contêiner principal",
          "Contêiner que substitui o principal em caso de falha",
        ],
        c: 0,
        e: "Sidecar é um contêiner auxiliar no mesmo Pod que adiciona funcionalidades sem modificar o app: proxy (Envoy/Istio), logging (fluentd), secrets injection (Vault agent), certificate rotation. Compartilham rede (localhost) e volumes com o contêiner principal.",
        x: "Pod com sidecar Vault Agent: init-container busca secrets do HashiCorp Vault → escreve em /vault/secrets/config.json → app lê o arquivo. Rotação automática: sidecar atualiza secrets a cada 5min sem restart do app.",
      },
      {
        q: "O que é o Kubernetes Gateway API e como se compara ao Ingress?",
        o: [
          "API de próxima geração mais expressiva e role-oriented que substitui gradualmente o Ingress",
          "API para gerenciar gateways VPN",
          "Versão simplificada do Ingress",
          "API exclusiva para service mesh",
        ],
        c: 0,
        e: "Gateway API é a evolução do Ingress: multi-tenant (GatewayClass → Gateway → HTTPRoute), suporta TCP/UDP/gRPC nativamente, header-based routing, traffic splitting, e políticas extensíveis. Role-oriented: infra team gerencia Gateway, dev teams criam Routes.",
        x: "HTTPRoute: matches: [{path: {value: '/api'}}, {headers: [{name: 'version', value: 'v2'}]}] → backendRefs: [{name: api-v2, weight: 80}, {name: api-v3, weight: 20}]. Canary deploy: 80% v2, 20% v3 com routing por header.",
      },
    ],
  },

  // ── DevOps e CI/CD ──
  "DevOps e CI/CD": {
    Fácil: [
      {
        q: "O que significa a sigla CI no contexto de DevOps?",
        o: [
          "Continuous Integration",
          "Continuous Inspection",
          "Code Integration",
          "Container Infrastructure",
        ],
        c: 0,
        e: "CI (Continuous Integration) é a prática de integrar código ao repositório compartilhado frequentemente, onde cada integração é verificada por builds e testes automatizados para detectar erros rapidamente.",
        x: "A cada push na branch main, o GitHub Actions executa 'npm test' e 'npm run build'. Se algum teste falhar, o desenvolvedor é notificado em minutos.",
      },
      {
        q: "O que significa CD no contexto de DevOps e quais são suas duas interpretações?",
        o: [
          "Continuous Delivery (deploy manual em produção) e Continuous Deployment (deploy automático)",
          "Code Deployment e Container Distribution",
          "Central Directory e Cloud Distribution",
          "Certified Developer e Code Design",
        ],
        c: 0,
        e: "Continuous Delivery: código é automaticamente testado e preparado para release, mas o deploy em produção requer aprovação manual. Continuous Deployment: vai além — o deploy em produção é automático após todos os testes passarem, sem intervenção humana.",
        x: "Continuous Delivery: PR mergeado → build → testes → staging automático → botão 'Deploy to Production'. Continuous Deployment: PR mergeado → build → testes → staging → produção, tudo automático.",
      },
      {
        q: "Qual ferramenta de CI/CD é integrada nativamente ao GitHub e usa arquivos YAML para definir workflows?",
        o: ["GitHub Actions", "Jenkins", "CircleCI", "Travis CI"],
        c: 0,
        e: "GitHub Actions é a plataforma de CI/CD nativa do GitHub. Workflows são definidos em arquivos YAML em .github/workflows/. Oferece runners gratuitos para projetos open-source e marketplace com milhares de actions reutilizáveis.",
        x: ".github/workflows/ci.yml: on: push → jobs: test: runs-on: ubuntu-latest, steps: checkout, setup-node, npm ci, npm test. Cada push dispara o workflow automaticamente.",
      },
      {
        q: "O que é um pipeline de CI/CD e quais são seus estágios típicos?",
        o: [
          "Fluxo automatizado: build → teste → análise → deploy, acionado por eventos como push/merge",
          "Apenas compilação automática",
          "Fluxo manual de deploy",
          "Ferramenta de versionamento",
        ],
        c: 0,
        e: "Pipeline CI/CD automatiza: 1) Build (compilar código, gerar artefato), 2) Test (unit, integração, e2e), 3) Análise (linting, SAST, coverage), 4) Publish (imagem Docker, pacote), 5) Deploy (staging, produção). Acionado por push, PR ou schedule.",
        x: "GitHub Actions pipeline: push → checkout → npm install → npm test (unit) → npm run build → docker build/push → deploy to staging → smoke tests → approve → deploy to production.",
      },
      {
        q: "O que é um artefato de build e por que é importante no CI/CD?",
        o: [
          "Resultado imutável do build (imagem Docker, JAR, ZIP) promovido entre ambientes",
          "Código-fonte versionado",
          "Log de execução do pipeline",
          "Configuração de infraestrutura",
        ],
        c: 0,
        e: "Artefato é o output imutável do build: imagem Docker, JAR, pacote npm. O MESMO artefato é promovido de dev → staging → prod para garantir que o que foi testado é exatamente o que vai para produção. Nunca rebuilde entre ambientes.",
        x: "Build gera imagem api:sha-abc123. Staging recebe api:sha-abc123, testes passam. Produção recebe api:sha-abc123 (mesma imagem, zero rebuilds). Armazenado em registry (ECR, ACR) até a próxima versão.",
      },
      {
        q: "O que é um ambiente de staging e por que é essencial no CI/CD?",
        o: [
          "Cópia do ambiente de produção para validar deploys antes de ir ao ar, reduzindo riscos",
          "Ambiente exclusivo para desenvolvimento",
          "Backup da produção",
          "Ambiente para testes unitários",
        ],
        c: 0,
        e: "Staging espelha produção: mesma infra (menor escala), mesmas configs, mesma rede. Permite executar smoke tests, testes de integração e validação manual antes do deploy real. Sem staging, bugs só aparecem em produção.",
        x: "Pipeline: build → unit tests → deploy staging → selenium e2e tests no staging → QA aprova → deploy produção. Staging encontrou bug de CORS que não apareceu nos unit tests.",
      },
      {
        q: "O que é versionamento semântico (SemVer) e como é usado no CI/CD?",
        o: [
          "Formato MAJOR.MINOR.PATCH onde cada número indica tipo de mudança (breaking, feature, fix)",
          "Numeração sequencial de builds",
          "Versão baseada em data",
          "Hash do commit",
        ],
        c: 0,
        e: "SemVer: MAJOR (breaking changes), MINOR (novas features compatíveis), PATCH (bug fixes). Ex: 2.3.1 → 2.4.0 (nova feature) → 3.0.0 (breaking change). CI/CD pode gerar versões automaticamente baseado em commits convencionais.",
        x: "Conventional Commits: 'feat: add auth' → bump minor (1.2.0 → 1.3.0). 'fix: null check' → bump patch (1.3.0 → 1.3.1). 'feat!: new API' → bump major (1.3.1 → 2.0.0). Ferramenta: semantic-release.",
      },
    ],
    Médio: [
      {
        q: "Qual estratégia de deploy envia o tráfego novo gradualmente para a nova versão enquanto mantém a versão anterior ativa?",
        o: [
          "Canary Deployment",
          "Blue-Green Deployment",
          "Rolling Update",
          "Recreate",
        ],
        c: 0,
        e: "No Canary Deployment, uma pequena porcentagem do tráfego (ex.: 5%) é direcionada à nova versão. Métricas são monitoradas e, se tudo estiver saudável, o tráfego é aumentado gradualmente até 100%. Permite rollback rápido.",
        x: "Envie 5% do tráfego para v2.0 via Ingress weight. Monitore taxa de erros por 30 min. Se erro < 0.1%, aumente para 25%, 50%, 100%.",
      },
      {
        q: "O que é Blue-Green Deployment e como funciona o rollback?",
        o: [
          "Mantém dois ambientes idênticos (blue/green) e alterna o tráfego entre eles; rollback é instantâneo",
          "Deploy em duas regiões geográficas",
          "Deploy em horários alternados",
          "Deploy com duas branches Git",
        ],
        c: 0,
        e: "No Blue-Green, o ambiente Blue roda a versão atual e Green é preparado com a nova versão. Após testes no Green, o roteador/load balancer muda todo o tráfego de Blue para Green instantaneamente. Se houver problemas, o rollback é imediato: basta apontar de volta para Blue.",
        x: "Blue (v1.0) recebendo tráfego → Deploy v2.0 no Green → Testar Green internamente → Alterar DNS/ALB para Green → Green agora recebe todo tráfego → Se erro: alterar de volta para Blue em segundos.",
      },
      {
        q: "No conceito de Infrastructure as Code, qual é a diferença entre abordagem declarativa e imperativa?",
        o: [
          "Declarativa descreve o estado desejado; imperativa descreve os passos para alcançá-lo",
          "São a mesma coisa",
          "Imperativa é mais moderna",
          "Declarativa exige mais código",
        ],
        c: 0,
        e: "Declarativa (Terraform, CloudFormation): você define QUAL é o estado final desejado e a ferramenta calcula como chegar lá. Imperativa (scripts bash, AWS CLI): você define os PASSOS exatos para executar. Declarativa é idempotente por natureza; imperativa precisa de lógica de verificação.",
        x: "Declarativo: 'quero 3 instâncias t3.large' → Terraform verifica que existem 2 e cria mais 1. Imperativo: 'crie 1 instância t3.large' → se rodar 3 vezes, cria 3 extras (total 5).",
      },
      {
        q: "O que é o conceito de 'imutable infrastructure' e como se aplica ao deploy?",
        o: [
          "Servidores nunca são modificados após criação; novas versões substituem instâncias antigas",
          "Infraestrutura que não pode ser destruída",
          "Configuração que não muda com scale",
          "Uso de hardware dedicado",
        ],
        c: 0,
        e: "Infraestrutura imutável: em vez de SSH + atualizar servidor (mutável, configuration drift), crie nova imagem com a nova versão e substitua as instâncias antigas. Garante consistência: toda instância é idêntica, testada e reproduzível.",
        x: "Mutável: SSH → apt upgrade → restart (cada servidor pode ficar diferente). Imutável: Packer cria AMI v2.0 → ASG launch template atualizado → rolling update substitui instâncias v1.0 por v2.0.",
      },
      {
        q: "O que é um rollback automático no CI/CD e quando ele é acionado?",
        o: [
          "Reverte automaticamente para a versão anterior quando health checks ou testes pós-deploy falham",
          "Restauração manual de backup",
          "Desfazer commit no Git",
          "Reiniciar o pipeline",
        ],
        c: 0,
        e: "Rollback automático: após deploy, smoke tests ou health checks monitoram a nova versão. Se erros ultrapassarem threshold (ex: error rate > 5%), o sistema reverte automaticamente para a versão anterior. Kubernetes faz nativamente via Deployment rollout undo.",
        x: "Kubernetes: kubectl rollout undo deployment/api. AWS CodeDeploy: se health check falhar, reverte automaticamente para a TaskDefinition anterior. ArgoCD: auto-sync volta para o commit anterior no Git.",
      },
      {
        q: "O que é o padrão GitFlow e quando ele é apropriado?",
        o: [
          "Modelo de branching com branches main, develop, feature, release e hotfix para releases planejadas",
          "Workflow de deploy contínuo",
          "Ferramenta de merge automático",
          "Sistema de code review",
        ],
        c: 0,
        e: "GitFlow: main (produção), develop (integração), feature/* (funcionalidades), release/* (preparação), hotfix/* (correções urgentes). Ideal para releases planejadas com versões. Para deploys contínuos, trunk-based development é mais adequado.",
        x: "GitFlow: feature/login → merge develop → release/2.0 (testes) → merge main + tag v2.0 → deploy. Trunk-based: commit direto na main com feature flags, deploy contínuo. GitFlow: apps mobile. Trunk: SaaS web.",
      },
      {
        q: "O que é um smoke test e onde ele se encaixa no pipeline?",
        o: [
          "Teste rápido pós-deploy que verifica se funcionalidades críticas estão operacionais",
          "Teste de estresse",
          "Teste unitário",
          "Análise estática de código",
        ],
        c: 0,
        e: "Smoke test: após deploy em staging/produção, verifica rapidamente se o sistema está funcional (health check, login, operações críticas). Não é exaustivo — se smoke falhar, rollback imediato. Geralmente < 2 minutos.",
        x: "Smoke test pós-deploy: 1) GET /health → 200? 2) POST /auth/login → token válido? 3) GET /api/users → resposta < 500ms? Se qualquer falhar → rollback automático → alerta no Slack.",
      },
    ],
    Difícil: [
      {
        q: "No GitOps com ArgoCD, o que acontece quando o estado do cluster Kubernetes diverge do estado declarado no repositório Git?",
        o: [
          "O ArgoCD detecta o drift e pode sincronizar automaticamente para restaurar o estado desejado",
          "O cluster sobrescreve o repositório Git",
          "O ArgoCD ignora a divergência até o próximo push",
          "O deploy é pausado indefinidamente",
        ],
        c: 0,
        e: "O ArgoCD monitora continuamente o estado do cluster e compara com o estado declarado no Git. Quando detecta drift (divergência), marca a aplicação como 'OutOfSync'. Com auto-sync habilitado, aplica automaticamente as correções; sem auto-sync, aguarda aprovação manual.",
        x: "Alguém edita um Deployment via kubectl direto. O ArgoCD detecta que 'replicas: 5' no cluster difere de 'replicas: 3' no Git e reverte automaticamente para 3.",
      },
      {
        q: "O que é um pipeline multistage com ambientes de staging, QA e produção, e como gates de aprovação funcionam?",
        o: [
          "Pipeline que promove artefatos entre ambientes sequenciais, com gates manuais ou automáticos entre stages",
          "Pipeline que roda testes em paralelo",
          "Pipeline que faz deploy em múltiplas regiões simultaneamente",
          "Pipeline exclusivo para microserviços",
        ],
        c: 0,
        e: "Um pipeline multistage promove o mesmo artefato (imagem Docker, pacote) por ambientes: Dev → QA → Staging → Prod. Gates são checkpoints entre stages: manuais (aprovação humana) ou automáticos (métricas de qualidade, testes de integração, security scans).",
        x: "Stage 1 (Dev): build + unit tests → Stage 2 (QA): integration tests + security scan (gate automático: coverage > 80%) → Stage 3 (Staging): smoke tests → Gate manual: gerente aprova → Stage 4 (Prod): deploy canary → full rollout.",
      },
      {
        q: "O que é o conceito de 'Shift Left' em segurança no pipeline CI/CD?",
        o: [
          "Mover verificações de segurança para etapas iniciais do desenvolvimento, antes do deploy",
          "Mover o deploy para a esquerda da tela",
          "Usar branches da esquerda antes",
          "Fazer rollback automático",
        ],
        c: 0,
        e: "Shift Left Security (DevSecOps) significa integrar verificações de segurança desde o início do ciclo de desenvolvimento: análise estática de código (SAST), análise de dependências vulneráveis (SCA), secrets scanning e container image scanning no pipeline CI, antes que código inseguro chegue a produção.",
        x: "Pipeline CI com Shift Left: 1) Pre-commit: detect-secrets + eslint-security. 2) Build: Snyk SCA (dependências). 3) Test: SAST com SonarQube. 4) Image: Trivy scan na imagem Docker. Vulnerabilidade crítica = pipeline falha.",
      },
      {
        q: "O que é Feature Flag (Feature Toggle) e como se usa no CI/CD?",
        o: [
          "Mecanismo para ativar/desativar funcionalidades em produção sem redeploy, controlado por configuração",
          "Branch de feature no Git",
          "Flag de compilação condicional",
          "Tipo de teste automatizado",
        ],
        c: 0,
        e: "Feature flags permitem deploy de código novo desabilitado e ativá-lo gradualmente (por usuário, %, região) sem redeploy. Desacopla deploy de release. Ferramentas: LaunchDarkly, Unleash, AWS AppConfig, Azure App Configuration.",
        x: "if (featureFlags.isEnabled('novo-checkout', { userId })) { renderNewCheckout(); } else { renderOldCheckout(); } — ativa novo checkout para 10% dos usuários, monitora, escala para 100%.",
      },
      {
        q: "O que é um postmortem (post-incident review) e por que é importante em DevOps?",
        o: [
          "Análise sem culpa após incidente para identificar causas raiz e prevenir recorrência",
          "Autopásia médica",
          "Revisão de código",
          "Teste de carga",
        ],
        c: 0,
        e: "Postmortem (blameless): após incidente, documenta timeline, causa raiz, impacto, resposta e action items preventivos. Cultura blameless foca em SISTEMAS, não em pessoas. Google SRE: postmortem obrigatório para incidentes que afetam SLO.",
        x: "Template: Data, Duração, Impacto (2000 usuários), Timeline, Causa raiz (deploy sem feature flag), Ações (adicionar canary deploy, melhorar alertas). Compartilhado com toda a empresa para aprendizado.",
      },
      {
        q: "O que é o padrão de Progressive Delivery e como vai além do canary deploy?",
        o: [
          "Combina canary, feature flags, análise automática de métricas e rollback automático em um fluxo unificado",
          "Deploy progressivo por região geográfica",
          "Deploy incremental de microserviços",
          "Pipeline com aprovação em cada stage",
        ],
        c: 0,
        e: "Progressive Delivery: canary deploy + análise automática de métricas (Kayenta/Flagger) + rollback automático. O sistema decide matematicamente se a nova versão é melhor que a atual baseado em SLIs. Ferramentas: Argo Rollouts, Flagger, Spinnaker.",
        x: "Argo Rollouts: deploy canary 10% → análise por 5 min (p99 < 200ms? error rate < 1%?) → aprovado → 30% → análise → 60% → 100%. Se métrica degradar em qualquer step → rollback automático.",
      },
      {
        q: "O que é o conceito de 'Chaos Engineering' e como ele melhora a resiliência?",
        o: [
          "Prática de introduzir falhas controladas em produção para validar resiliência do sistema",
          "Testes de estresse em staging",
          "Debugging de bugs aleatórios",
          "Redesenho de arquitetura após incidentes",
        ],
        c: 0,
        e: "Chaos Engineering (Netflix Simian Army): injeta falhas controladas (matar instâncias, latência de rede, falha de AZ) em produção para validar hipóteses de resiliência. Princípio: se você não testa falhas, falhas te testam. Ferramentas: Chaos Monkey, Litmus, Gremlin.",
        x: "Experimento: 'Se matarmos 50% dos pods do serviço de pagamento, o circuit breaker ativa e usuários veem mensagem de retry em < 3s?'. Litmus injeta pod-kill → valida SLO → documenta resultado.",
      },
    ],
  },

  // ── Google Cloud Platform ──
  "Google Cloud Platform": {
    Fácil: [
      {
        q: "Qual serviço do Google Cloud é equivalente ao Amazon S3 para armazenamento de objetos?",
        o: ["Cloud Storage", "Cloud SQL", "Compute Engine", "BigQuery"],
        c: 0,
        e: "O Google Cloud Storage é o serviço de armazenamento de objetos do GCP. Oferece classes de armazenamento (Standard, Nearline, Coldline, Archive) com durabilidade de 99,999999999% e integração nativa com outros serviços GCP.",
        x: "gsutil cp arquivo.csv gs://meu-bucket/dados/ — faz upload de um arquivo para o Cloud Storage usando a ferramenta de linha de comando gsutil.",
      },
      {
        q: "Qual serviço do GCP é equivalente ao Amazon EC2 para executar máquinas virtuais?",
        o: ["Compute Engine", "Cloud Run", "App Engine", "Cloud Functions"],
        c: 0,
        e: "O Google Compute Engine é o serviço IaaS do GCP para criar e gerenciar máquinas virtuais. Oferece tipos de máquina predefinidos e customizados, SSD local, GPUs, e integra-se com load balancers e auto-scaling gerenciados.",
        x: "gcloud compute instances create minha-vm --zone=us-central1-a --machine-type=e2-medium --image-family=debian-11 — cria uma VM Debian com 2 vCPUs e 4GB RAM.",
      },
      {
        q: "O que é o Google Cloud Run e para qual tipo de workload ele é indicado?",
        o: [
          "Plataforma serverless que executa contêineres stateless, escalando de zero automaticamente",
          "Serviço de banco de dados",
          "Ferramenta de CI/CD",
          "Serviço de CDN",
        ],
        c: 0,
        e: "Cloud Run executa contêineres Docker stateless de forma serverless. Escala automaticamente de zero (sem tráfego = sem custo) até milhares de instâncias. Aceita qualquer linguagem/framework desde que esteja em um contêiner que escute HTTP.",
        x: "gcloud run deploy meu-api --image gcr.io/meu-projeto/api:v1 --platform managed --allow-unauthenticated — deploya um contêiner que escala de 0 a 1000 instâncias automaticamente.",
      },
      {
        q: "O que é o Google Cloud Functions e como difere do Cloud Run?",
        o: [
          "FaaS que executa funções individuais acionadas por eventos; Cloud Run executa contêineres inteiros",
          "São o mesmo serviço",
          "Cloud Run é FaaS",
          "Cloud Functions roda contêineres",
        ],
        c: 0,
        e: "Cloud Functions: FaaS, escreva apenas a função, GCP gerencia todo o runtime. Triggers: HTTP, Pub/Sub, Cloud Storage, Firestore. Cloud Run: roda qualquer contêiner Docker. Funções simples → Cloud Functions. Apps complexos/multi-rota → Cloud Run.",
        x: "Cloud Function: exports.processImage = (event) => { /* thumbnail */ }. Cloud Run: Express app com 20 rotas em contêiner Docker. Ambos escalam de 0, mas Cloud Run aceita qualquer framework.",
      },
      {
        q: "O que é o Google Cloud Pub/Sub e para que serve?",
        o: [
          "Serviço de mensageria assíncrona pub/sub para comunicar serviços desacoplados",
          "Banco de dados público/privado",
          "CDN do GCP",
          "Ferramenta de CI/CD",
        ],
        c: 0,
        e: "Cloud Pub/Sub é um serviço de mensageria serverless em que publishers enviam mensagens para topics e subscribers recebem independentemente. Garante entrega at-least-once. Ideal para desacoplar microsserviços e processar eventos assíncronos.",
        x: "Publisher: pubsub.topic('pedidos').publishMessage({ json: { pedidoId: 123 } }). Subscriptions: sub-pagamentos (push para Cloud Run), sub-email (pull por Cloud Function), sub-analytics (BigQuery subscription direta).",
      },
      {
        q: "O que é o Firebase e como se relaciona com o GCP?",
        o: [
          "Plataforma de desenvolvimento de apps móveis/web que roda sobre infraestrutura do GCP",
          "Serviço de email do Google",
          "Alternativa ao GCP",
          "Banco de dados relacional",
        ],
        c: 0,
        e: "Firebase é uma plataforma BaaS (Backend as a Service) do Google para apps móveis e web. Oferece Auth, Firestore (NoSQL), Realtime Database, Cloud Storage, Hosting, Cloud Functions e Analytics. Roda sobre infra GCP e compartilha projeto com console GCP.",
        x: "App React Native: Firebase Auth (login social), Firestore (dados real-time), Cloud Storage (imagens), Cloud Functions (lógica backend). Mesmo projeto acessível no console Firebase e GCP.",
      },
      {
        q: "O que é o Google Cloud VPC (Virtual Private Cloud)?",
        o: [
          "Rede virtual privada global que conecta recursos GCP com isolação e controle de tráfego",
          "VPN para acessar o Google",
          "Serviço de CDN",
          "Banco de dados em nuvem privada",
        ],
        c: 0,
        e: "VPC no GCP é global por padrão (subnets são regionais). Recursos em regiões diferentes na mesma VPC se comunicam via rede interna do Google. Firewall rules, Cloud NAT, Cloud Router e VPC peering controlam o tráfego.",
        x: "VPC 'producao' com subnet us-central1 (10.0.1.0/24) e subnet southamerica-east1 (10.0.2.0/24). VMs nas duas regiões se comunicam internamente sem exposição à internet. Firewall: allow tcp:443 de 0.0.0.0/0.",
      },
    ],
    Médio: [
      {
        q: "No Google Cloud, qual serviço de data warehouse serverless permite executar queries SQL em petabytes de dados?",
        o: ["BigQuery", "Cloud Spanner", "Dataflow", "Dataproc"],
        c: 0,
        e: "O BigQuery é o data warehouse analítico serverless do GCP. Usa armazenamento colunar e processamento massivamente paralelo para executar queries SQL em petabytes de dados em segundos. Cobrança por volume de dados processados.",
        x: "SELECT user_id, COUNT(*) FROM `projeto.dataset.eventos` WHERE data > '2025-01-01' GROUP BY user_id — processa 2TB de dados em ~15 segundos.",
      },
      {
        q: "No GCP, qual é a diferença entre Cloud SQL e Cloud Spanner?",
        o: [
          "Cloud SQL é regional com réplicas limitadas; Cloud Spanner é globalmente distribuído com consistência forte",
          "São o mesmo serviço",
          "Cloud Spanner é NoSQL",
          "Cloud SQL é global e Spanner regional",
        ],
        c: 0,
        e: "Cloud SQL é um serviço gerenciado para MySQL, PostgreSQL e SQL Server, ideal para aplicações regionais (single-region com read replicas). Cloud Spanner é um banco relacional distribuído globalmente com consistência forte, escala horizontal ilimitada e SLA de 99.999%.",
        x: "Blog pessoal: Cloud SQL PostgreSQL (~$50/mês). Sistema bancário global que precisa de consistência ACID entre continentes: Cloud Spanner ($$$). Spanner escala horizontalmente mantendo transações distribuídas.",
      },
      {
        q: "O que é o Google Kubernetes Engine (GKE) Autopilot e como difere do GKE Standard?",
        o: [
          "Autopilot gerencia nós automaticamente e cobra por Pod; Standard dá controle total dos nós",
          "São idênticos",
          "Standard é mais novo",
          "Autopilot não suporta GPUs",
        ],
        c: 0,
        e: "GKE Autopilot: Google gerencia nós, auto-scaling, segurança e configuração. Cobra por recursos (CPU/memória) dos Pods. GKE Standard: você gerencia node pools, escolhe tipos de máquina e configura auto-scaling. Mais controle, mas mais responsabilidade operacional.",
        x: "Autopilot: defina apenas os Pods (requests: cpu: 500m, memory: 512Mi) e o GKE provisiona nós automaticamente. Standard: crie node pool com n2-standard-4, configure cluster autoscaler min=2 max=10.",
      },
      {
        q: "O que é o Google Cloud IAM e como funciona o modelo de permissões?",
        o: [
          "Gerenciamento de acesso baseado em roles (RBAC) que vincula member + role + resource",
          "Firewall do GCP",
          "Serviço de criptografia",
          "Auditoria de logs",
        ],
        c: 0,
        e: "GCP IAM usa o modelo: Member (quem: usuário, service account, grupo) + Role (o quê: conjunto de permissões) + Resource (onde: projeto, pasta, org). Roles: Basic (Owner/Editor/Viewer), Predefined (ex: roles/storage.objectViewer) e Custom.",
        x: "gcloud projects add-iam-policy-binding meu-projeto --member='serviceAccount:app@meu-projeto.iam' --role='roles/storage.objectViewer' — app só pode ler objetos do Storage, nada mais.",
      },
      {
        q: "O que são Service Accounts no GCP e quando usá-las?",
        o: [
          "Identidades para aplicações e serviços se autenticarem sem credenciais de usuário",
          "Contas compartilhadas para equipes",
          "Contas de faturamento",
          "Grupos de usuários",
        ],
        c: 0,
        e: "Service Accounts são identidades não-humanas para apps, VMs e serviços. Geram tokens automaticamente (sem senha). Cada recurso GCP pode ter uma SA associada com roles mínimas. Evitam usar credenciais pessoais em automações.",
        x: "Cloud Run com SA 'api-sa': role storage.objectCreator (upload) + role bigquery.dataEditor (queries). A app autentica automaticamente sem chaves JSON exportadas (Workload Identity).",
      },
      {
        q: "O que é o Cloud Build no GCP e como funciona como CI/CD?",
        o: [
          "Serviço serverless de CI/CD que executa builds, testes e deploys definidos em YAML",
          "Compilador de código Go exclusivo",
          "IDE online do GCP",
          "Ferramenta de IaC",
        ],
        c: 0,
        e: "Cloud Build é CI/CD serverless do GCP. Define steps em cloudbuild.yaml: build Docker image, executar testes, push para Artifact Registry, deploy no Cloud Run/GKE. Triggers: push Git, tag, PR. Integra com GitHub, Bitbucket e Cloud Source Repos.",
        x: "cloudbuild.yaml: steps: [{name: node:18, args: ['npm','test']}, {name: gcr.io/cloud-builders/docker, args: ['build','-t','gcr.io/$PROJECT_ID/api']}]. Trigger: push na main → build+test+deploy automático.",
      },
      {
        q: "O que é o Google Cloud Armor e para que serve?",
        o: [
          "Serviço de WAF e proteção DDoS para aplicações atrás de Load Balancers",
          "Antivírus para VMs",
          "Criptografia de discos",
          "Firewall de rede L4",
        ],
        c: 0,
        e: "Cloud Armor é WAF (Web Application Firewall) + proteção DDoS do GCP. Integra-se com HTTP(S) Load Balancer. Regras personalizadas: bloquear IPs, geo-blocking, rate limiting, regras OWASP Top 10 pré-configuradas. Adaptive Protection usa ML para detectar ataques.",
        x: "Security policy: deny(403) se origin.region == 'CN' || 'RU'. Rate limit: max 100 req/min por IP. OWASP: bloquear SQL injection e XSS automaticamente. Adaptive Protection: detecta e mitiga DDoS L7 em < 1 min.",
      },
    ],
    Difícil: [
      {
        q: "No Google Cloud Spanner, como o protocolo TrueTime permite transações distribuídas globais com consistência externa?",
        o: [
          "Usa relógios atômicos e GPS para criar timestamps com margem de erro conhecida, permitindo ordenação global sem bloqueios",
          "Usa consenso Paxos puro sem relógios",
          "Replica dados com eventual consistency",
          "Depende de NTP padrão para sincronizar nós",
        ],
        c: 0,
        e: "O Cloud Spanner usa o TrueTime API que combina relógios atômicos e receptores GPS em cada datacenter para fornecer intervalos de tempo com margem de incerteza conhecida. Isso permite atribuir timestamps globalmente consistentes a transações distribuídas, garantindo serialização sem locks globais.",
        x: "Uma transação no Spanner recebe timestamp T=[t1, t2] com incerteza de ~7ms. O Spanner espera a incerteza passar antes de confirmar, garantindo que nenhuma outra transação possa receber timestamp sobreposto.",
      },
      {
        q: "No GCP, como o Anthos permite gerenciar clusters Kubernetes em ambientes multi-cloud e on-premises?",
        o: [
          "Plataforma unificada que estende GKE para AWS, Azure e on-premises com políticas consistentes via Config Management",
          "Apenas migra VMs para GCP",
          "Ferramenta de backup multi-cloud",
          "CDN distribuída entre clouds",
        ],
        c: 0,
        e: "Anthos é a plataforma de aplicações multi-cloud do Google. Permite rodar clusters Kubernetes gerenciados no GCP (GKE), on-premises (Anthos on VMware/bare metal), AWS e Azure. Anthos Config Management sincroniza políticas via GitOps, e Anthos Service Mesh fornece observabilidade e segurança uniforme.",
        x: "Cluster GKE no GCP + cluster Anthos on-premises + cluster Anthos na AWS. Anthos Config Management aplica NetworkPolicy e RBAC idênticos nos 3 clusters via repositório Git centralizado.",
      },
      {
        q: "No BigQuery, o que são tabelas particionadas e clusterizadas e como elas otimizam custo e performance?",
        o: [
          "Particionamento divide dados por coluna (ex: data); clustering ordena dentro da partição, ambos reduzem volume processado",
          "São índices tradicionais",
          "Particionamento é para backup",
          "Clustering replica dados entre regiões",
        ],
        c: 0,
        e: "Particionamento divide a tabela em segmentos por uma coluna (tipicamente data), permitindo que queries filtrem apenas partições relevantes. Clustering ordena os dados dentro de cada partição por até 4 colunas. Juntos, reduzem drasticamente o volume de bytes processados (= menor custo e mais velocidade).",
        x: "CREATE TABLE eventos PARTITION BY DATE(timestamp) CLUSTER BY user_id, country. Query 'WHERE date = 2025-01-15 AND country = BR' escaneia apenas 1 partição e os blocos do cluster 'BR', processando 1GB em vez de 500GB.",
      },
      {
        q: "O que é o Google Cloud Dataflow e quando usá-lo?",
        o: [
          "Serviço gerenciado baseado em Apache Beam para processamento batch e stream de dados",
          "Ferramenta de transferência de arquivos",
          "CDN para streaming de vídeo",
          "Banco de dados de fluxo",
        ],
        c: 0,
        e: "Dataflow é um serviço de processamento de dados (batch e streaming) baseado no Apache Beam. Tem auto-scaling de workers, exatamente-uma-vez para streaming e integração nativa com Pub/Sub, BigQuery e Cloud Storage.",
        x: "Pipeline Beam: ReadFromPubSub (eventos) → Window (janelas de 5 min) → GroupByKey → Aggregate → WriteToBigQuery. Dataflow escala workers automaticamente conforme volume de eventos.",
      },
      {
        q: "O que é o principío de consistorial forte do Cloud Spanner e como afeta o design de aplicação?",
        o: [
          "Toda leitura retorna o dado mais recente em qualquer réplica global, simplificando o design",
          "Dados podem estar desatualizados por minutos",
          "Consistência apenas na região primária",
          "Requer cache local para consistência",
        ],
        c: 0,
        e: "Cloud Spanner garante consistência externa (strongest form): qualquer leitura em qualquer região retorna o valor mais recente. Elimina complexidade de eventual consistency no código. Trade-off: latência de escrita ligeiramente maior (espera TrueTime) e custo elevado.",
        x: "Transferência bancária entre contas em continentes diferentes: Spanner garante que ambos os saldos são atualizados atomicamente com consistência global. Com DynamoDB eventual, precisaria de lógica de reconciliação no código.",
      },
      {
        q: "O que é o VPC Service Controls no GCP e qual problema de segurança ele resolve?",
        o: [
          "Perímetro de segurança que impede exfiltração de dados de serviços GCP mesmo com credenciais válidas",
          "Firewall de rede para VMs",
          "VPN entre VPCs",
          "Antivírus para Cloud Storage",
        ],
        c: 0,
        e: "VPC Service Controls cria perímetros de segurança ao redor de serviços GCP (BigQuery, Cloud Storage, etc.). Mesmo com credenciais IAM válidas, operações que cruzam o perímetro são bloqueadas. Previne exfiltração: dados não podem ser copiados para projetos fora do perímetro.",
        x: "Perímetro inclui projeto-prod (BigQuery + Storage). Usuário com role bigquery.admin tenta: bq cp dataset projeto-externo:dataset → BLOQUEADO pelo perímetro. Dados não saem mesmo com permissão IAM.",
      },
      {
        q: "O que são Cloud Interconnect e Cloud VPN e quando usar cada um?",
        o: [
          "Interconnect é conexão física dedicada de alta largura de banda; VPN é túnel criptografado pela internet",
          "São o mesmo serviço",
          "VPN é mais rápido que Interconnect",
          "Interconnect é gratuito",
        ],
        c: 0,
        e: "Dedicated Interconnect: conexão física 10/100 Gbps entre datacenter on-prem e GCP, latência baixa e previsível. Partner Interconnect: via provedor para 50 Mbps-50 Gbps. Cloud VPN: túnel IPsec pela internet, até 3 Gbps por túnel, setup rápido.",
        x: "Hospital com 500TB de dados: Dedicated Interconnect 10 Gbps para transferência diária ao BigQuery. Startup com 10 devs remotos: Cloud VPN HA (2 túneis, 99.99% SLA) para acessar recursos na VPC. Custo vs performance.",
      },
    ],
  },

  // ── Infrastructure as Code ──
  "Infrastructure as Code": {
    Fácil: [
      {
        q: "Qual ferramenta de Infrastructure as Code usa a linguagem declarativa HCL para provisionar recursos em múltiplos provedores de nuvem?",
        o: ["Terraform", "Ansible", "Chef", "Puppet"],
        c: 0,
        e: "O Terraform, da HashiCorp, usa a linguagem HCL (HashiCorp Configuration Language) para definir infraestrutura de forma declarativa. Suporta múltiplos provedores (AWS, Azure, GCP) através de plugins chamados providers.",
        x: 'resource "aws_instance" "web" { ami = "ami-0c55b159" instance_type = "t3.micro" } — cria uma instância EC2 com Terraform usando HCL.',
      },
      {
        q: "Qual ferramenta de IaC é focada em gerenciamento de configuração (instalar pacotes, configurar serviços) em vez de provisionamento de infraestrutura?",
        o: ["Ansible", "Terraform", "CloudFormation", "Pulumi"],
        c: 0,
        e: "Ansible usa YAML (playbooks) para automatizar configuração de servidores: instalar pacotes, copiar arquivos, reiniciar serviços. É agentless (conecta via SSH). Terraform provisiona infraestrutura (VMs, redes); Ansible as configura. Frequentemente usados juntos.",
        x: "Terraform cria 3 VMs na AWS. Ansible configura cada uma: instala Nginx, copia o app, configura SSL e reinicia o serviço. Playbook: hosts: webservers, tasks: [apt: name=nginx, copy: src=app/ dest=/var/www/].",
      },
      {
        q: "O que é o AWS CloudFormation e como ele se compara ao Terraform?",
        o: [
          "Serviço nativo da AWS para provisionar recursos via templates JSON/YAML; Terraform é multi-cloud",
          "São idênticos",
          "CloudFormation é multi-cloud",
          "Terraform é exclusivo AWS",
        ],
        c: 0,
        e: "CloudFormation é o IaC nativo da AWS que usa templates JSON ou YAML para provisionar recursos. Vantagem: integração profunda com AWS (drift detection, rollback automático). Desvantagem: exclusivo AWS. Terraform é multi-cloud mas requer gerenciamento externo do state.",
        x: "CloudFormation template: Resources: MinhaVM: Type: AWS::EC2::Instance, Properties: InstanceType: t3.micro, ImageId: ami-xxx. Deploy: aws cloudformation create-stack --stack-name prod --template-body file://template.yaml.",
      },
      {
        q: "O que é o Bicep do Azure e como se compara ao ARM Templates?",
        o: [
          "Linguagem declarativa simplificada que compila para ARM Templates JSON",
          "Linguagem de programação general-purpose",
          "Substituição do Terraform",
          "Ferramenta de CI/CD",
        ],
        c: 0,
        e: "Bicep é uma DSL que simplifica a escrita de ARM Templates. Sintaxe concisa (sem JSON verboso), módulos reutilizáveis e validação em tempo de autoria. Compila para ARM JSON transparentemente. Suporte nativo da Microsoft.",
        x: "resource storageAccount 'Microsoft.Storage/storageAccounts@2023-01-01' = { name: 'meuStorage', location: 'brazilsouth', kind: 'StorageV2', sku: { name: 'Standard_LRS' } } — muito mais limpo que ARM JSON equivalente.",
      },
      {
        q: "O que é GitOps e como ele se relaciona com Infrastructure as Code?",
        o: [
          "Usar Git como fonte única de verdade para infraestrutura e deploy, com sincronização automática",
          "Usar GitHub para hospedar código",
          "Ferramenta de versionamento",
          "CI/CD baseado em Jenkins",
        ],
        c: 0,
        e: "GitOps: todo estado desejado (infra, configs, apps) é declarado em Git. Um operador (ArgoCD, Flux) monitora o repositório e sincroniza automaticamente o cluster/ambiente com o estado declarado. Push-based ou pull-based. PR = change request auditado.",
        x: "Dev abre PR alterando replicas: 3 para 5 no YAML. Reviewer aprova. Merge no main. ArgoCD detecta diff e escala o deployment para 5 réplicas automaticamente. Histórico completo de mudanças no Git.",
      },
      {
        q: "O que é o Terraform e qual o conceito de 'state' (estado)?",
        o: [
          "Ferramenta de IaC que mantém um state file mapeando código aos recursos reais provisionados",
          "Editor de código para infraestrutura",
          "Serviço de cloud computing",
          "Banco de dados de configurações",
        ],
        c: 0,
        e: "Terraform usa HCL para declarar infraestrutura desejada. O state file (terraform.tfstate) mapeia cada recurso declarado ao recurso real na nuvem (com IDs, atributos). Comandos: init (setup), plan (preview), apply (executar), destroy (remover).",
        x: "terraform init → baixa provider AWS. terraform plan → '+1 S3 bucket'. terraform apply → cria o bucket. State salva: aws_s3_bucket.dados = bucket-id-abc123. Próximo plan compara state com código.",
      },
      {
        q: "O que é o CDK (Cloud Development Kit) e como difere do CloudFormation nativo?",
        o: [
          "Framework que permite definir recursos AWS usando linguagens de programação (TypeScript, Python) que compilam para CloudFormation",
          "Substituio do Terraform",
          "Ferramenta de CI/CD",
          "IDE exclusiva da AWS",
        ],
        c: 0,
        e: "AWS CDK permite escrever infraestrutura em TypeScript, Python, Java, C#. Compila para CloudFormation templates. Vantagens: constructs reutilizáveis, lógica real (loops, condicionais), autocomplete de IDE, testes unitários. Abstrações L1 (raw), L2 (opinativas) e L3 (patterns).",
        x: "const api = new apigateway.RestApi(this, 'Api'); const fn = new lambda.Function(this, 'Handler', { runtime: Runtime.NODEJS_18_X }); api.root.addMethod('GET', new apigateway.LambdaIntegration(fn)); — 3 linhas vs 150 de CloudFormation YAML.",
      },
    ],
    Médio: [
      {
        q: "No Terraform, qual comando mostra o plano de execução detalhando quais recursos serão criados, modificados ou destruídos?",
        o: [
          "terraform plan",
          "terraform apply",
          "terraform init",
          "terraform validate",
        ],
        c: 0,
        e: "O 'terraform plan' compara o estado atual (state file) com a configuração desejada e exibe um plano detalhado: recursos a criar (+), modificar (~) e destruir (-). É uma etapa de revisão antes de aplicar mudanças reais.",
        x: "terraform plan mostra: '+ aws_s3_bucket.dados will be created', '~ aws_instance.web will be updated (instance_type: t3.micro → t3.small)', '- aws_rds_instance.old will be destroyed'.",
      },
      {
        q: "No Terraform, o que é o state file e por que ele é crítico para o funcionamento correto?",
        o: [
          "Arquivo que mapeia recursos declarados no código aos recursos reais na nuvem",
          "Arquivo de log de erros",
          "Template de configuração",
          "Backup dos recursos",
        ],
        c: 0,
        e: "O terraform.tfstate é um arquivo JSON que armazena o mapeamento entre recursos declarados no código HCL e recursos reais provisionados (com IDs, atributos). O Terraform compara o state com o código para calcular o plan. Sem ele, o Terraform não sabe o que já existe.",
        x: 'State local: terraform.tfstate no disco. State remoto (recomendado em equipe): S3 + DynamoDB para locking. backend "s3" { bucket = "my-tf-state" key = "prod/terraform.tfstate" dynamodb_table = "tf-locks" }. Evita conflitos de escrita concorrente.',
      },
      {
        q: "O que são módulos no Terraform e qual problema eles resolvem?",
        o: [
          "Pacotes reutilizáveis de configuração Terraform que evitam duplicação de código",
          "Plugins de provedores de nuvem",
          "Extensões da linguagem HCL",
          "Ferramentas de teste",
        ],
        c: 0,
        e: "Módulos Terraform encapsulam grupos de recursos relacionados em pacotes reutilizáveis com variáveis de entrada e outputs. Podem ser locais (pastas) ou remotos (Terraform Registry, Git). Eliminam duplicação e padronizam infraestrutura entre projetos e equipes.",
        x: 'module "vpc" { source = "terraform-aws-modules/vpc/aws", version = "5.0.0", cidr = "10.0.0.0/16", azs = ["us-east-1a", "us-east-1b"] } — cria VPC completa com sub-redes usando módulo do Registry.',
      },
      {
        q: "O que é drift detection em Infrastructure as Code e por que é importante?",
        o: [
          "Detecção de diferenças entre o estado declarado no código e o estado real da infraestrutura",
          "Detecção de erros de sintaxe no código",
          "Monitoramento de performance",
          "Backup incremental",
        ],
        c: 0,
        e: "Drift: alguém altera a infra manualmente (console/CLI) sem atualizar o código IaC. O estado real diverge do declarado. terraform plan detecta drift. AWS Config e CloudFormation Drift Detection também detectam. Drift é perigoso pois próximo apply pode sobrescrever.",
        x: "Dev alterou security group pelo console (adicionou porta 22). terraform plan mostra: ~ security_group_rule será modificado (removendo porta 22). Prática: proibir mudanças manuais, usar apenas IaC.",
      },
      {
        q: "O que é o conceito de state locking no Terraform e por que é necessário?",
        o: [
          "Mecanismo que impede dois usuários de modificar o state file simultaneamente",
          "Criptografia do state file",
          "Lock de recursos na nuvem",
          "Bloqueio de deploys em produção",
        ],
        c: 0,
        e: "State locking impede aplicações concorrentes do Terraform que poderiam corromper o state ou criar recursos duplicados. Com backend S3, use DynamoDB para locking. Terraform Cloud tem locking nativo. Se dois devs rodarem apply simultaneamente sem lock, o state pode ficar inconsistente.",
        x: "Dev A e Dev B rodam terraform apply ao mesmo tempo sem lock — state corrompido, recursos duplicados. Com DynamoDB lock: Dev B recebe 'Error: state locked by Dev A'. Dev B espera Dev A terminar.",
      },
      {
        q: "No Terraform, o que são data sources e como diferem de resources?",
        o: [
          "Data sources consultam informações de recursos existentes sem gerenciá-los; resources criam/modificam recursos",
          "São sinônimos",
          "Data sources criam recursos somente-leitura",
          "Resources consultam dados externos",
        ],
        c: 0,
        e: "Data sources (data blocks) permitem ler informações de recursos existentes NÃO gerenciados pelo Terraform (ex: AMI mais recente, VPC existente). Resources criam e gerenciam o ciclo de vida completo. Data sources são somente leitura.",
        x: 'data "aws_ami" "ubuntu" { filter { name = "name", values = ["ubuntu/images/hvm-ssd/ubuntu-22.04-*"] } } → retorna AMI ID mais recente do Ubuntu. resource "aws_instance" { ami = data.aws_ami.ubuntu.id }.',
      },
      {
        q: "O que é o Terraform Workspace e quando usá-lo?",
        o: [
          "Permite manter múltiplos states independentes para o mesmo código (ex: dev, staging, prod)",
          "IDE integrada ao Terraform",
          "Pasta de módulos",
          "Backend de armazenamento",
        ],
        c: 0,
        e: "Workspaces criam states independentes para a mesma configuração: terraform workspace new staging → state separado. Variáveis podem mudar por workspace: instance_type = terraform.workspace == 'prod' ? 't3.large' : 't3.micro'. Alternativa: diretórios separados por ambiente.",
        x: "terraform workspace new dev → terraform apply (cria infra dev com t3.micro). terraform workspace select prod → terraform apply (cria infra prod com t3.large). Dois states separados, mesmo código.",
      },
    ],
    Difícil: [
      {
        q: "No Terraform, qual é a diferença funcional entre 'terraform import' e configurar um bloco 'import' no código HCL (Terraform 1.5+)?",
        o: [
          "O CLI import apenas atualiza o state; o bloco import também gera o código HCL do recurso automaticamente",
          "Não há diferença",
          "O bloco import é mais lento",
          "O CLI import gera código e o bloco não",
        ],
        c: 0,
        e: "O comando 'terraform import' (CLI) adiciona o recurso existente ao state file, mas você precisa escrever o bloco resource manualmente. A partir do Terraform 1.5, o bloco 'import' no HCL permite importar e gerar o código de configuração automaticamente via 'terraform plan -generate-config-out=generated.tf'.",
        x: 'import { to = aws_s3_bucket.existente, id = "meu-bucket" } — no próximo plan com -generate-config-out, o Terraform gera o bloco resource completo com todos os atributos do bucket existente.',
      },
      {
        q: "O que é Terraform Cloud/Enterprise e quais problemas ele resolve em equipes?",
        o: [
          "Plataforma SaaS que centraliza state, gerencia runs concorrentes e adiciona workflow de aprovação",
          "IDE para escrever HCL",
          "CDN para distribuição de state",
          "Ferramenta de teste unitário",
        ],
        c: 0,
        e: "Terraform Cloud centraliza: state remoto com locking automático, runs remotos (plan/apply no servidor), políticas Sentinel (policy as code), workspace por ambiente, VCS integration (GitHub/GitLab), e workflow de aprovação para applies. Elimina problemas de state local em equipes.",
        x: "Fluxo: dev faz PR no GitHub → Terraform Cloud executa plan automaticamente → reviewer vê o plan na PR → aprova → TFC executa apply → state atualizado centralmente. Sentinel verifica: 'toda instância DEVE ter tag Environment'.",
      },
      {
        q: "O que é Pulumi e como sua abordagem difere fundamentalmente do Terraform?",
        o: [
          "Usa linguagens de programação reais (TypeScript, Python, Go) em vez de DSL dedicada como HCL",
          "Usa YAML exclusivamente",
          "É exclusivo para Azure",
          "Não gerencia state",
        ],
        c: 0,
        e: "Pulumi permite definir infraestrutura usando linguagens genéricas: TypeScript, Python, Go, C#, Java. Vantagens sobre HCL: loops nativos, condições complexas, testes unitários com frameworks padrão, autocomplete de IDE, abstracões orientadas a objeto. Também gerencia state (Pulumi Cloud ou self-hosted).",
        x: "import * as aws from '@pulumi/aws';\nconst bucket = new aws.s3.Bucket('meu-bucket', { acl: 'private' });\nexport const bucketName = bucket.id; — TypeScript real ao invés de HCL. Pode usar for loops, classes, funções.",
      },
      {
        q: "O que é o Packer da HashiCorp e como complementa o Terraform?",
        o: [
          "Ferramenta que cria imagens de máquinas (AMIs, VM images) automáticas e reproduzíveis",
          "Alternativa ao Terraform",
          "Compactador de arquivos",
          "Gerenciador de pacotes",
        ],
        c: 0,
        e: "Packer cria imagens de máquinas (AMI, Azure Image, GCE Image) automatizadas: instala pacotes, configura SO, hardening. Terraform usa essas imagens para provisionar instâncias. Juntos: Packer cria a imagem, Terraform a usa.",
        x: "Packer: instala Nginx + Node.js + app na AMI. Terraform: lança 5 instâncias EC2 com essa AMI. Atualização: Packer cria AMI v2, Terraform faz rolling update das instâncias para a nova AMI.",
      },
      {
        q: "O que é Policy as Code e como ferramentas como Sentinel e OPA implementam isso?",
        o: [
          "Definir políticas de compliance e segurança como código, validadas automaticamente no pipeline",
          "Código-fonte das políticas de privacidade",
          "Documentação de políticas em PDF",
          "Smart contracts blockchain",
        ],
        c: 0,
        e: "Policy as Code: regras de compliance/segurança escritas como código e avaliadas automaticamente. Sentinel (HashiCorp): integrada ao Terraform Cloud. OPA/Rego (open source): avalia políticas em Kubernetes, Terraform, APIs. Garante que nenhum recurso non-compliant seja criado.",
        x: "Sentinel: 'todo aws_instance deve ter tag Environment'. OPA: 'todo container deve ter limits de CPU/memória'. Se a política falhar, terraform apply é bloqueado antes de criar o recurso.",
      },
      {
        q: "O que é o Crossplane e como se diferencia do Terraform?",
        o: [
          "Framework que gerencia infraestrutura cloud como recursos Kubernetes nativos (CRDs), usando o reconciliation loop do K8s",
          "Versão do Terraform para Kubernetes",
          "Plugin do Terraform",
          "Ferramenta de monitoring",
        ],
        c: 0,
        e: "Crossplane estende o Kubernetes com CRDs para gerenciar recursos cloud (S3, RDS, VPC). Usa o reconciliation loop nativo: se alguém deletar um bucket manualmente, Crossplane recria automaticamente (self-healing). Terraform precisa de re-run manual.",
        x: "apiVersion: s3.aws.crossplane.io/v1beta1, kind: Bucket, spec: { forProvider: { region: us-east-1, acl: private } }. kubectl apply → cria bucket S3. kubectl get bucket → READY: True. Alguém deleta na console → Crossplane recria.",
      },
      {
        q: "Como funciona o teste de infraestrutura com Terratest?",
        o: [
          "Framework Go que provisiona infra real em ambiente temporário, valida e destrói automaticamente",
          "Validação de sintaxe HCL",
          "Linter para Terraform",
          "Simulador de cloud local",
        ],
        c: 0,
        e: "Terratest (Gruntwork): escreve testes em Go que executam terraform apply em conta AWS real, validam outputs e recursos (HTTP request, SSH, query), e executam terraform destroy no final. Integra com CI/CD para testar módulos antes de publicar.",
        x: "func TestWebServer(t *testing.T) { terraformOptions := { TerraformDir: './modules/web' }. defer terraform.Destroy(t, opts). terraform.InitAndApply(t, opts). url := terraform.Output(t, opts, 'url'). http_helper.HttpGetWithRetry(t, url, 200, 'Hello', 30, 5*time.Second) }.",
      },
    ],
  },

  // ── Monitoramento e Observabilidade ──
  "Monitoramento e Observabilidade": {
    Fácil: [
      {
        q: "Quais são os três pilares da observabilidade em sistemas distribuídos?",
        o: [
          "Logs, Métricas e Traces",
          "CPU, Memória e Disco",
          "Firewall, Proxy e VPN",
          "Frontend, Backend e Banco",
        ],
        c: 0,
        e: "Os três pilares da observabilidade são: Logs (registros de eventos), Métricas (medições quantitativas ao longo do tempo) e Traces (rastreamento de requisições entre serviços). Juntos, permitem entender o comportamento interno do sistema.",
        x: "Um request lento: o Trace mostra que passou por 5 microsserviços; a Métrica mostra latência p99 = 2s no serviço de pagamento; o Log do pagamento revela timeout na conexão com o banco.",
      },
      {
        q: "O que é um alerta de monitoramento e quais boas práticas para configurá-lo?",
        o: [
          "Notificação automática quando métricas ultrapassam thresholds; evitar alert fatigue",
          "Email diário com resumo de métricas",
          "Log automático de erros",
          "Dashboard atualizado em tempo real",
        ],
        c: 0,
        e: "Alertas bons são acionáveis (alguém precisa agir), urgentes e não-redundantes. Evite alert fatigue (muitos alertas irrelevantes). Use severidades (critical, warning, info). Agrupe alertas correlacionados. Alertas baseados em SLOs são mais eficazes que thresholds estáticos.",
        x: "Ruim: alerta a cada erro 500 individual (100 alertas/dia). Bom: alerta quando taxa de erro 5xx > 1% por 5 minutos (acionável, com contexto). Inclua runbook link no alerta.",
      },
      {
        q: "O que é um dashboard de observabilidade e quais informações essenciais deve conter?",
        o: [
          "Painel visual com Golden Signals, SLIs e status dos serviços em tempo real",
          "Lista de todos os servidores",
          "Histórico de deploys",
          "Organograma da equipe de SRE",
        ],
        c: 0,
        e: "Dashboard essencial: Golden Signals (latência, tráfego, erros, saturação), SLI/SLO status e error budget restante, health check dos serviços, últimos deploys. Use Grafana, Datadog ou CloudWatch Dashboards. Organize por serviço/equipe.",
        x: "Dashboard de produção: painel 1 — latência p50/p95/p99 (Prometheus). Painel 2 — error rate com SLO line (99.9%). Painel 3 — req/s por endpoint. Painel 4 — CPU/memória dos pods. Painel 5 — últimos deploys.",
      },
      {
        q: "O que é o Prometheus e para que é utilizado?",
        o: [
          "Sistema open-source de monitoramento e alertas que coleta métricas numéricas de séries temporais",
          "Banco de dados relacional",
          "Ferramenta de tracing distribuído",
          "CDN para dashboards",
        ],
        c: 0,
        e: "Prometheus coleta métricas via pull (scrape de endpoints /metrics). Armazena como time series com labels. PromQL para queries. AlertManager para notificações. Integra com Grafana para dashboards. Padrão em K8s. 4 tipos de métricas: Counter, Gauge, Histogram, Summary.",
        x: "Configuração: scrape_configs: [{job_name: 'api', static_configs: [{targets: ['api:3000']}]}]. PromQL: rate(http_requests_total{status='500'}[5m]) → taxa de erros 500 nos últimos 5 min.",
      },
      {
        q: "O que é o Grafana e como se integra com o ecossistema de observabilidade?",
        o: [
          "Plataforma de visualização que conecta múltiplas fontes de dados para criar dashboards interativos",
          "Banco de métricas",
          "Coletor de logs",
          "Sistema de alertas exclusivo",
        ],
        c: 0,
        e: "Grafana é visualização, não armazena dados. Conecta com Prometheus (métricas), Loki (logs), Tempo (traces), Elasticsearch, CloudWatch, InfluxDB. Dashboards com painéis, variáveis, alertas. Grafana Cloud oferece stack LGTM (Loki, Grafana, Tempo, Mimir).",
        x: "Dashboard Grafana: painel de métricas (Prometheus), painel de logs (Loki) com correlação temporal, link para trace (Tempo) ao clicar em um log de erro. Tudo em uma interface unificada.",
      },
    ],
    Médio: [
      {
        q: "No Prometheus, qual tipo de métrica é mais adequado para medir a duração de requisições HTTP, permitindo calcular percentis como p95 e p99?",
        o: ["Histogram", "Counter", "Gauge", "Summary"],
        c: 0,
        e: "O Histogram agrupa observações em buckets configuráveis e registra contagem e soma total. Permite calcular percentis (p50, p95, p99) no servidor Prometheus usando a função histogram_quantile(), ideal para latências.",
        x: 'http_request_duration_seconds_bucket{le="0.5"} = 900 — 900 das 1000 requisições levaram até 0.5s. histogram_quantile(0.95, ...) calcula o p95.',
      },
      {
        q: "O que são os Golden Signals definidos pelo Google SRE e quais são?",
        o: [
          "Latência, Tráfego, Erros e Saturação — 4 métricas essenciais para monitorar serviços",
          "CPU, Memória, Disco e Rede",
          "Disponibilidade, Durabilidade, Escalabilidade e Segurança",
          "Uptime, Downtime, MTTR e MTBF",
        ],
        c: 0,
        e: "Golden Signals (Google SRE Book): 1) Latência: tempo de resposta das requisições. 2) Tráfego: volume de demanda (req/s). 3) Erros: taxa de requisições que falham. 4) Saturação: quão cheio o serviço está (CPU, memória, fila). Se você monitora apenas esses 4, já tem excelente visibilidade.",
        x: "Dashboard com Golden Signals: Latência p99 = 200ms ✓, Tráfego = 1.2k req/s ✓, Erros = 0.1% ✓, Saturação CPU = 85% ⚠️. A saturação alta indica necessidade de scaling antes que afete latência.",
      },
      {
        q: "O que é distributed tracing e qual problema ele resolve em microsserviços?",
        o: [
          "Rastreamento de requisições entre múltiplos serviços, identificando gargalos na cadeia",
          "Monitoramento de CPU distribuída",
          "Backup distribuído de logs",
          "Balanceamento de carga entre traces",
        ],
        c: 0,
        e: "Distributed tracing propaga um trace ID único através de todos os serviços que processam uma requisição. Cada serviço cria spans com timestamps, permitindo visualizar a jornada completa da requisição, identificar qual serviço está lento e entender dependências. Ferramentas: Jaeger, Zipkin, Tempo.",
        x: "Trace ID abc123: API Gateway (5ms) → Auth Service (15ms) → Product Service (8ms) → Database Query (350ms) → Cache Write (2ms). Total: 380ms. Gargalo claro: query ao banco de 350ms.",
      },
      {
        q: "O que é o Grafana Loki e como difere do Elasticsearch para logs?",
        o: [
          "Sistema de logs que indexa apenas labels, mais leve e barato que Elasticsearch",
          "Fork do Elasticsearch",
          "Banco de métricas",
          "Ferramenta de tracing",
        ],
        c: 0,
        e: "Loki: indexa apenas labels (app, namespace, level), não o texto do log. Busca via LogQL similar a PromQL. Muito mais barato em armazenamento que Elasticsearch. Integração nativa com Grafana. Ideal quando já usa Prometheus+Grafana.",
        x: 'LogQL: {app="api", level="error"} |= "timeout" | json | duration > 5s — busca logs de erro da API contendo timeout onde duração > 5s. Loki armazena logs comprimidos no S3.',
      },
      {
        q: "O que é APM (Application Performance Monitoring) e quais insights fornece?",
        o: [
          "Monitoramento de performance de aplicações: latência, erros, dependências e transações",
          "Monitoramento de infraestrutura apenas",
          "Ferramenta de load testing",
          "Scanner de vulnerabilidades",
        ],
        c: 0,
        e: "APM instrumenta aplicações para rastrear cada transação: tempo de resposta, queries SQL, chamadas HTTP externas, erros com stack trace. Ferramentas: Datadog APM, New Relic, Azure Application Insights, Elastic APM, OpenTelemetry.",
        x: "Datadog APM mostra: endpoint GET /users p99=450ms. Drill down: 200ms no PostgreSQL (query N+1 detectada), 150ms em chamada HTTP para serviço de auth, 100ms processamento. Recomendação: resolver N+1.",
      },
      {
        q: "O que é log estruturado e por que é superior ao log de texto livre?",
        o: [
          "Logs em formato JSON/chave-valor que permitem filtragem e análise programática eficiente",
          "Logs organizados por data",
          "Logs em XML",
          "Logs compactados em ZIP",
        ],
        c: 0,
        e: "Log estruturado (JSON): cada campo é queryável separadamente (userId, duration, status). Log de texto livre: precisa de regex para extrair informações. Structured logging permite agregação, correlação e alertas baseados em campos específicos.",
        x: 'Texto livre: \'2025-01-15 10:30:45 ERROR Payment failed for user 123 after 450ms\'. Estruturado: {"timestamp":"2025-01-15T10:30:45Z","level":"error","msg":"Payment failed","userId":123,"duration_ms":450}. Query: level=error AND duration_ms>400.',
      },
      {
        q: "O que é o OpenTelemetry e por que está se tornando o padrão de observabilidade?",
        o: [
          "Framework open-source vendor-neutral que unifica coleta de traces, métricas e logs com SDKs padronizados",
          "Ferramenta de monitoramento da Google",
          "Substituto do Prometheus",
          "CDN para telemetria",
        ],
        c: 0,
        e: "OpenTelemetry (OTel) é o merge de OpenTracing + OpenCensus. Fornece SDKs para instrumentação (auto e manual), OTLP (protocolo padrão) e Collector (pipeline). Vendor-neutral: instrumenta uma vez, exporta para qualquer backend (Jaeger, Datadog, New Relic, Grafana).",
        x: "SDK OTel Node.js: auto-instrumenta Express, pg, Redis automaticamente. Exporta traces via OTLP para Collector → Collector envia métricas para Prometheus e traces para Tempo. Troca de backend: só muda config do Collector.",
      },
    ],
    Difícil: [
      {
        q: "No OpenTelemetry, qual é o papel do 'Collector' na arquitetura e quais são seus três componentes internos de pipeline?",
        o: [
          "Recebe, processa e exporta telemetria — Receivers, Processors e Exporters",
          "Apenas armazena dados — Storage, Index e Query",
          "Gera métricas — Generator, Filter e Display",
          "Coleta logs — Agent, Parser e Writer",
        ],
        c: 0,
        e: "O OpenTelemetry Collector é um proxy/pipeline de telemetria com três componentes: Receivers (recebem dados via OTLP, Jaeger, Prometheus), Processors (filtram, agrupam, enriquecem dados) e Exporters (enviam para backends como Jaeger, Prometheus, Datadog).",
        x: "receivers: { otlp: { protocols: { grpc: {} } } }, processors: { batch: {} }, exporters: { jaeger: { endpoint: 'jaeger:14250' } } — recebe OTLP, agrupa em batch e exporta para Jaeger.",
      },
      {
        q: "O que são SLIs, SLOs e SLAs no contexto de SRE e como se relacionam?",
        o: [
          "SLI é a métrica medida; SLO é o objetivo interno; SLA é o contrato externo com penalidades",
          "São sinônimos",
          "SLA é a métrica e SLI o contrato",
          "SLO substitui SLA",
        ],
        c: 0,
        e: "SLI (Service Level Indicator): métrica real (ex: latência p99 = 180ms). SLO (Service Level Objective): alvo interno (ex: p99 < 200ms em 99.9% do tempo). SLA (Service Level Agreement): contrato com cliente com penalidades (ex: 99.9% uptime, crédito se descumprir). Hierarquia: SLI mede, SLO define objetivo, SLA compromete.",
        x: "SLI: latência p99 nos últimos 30 dias = 185ms. SLO: p99 < 200ms → status: OK (dentro do budget). SLA: 99.9% disponibilidade → se ultrapassar 43min de downtime/mês, cliente recebe 10% de crédito.",
      },
      {
        q: "O que é error budget em SRE e como ele guia decisões entre velocidade de release e confiabilidade?",
        o: [
          "Orçamento de indisponibilidade permitido pelo SLO; quando esgotado, prioriza-se estabilidade sobre features",
          "Budget financeiro para corrigir bugs",
          "Limite de erros em logs",
          "Tempo de resposta máximo",
        ],
        c: 0,
        e: "Se o SLO é 99.9% uptime mensal, o error budget é 0.1% = ~43 minutos de downtime permitido. Enquanto houver budget, equipes podem deployar agressivamente. Quando o budget se esgota (muitos incidentes), deploys são congelados e o foco muda para confiabilidade. Política objective de trade-off velocidade vs estabilidade.",
        x: "Mês com error budget de 43 min. Dia 15: incidente consumiu 30 min. Restam 13 min. Equipe reduz frequência de deploys e foca em testes. Dia 25: segundo incidente de 15 min → budget estourado → freeze de releases + postmortem obrigatório.",
      },
      {
        q: "O que é o padrão RED (Rate, Errors, Duration) para monitoramento de microsserviços?",
        o: [
          "Método que monitora taxa de requisições, taxa de erros e duração por serviço",
          "Framework de segurança",
          "Linguagem de configuração",
          "Tipo de alerta crítico",
        ],
        c: 0,
        e: "RED (Tom Wilkie, Grafana): Rate (req/s), Errors (req com falha/s), Duration (latência). Complementa USE (Utilization, Saturation, Errors) para infraestrutura. RED para serviços request-driven; USE para recursos (CPU, disco).",
        x: "Dashboard RED do serviço de pagamentos: Rate: 500 req/s OK. Errors: 2 req/s (0.4%) OK. Duration p99: 800ms (SLO: < 500ms). Investigação: query lenta no banco após deploy v2.3.",
      },
      {
        q: "O que é observability-driven development e como impacta a engenharia?",
        o: [
          "Instrumentar observabilidade desde o desenvolvimento, não apenas após produzir o código",
          "Desenvolver dashboards antes do código",
          "Usar logs como documentação",
          "Substituir testes por monitoramento",
        ],
        c: 0,
        e: "Observability-driven: adicione métricas, logs estruturados e spans de tracing DURANTE o desenvolvimento, não como afterthought. Pergunte: como vou debugar isso em produção? OpenTelemetry facilita com SDKs idiomáticos.",
        x: "Dev adiciona: span.setAttributes({ 'payment.method': 'pix', 'payment.amount': 150.00 }); logger.info('Payment processed', { orderId, duration }); meter.counter('payments_total').add(1); — tudo instrumentado antes do merge.",
      },
      {
        q: "O que é o conceito de 'Cardinality' em métricas e por que alta cardinalidade é problemática?",
        o: [
          "Número de combinações únicas de labels; alta cardinalidade consome memória e disco excessivos no sistema de métricas",
          "Número de métricas distintas",
          "Quantidade de dashboards",
          "Frequência de scrape",
        ],
        c: 0,
        e: "Cardinalidade = combinações únicas de label values em uma métrica. http_requests{method, path, status}: 5 methods × 1000 paths × 10 status = 50.000 séries. Alta cardinalidade: Prometheus consome GBs de RAM. Solução: evitar labels de alta variação (userId, requestId).",
        x: "RUIM: http_requests_total{userId='abc123'} → 1M usuários = 1M séries → OOM do Prometheus. BOM: http_requests_total{endpoint='/api/users', method='GET', status='200'} → centenas de séries. UserID vai no trace/log, NÃO na métrica.",
      },
      {
        q: "O que é o padrão USE (Utilization, Saturation, Errors) para monitoramento de infraestrutura?",
        o: [
          "Método que monitora utilização, saturação e erros de cada recurso de hardware/software",
          "Framework de deploy",
          "Tipo de SLO",
          "Método de capacity planning",
        ],
        c: 0,
        e: "USE (Brendan Gregg): para cada recurso (CPU, memória, disco, rede): U=Utilization (% em uso), S=Saturation (fila de espera), E=Errors (falhas). Complementa RED (para serviços). USE identifica gargalos de infraestrutura; RED identifica problemas de aplicação.",
        x: "CPU: U=85% (alto), S=12 processos na run queue (saturado), E=0. Diagnóstico: CPU sobrecarregada, precisa scale up ou otimizar código. Disco: U=95%, S=await 150ms, E=3 I/O errors → disco degradando, substituir.",
      },
    ],
  },

  // ── Serverless e Functions ──
  "Serverless e Functions": {
    Fácil: [
      {
        q: "Em computação serverless, quem é responsável por gerenciar e escalar os servidores que executam o código?",
        o: [
          "O provedor de nuvem",
          "O desenvolvedor",
          "O cliente final",
          "O time de infraestrutura interno",
        ],
        c: 0,
        e: "No modelo serverless, o provedor de nuvem gerencia toda a infraestrutura: provisiona servidores, aplica patches, escala automaticamente conforme a demanda e cobra apenas pelo tempo de execução efetivo do código.",
        x: "Uma função Lambda recebe 0 requisições à noite → custo zero. Às 9h recebe 10.000 requisições → AWS escala automaticamente para várias instâncias. Você só paga pelo tempo de execução.",
      },
      {
        q: "Qual é um exemplo comum de trigger (gatilho) que pode invocar uma função serverless?",
        o: [
          "Requisição HTTP, upload de arquivo no storage ou mensagem em uma fila",
          "Reiniciar o servidor",
          "Compilar o código-fonte",
          "Criar uma máquina virtual",
        ],
        c: 0,
        e: "Funções serverless são acionadas por eventos (triggers): HTTP requests (API Gateway), uploads em storage (S3, Blob), mensagens em filas (SQS, Pub/Sub), alterações em banco (DynamoDB Streams), schedules (cron), e eventos de outros serviços.",
        x: "Usuário faz upload de foto no S3 → S3 Event Notification dispara Lambda → Lambda redimensiona a foto → salva thumbnail no S3. Tudo automático, sem servidor dedicado.",
      },
      {
        q: "Qual é a principal vantagem financeira do modelo de preço serverless?",
        o: [
          "Pagamento apenas pelo tempo de execução real (pay-per-use), sem custos com ociosidade",
          "Preço fixo mensal",
          "Desconto por volume de dados",
          "Gratuito para todos os usos",
        ],
        c: 0,
        e: "No modelo serverless, você paga por invocação e tempo de computação (ex: $0.20/1M invocações + $0.0000166667/GB-segundo no Lambda). Se a função não é invocada, o custo é zero. Em servidores tradicionais, você paga 24/7 mesmo com 5% de utilização.",
        x: "API com 100k requests/mês, 200ms cada, 256MB memória: Lambda custa ~$0.42/mês. Servidor EC2 t3.micro 24/7: ~$8.50/mês. Para workloads esporádicos, serverless é 10-20x mais barato.",
      },
      {
        q: "O que é BaaS (Backend as a Service) e como complementa o FaaS?",
        o: [
          "Serviços gerenciados de backend (auth, banco, storage) que eliminam a necessidade de servidor próprio",
          "Backup como serviço",
          "Blockchain como serviço",
          "Browser como serviço",
        ],
        c: 0,
        e: "BaaS fornece componentes de backend prontos: Firebase (auth, Firestore, Storage), Supabase (PostgreSQL, auth, storage), AWS Amplify. Combinado com FaaS (Lambda, Cloud Functions), permite criar aplicações completas sem servidor. Ideal para MVPs e apps mobile.",
        x: "App mobile com Firebase: Auth (login Google), Firestore (banco real-time), Storage (imagens), Cloud Functions (lógica de negócio). Zero servidores para gerenciar. Custo: $0 até 50k usuários no free tier.",
      },
      {
        q: "O que é o conceito de event-driven architecture em serverless?",
        o: [
          "Arquitetura onde componentes reagem a eventos assíncronos em vez de chamadas síncronas diretas",
          "Arquitetura baseada em polling contínuo",
          "Modelo request-response tradicional",
          "Arquitetura monolítica com eventos",
        ],
        c: 0,
        e: "Event-driven: produtores emitem eventos (pedido criado, arquivo salvo) e consumidores reagem independentemente. Desacoplamento total. Componentes: event source (S3, API), event router (EventBridge, SNS) e event handler (Lambda). Escala naturalmente.",
        x: "Usuário faz upload (S3 event) → Lambda gera thumbnail → publica evento 'thumbnail-created' no EventBridge → Lambda atualiza banco → Lambda envia notificação. Tudo desacoplado e independente.",
      },
      {
        q: "O que é o AWS API Gateway e como se integra com Lambda?",
        o: [
          "Serviço que cria e gerencia APIs REST/HTTP/WebSocket, encaminhando requisições para Lambda ou outros backends",
          "Gateway de rede entre VPCs",
          "CDN para APIs",
          "Banco de dados para APIs",
        ],
        c: 0,
        e: "API Gateway cria endpoints HTTP que roteiam para Lambda, HTTP backends ou serviços AWS. Oferece: throttling, caching, autorização (Cognito, Lambda authorizer), versionamento, CORS. Dois tipos: REST API (mais features) e HTTP API (mais barato e simples).",
        x: "API Gateway HTTP API: GET /users → Lambda listUsers. POST /users → Lambda createUser. Throttle: 1000 req/s. Custom domain: api.meuapp.com com certificado ACM. Custo HTTP API: $1.00/milhão de requests.",
      },
      {
        q: "O que é scale-to-zero e por que é uma característica importante do serverless?",
        o: [
          "Capacidade de reduzir instâncias a zero quando não há tráfego, eliminando custo de ociosidade",
          "Escalar para performance zero",
          "Zerar os logs do servidor",
          "Remover todos os dados",
        ],
        c: 0,
        e: "Scale-to-zero: quando não há requisições, o serviço não consome recursos (e não cobra). Ao receber tráfego, escala automaticamente. Lambda, Cloud Run e Azure Functions (Consumption) fazem isso nativamente. Trade-off: cold start na primeira requisição após ociosidade.",
        x: "API serverless às 3h da manhã: 0 instâncias, custo $0. Às 9h: pico de tráfego, escala para 100 instâncias. Às 22h: demanda cai, escala para 5. Às 2h: 0 novamente. Servidor trad: $8.50/mês 24/7.",
      },
    ],
    Médio: [
      {
        q: "O que é o problema de 'cold start' em funções serverless e qual seu impacto?",
        o: [
          "Latência extra na primeira invocação quando o runtime precisa ser inicializado",
          "Perda de dados quando a função é encerrada",
          "Erro de conexão com o banco de dados",
          "Limitação de memória da função",
        ],
        c: 0,
        e: "Cold start ocorre quando uma função serverless é invocada após período de inatividade e o provedor precisa alocar um contêiner, carregar o runtime e inicializar o código. Isso adiciona latência de 100ms a vários segundos dependendo do runtime e tamanho do pacote.",
        x: "Uma Lambda em Java com SDK AWS demora ~3s no cold start. Provisioned Concurrency mantém N instâncias quentes: aws lambda put-provisioned-concurrency-config --function-name api --qualifier prod --provisioned-concurrent-executions 10.",
      },
      {
        q: "Qual é o limite de tempo de execução (timeout) máximo de uma AWS Lambda e como isso afeta o design da aplicação?",
        o: [
          "15 minutos — processos longos devem ser divididos ou usar Step Functions",
          "30 segundos",
          "1 hora",
          "Sem limite",
        ],
        c: 0,
        e: "AWS Lambda tem timeout máximo de 15 minutos (900 segundos). Para processos mais longos, use: Step Functions para orquestração, divida em funções menores encadeadas, ou use ECS/Fargate para tarefas sem limite de tempo. Azure Functions (Consumption): 10 min (Premium: sem limite).",
        x: "Processar vídeo de 2h em uma única Lambda é impossível (>15min). Solução: Lambda 1 divide o vídeo em chunks de 5 min → Step Functions dispara N Lambdas paralelas (Map State) → Lambda final concatena os resultados.",
      },
      {
        q: "O que é o AWS SAM (Serverless Application Model) e como ele simplifica o desenvolvimento serverless?",
        o: [
          "Framework que estende CloudFormation com sintaxe simplificada para recursos serverless",
          "IDE para Lambda",
          "Linguagem de programação serverless",
          "Serviço de deploy de contêineres",
        ],
        c: 0,
        e: "AWS SAM é um framework open-source que usa templates YAML com sintaxe simplificada para definir Lambda, API Gateway, DynamoDB e outros recursos serverless. Inclui CLI para build, teste local (sam local invoke) e deploy. É transformado em CloudFormation na hora do deploy.",
        x: "template.yaml: Type: AWS::Serverless::Function, Properties: Handler: index.handler, Runtime: nodejs18.x, Events: Api: { Type: Api, Properties: { Path: /hello, Method: get } }. sam local start-api → testa localmente na porta 3000.",
      },
      {
        q: "O que é o Serverless Framework e como simplifica o desenvolvimento serverless?",
        o: [
          "Framework open-source multi-cloud para definir, deployar e gerenciar aplicações serverless via YAML",
          "SDK para Azure Functions",
          "IDE para Lambda",
          "Container runtime serverless",
        ],
        c: 0,
        e: "Serverless Framework usa serverless.yml para definir funções, eventos (HTTP, SQS, schedule) e recursos (DynamoDB, S3). Suporta AWS, Azure, GCP. Comandos: sls deploy (provisiona tudo), sls invoke (testa função), sls logs (visualiza logs).",
        x: "serverless.yml: functions: hello: handler: handler.hello, events: [httpApi: GET /hello]. process: handler: handler.process, events: [sqs: arn]. sls deploy — cria API Gateway + 2 Lambdas + vincula SQS.",
      },
      {
        q: "Quais são as limitações comuns de funções serverless que afetam o design da aplicação?",
        o: [
          "Timeout, tamanho do pacote, memória, cold start e falta de estado persistente",
          "Não suportam HTTP",
          "Não podem acessar bancos de dados",
          "Só funcionam com JavaScript",
        ],
        c: 0,
        e: "Limitações: timeout (Lambda 15min), pacote (250MB unzipped), memória (10GB max), cold start (100ms-10s), sem estado persistente (stateless), concurrency limits. Design: funções pequenas, idempotentes, stateless, com timeouts curtos.",
        x: "Lambda: max 15min, 10GB RAM, 250MB pacote. Para vídeo de 2h: divide em chunks via Step Functions. Para estado: use DynamoDB/Redis. Para conectar ao RDS: use RDS Proxy para evitar exaurir conexões.",
      },
      {
        q: "O que é o AWS EventBridge e como difere do SNS?",
        o: [
          "Barramento de eventos serverless com roteamento baseado em conteúdo, schema registry e integração SaaS",
          "São idênticos",
          "SNS é mais avançado",
          "EventBridge é para streaming",
        ],
        c: 0,
        e: "EventBridge: barramento de eventos com roteamento baseado em conteúdo (filtrar por campos do evento), schema registry, integração com SaaS (Zendesk, Shopify), archive e replay de eventos. SNS: pub/sub simples com filtering por atributos. EventBridge é a evolução.",
        x: "EventBridge rule: source='orders', detail-type='OrderCreated', detail: { amount: [{numeric: ['>', 1000]}] } → target: Lambda antifraud. Apenas pedidos > R$1000 disparam a função de antifraude.",
      },
      {
        q: "O que é o conceito de 'fan-in' em arquiteturas serverless?",
        o: [
          "Padrão onde múltiplas execuções paralelas convergem em um ponto de agregação",
          "Distribuir eventos para múltiplos consumidores",
          "Replicar funções em múltiplas regiões",
          "Comprimir payloads de eventos",
        ],
        c: 0,
        e: "Fan-in é o oposto de fan-out: múltiplas execuções paralelas produzem resultados que são agregados em um único ponto. Step Functions Map State faz fan-out (paralelo) e depois fan-in (coleta todos os resultados). SQS + batch Lambda também implementa fan-in.",
        x: "Step Functions: Map State processa 100 imagens em paralelo (fan-out). Cada Lambda retorna metadata. Após todas completarem, próximo state agrega os 100 resultados em um relatório final (fan-in).",
      },
    ],
    Difícil: [
      {
        q: "Ao projetar um sistema event-driven serverless com AWS Lambda, SQS e DynamoDB, como evitar processamento duplicado de eventos garantindo idempotência?",
        o: [
          "Armazenar um ID de idempotência no DynamoDB com conditional write antes de processar",
          "Confiar na entrega exactly-once do SQS Standard",
          "Usar timeout curtos na Lambda",
          "Desabilitar retries na fila SQS",
        ],
        c: 0,
        e: "SQS Standard pode entregar mensagens duplicadas. Para garantir idempotência, cada mensagem deve ter um ID único. Antes de processar, faça um PutItem condicional no DynamoDB com condition 'attribute_not_exists(pk)'. Se o item já existir, a mensagem já foi processada.",
        x: "const params = { TableName: 'ProcessedEvents', Item: { pk: eventId }, ConditionExpression: 'attribute_not_exists(pk)' }; try { await dynamo.put(params); await processEvent(); } catch (e) { if (e.code === 'ConditionalCheckFailedException') return; /* já processado */ }",
      },
      {
        q: "No AWS Lambda, o que é Lambda@Edge e como ela difere de CloudFront Functions?",
        o: [
          "Lambda@Edge roda em edge locations do CloudFront com mais recursos e suporte a origin request/response; CloudFront Functions são mais leves e rápidas para viewer events",
          "São idênticas",
          "CloudFront Functions têm mais recursos",
          "Lambda@Edge é mais barata",
        ],
        c: 0,
        e: "Lambda@Edge: roda nas edge locations do CloudFront, suporta Node.js/Python, até 5s (viewer) ou 30s (origin), até 10GB de memória, acesso a rede. CloudFront Functions: execução sub-milissegundo em 200+ PoPs, apenas JavaScript, até 10ms, 2MB de memória. CF Functions para manipulações simples (headers, redirects); Lambda@Edge para lógica complexa.",
        x: "CloudFront Function: adicionar header de segurança em toda response (< 1ms). Lambda@Edge: verificar autenticação JWT na origin request, fazer A/B testing com cookies, ou gerar conteúdo dinâmico no edge.",
      },
      {
        q: "Como projetar uma arquitetura serverless event-driven com fan-out pattern usando SNS + SQS + Lambda?",
        o: [
          "SNS publica evento para múltiplas filas SQS (fan-out); cada fila dispara uma Lambda consumidora independente",
          "Lambda chama Lambda diretamente",
          "SQS publica para SNS",
          "Fan-out é possível apenas com Kinesis",
        ],
        c: 0,
        e: "Padrão fan-out: SNS topic recebe um evento e distribui para múltiplas filas SQS inscritas (subscribers). Cada fila SQS tem uma Lambda consumidora independente com retry próprio e DLQ. Isso desacopla produtores e consumidores, permite processamento paralelo e independente de cada consumidor.",
        x: "Evento 'PedidoCriado' → SNS Topic → SQS-Pagamento (→ Lambda processa pagamento) + SQS-Estoque (→ Lambda atualiza estoque) + SQS-Email (→ Lambda envia confirmação). Se a Lambda de e-mail falhar, as outras não são afetadas.",
      },
      {
        q: "O que é o Knative e como ele traz serverless para o Kubernetes?",
        o: [
          "Plataforma que adiciona capacidades serverless (scale-to-zero, event-driven) ao Kubernetes",
          "Distribuição de Kubernetes",
          "Alternativa ao Docker",
          "Plugin de rede para K8s",
        ],
        c: 0,
        e: "Knative adiciona dois componentes ao K8s: Serving (scale-to-zero, revisions, traffic splitting) e Eventing (event sources, brokers, triggers). Permite experiência serverless (como Cloud Run, que é baseado em Knative) dentro do seu cluster K8s.",
        x: "apiVersion: serving.knative.dev/v1, kind: Service, spec: template: spec: containers: [{image: gcr.io/app:v1}]. Escala de 0 a N automaticamente. Traffic: 90% v1, 10% v2 para canary.",
      },
      {
        q: "O que é o conceito de connection pooling e por que é crítico em serverless?",
        o: [
          "Reutilizar conexões de banco em pool; serverless cria muitas instâncias que podem esgotar conexões",
          "Pool de threads para computação paralela",
          "Cache de requisições HTTP",
          "Agrupamento de logs",
        ],
        c: 0,
        e: "Cada instância Lambda/Function abre conexão ao banco. Com 1000 instâncias simultâneas, são 1000 conexões — PostgreSQL default max_connections=100. Solução: RDS Proxy (AWS), PgBouncer, Prisma Data Proxy — pool compartilhado entre instâncias.",
        x: "Sem proxy: 500 Lambdas x 1 conexão = 500 (RDS suporta 100 — erro). Com RDS Proxy: 500 Lambdas → proxy → 50 conexões ao RDS, reutilizando. Latência de conexão também cai com proxy.",
      },
      {
        q: "O que é o padrão Saga em arquiteturas serverless e como implementar com Step Functions?",
        o: [
          "Padrão para transações distribuídas que usa compensações (rollback) em caso de falha em qualquer etapa",
          "Backup automático de funções",
          "Cache distribuído",
          "Tipo de fila de mensagens",
        ],
        c: 0,
        e: "Saga executa uma sequência de transações locais. Se uma falhar, executa compensações (desfazer) das anteriores. Dois tipos: orchestration (Step Functions coordena) e choreography (eventos assíncronos). Substitui transações distribuídas (2PC) em microsserviços.",
        x: "Step Functions Saga: ReservarVoo → ReservarHotel → CobrarCartão. Se CobrarCartão falhar: Catch → CancelarHotel → CancelarVoo. Cada step tem compensador. State machine garante que rollback completo ocorra.",
      },
      {
        q: "O que é o conceito de 'ephemeral compute' e como afeta o design serverless?",
        o: [
          "Instâncias de computação temporárias que podem ser destruídas a qualquer momento, exigindo design stateless",
          "Computação com menor custo",
          "Servidores com uptime garantido",
          "Cache que persiste entre invocações",
        ],
        c: 0,
        e: "Em serverless, instâncias são efêmeras: criadas sob demanda, recicladas após período de inatividade. Implicações: todo estado deve ser externo (DynamoDB, S3, Redis), filesystem é temporário (/tmp, max 10GB no Lambda), conexões devem ser resilientes a reconexão.",
        x: "Lambda usa /tmp para cache local (válido apenas durante warm instances). Sessão de usuário: DynamoDB (não em memória local). Upload temporário: S3 com lifecycle policy de 24h. Variáveis de ambiente para configs.",
      },
    ],
  },

  // ── Segurança em Cloud ──
  "Segurança em Cloud": {
    Fácil: [
      {
        q: "Qual é o princípio de segurança que determina que cada usuário ou serviço deve ter apenas as permissões mínimas necessárias para realizar sua função?",
        o: [
          "Princípio do menor privilégio",
          "Defesa em profundidade",
          "Separação de deveres",
          "Zero Trust",
        ],
        c: 0,
        e: "O princípio do menor privilégio (Least Privilege) estabelece que identidades devem receber apenas as permissões estritamente necessárias para suas tarefas, reduzindo a superfície de ataque caso a credencial seja comprometida.",
        x: "Em vez de dar AdministratorAccess a um desenvolvedor, conceda apenas s3:GetObject e s3:PutObject no bucket específico do projeto dele.",
      },
      {
        q: "O que é MFA (Multi-Factor Authentication) e por que é recomendado para contas em nuvem?",
        o: [
          "Autenticação com dois ou mais fatores (algo que sabe + algo que tem), dificultando acesso não autorizado",
          "Usar senha mais longa",
          "Criptografia de dados",
          "Firewall em múltiplas camadas",
        ],
        c: 0,
        e: "MFA exige pelo menos dois fatores de autenticação: fator de conhecimento (senha), fator de posse (token, celular), fator biométrico (digital, face). Mesmo que a senha seja comprometida, o atacante precisa do segundo fator. Essencial para contas root e IAM com privilégios elevados.",
        x: "AWS root account com MFA: ao fazer login, além da senha, insira o código de 6 dígitos do Google Authenticator ou toque na YubiKey (hardware token). Sem o dispositivo físico, login é impossível.",
      },
      {
        q: "O que é um WAF (Web Application Firewall) e contra quais ataques ele protege?",
        o: [
          "Firewall de aplicação web que protege contra SQL injection, XSS, CSRF e outros ataques HTTP",
          "Firewall de rede que bloqueia IPs",
          "Antivírus para servidores",
          "Sistema de backup",
        ],
        c: 0,
        e: "WAF opera na camada 7 (aplicação) e inspeciona requisições HTTP/HTTPS. Regras protegem contra: SQL Injection, Cross-Site Scripting (XSS), path traversal, bots maliciosos e DDoS na camada de aplicação. Diferente de firewall de rede (camada 3/4) que filtra por IP/porta.",
        x: "AWS WAF no ALB: regra 1 bloqueia requests com padrão SQL Injection (ex: ' OR 1=1--). Regra 2 limita 100 req/s por IP (rate limiting). Regra 3 bloqueia user-agents de bots conhecidos. Managed Rules incluem OWASP Top 10.",
      },
      {
        q: "O que é Identity Federation (federação de identidade) na nuvem?",
        o: [
          "Permite que usuários usem credenciais de provedores externos (Google, AD) para acessar recursos cloud",
          "Criar usuários duplicados em cada provedor",
          "Compartilhar senhas entre clouds",
          "Tipo de criptografia federada",
        ],
        c: 0,
        e: "Identity Federation permite autenticar com provedores de identidade externos (corporate AD, Google, Facebook) via SAML, OIDC ou OAuth. O usuário faz login no IdP corporativo e recebe credenciais temporárias para acessar AWS/Azure/GCP sem criar conta separada.",
        x: "Funcionário faz login no Azure AD corporativo → IAM Identity Center federa para AWS → assume IAM Role com permissões. Zero passwords AWS. STS gera credenciais temporárias de 1h.",
      },
      {
        q: "O que é criptografia do lado do cliente vs do lado do servidor na nuvem?",
        o: [
          "Client-side: dados criptografados ANTES de enviar à nuvem; server-side: provedor criptografa ao receber",
          "São idênticas",
          "Client-side usa TLS e server-side usa AES",
          "Server-side é sempre preferível",
        ],
        c: 0,
        e: "Server-side encryption (SSE): o provedor criptografa ao armazenar e descriptografa ao ler (S3 SSE-S3, SSE-KMS). Client-side encryption (CSE): você criptografa antes de enviar — o provedor nunca vê dados em claro. CSE é mais seguro mas mais complexo.",
        x: "SSE-KMS: S3 criptografa com chave KMS ao gravar, descriptografa ao ler. CSE: app criptografa com chave local AES-256 ANTES de fazer PUT no S3. O S3 armazena blob criptografado — mesmo a AWS não pode ler.",
      },
      {
        q: "O que é um Security Group e o que é um NACL (Network ACL) na AWS?",
        o: [
          "Security Group é firewall stateful por instância; NACL é firewall stateless por sub-rede",
          "São idênticos",
          "NACL é stateful e SG é stateless",
          "SG opera na sub-rede e NACL na instância",
        ],
        c: 0,
        e: "Security Group: stateful (resposta automática), ligado à instância/recurso, só regras ALLOW. NACL: stateless (precisa regra explícita para request E response), ligado à sub-rede, regras ALLOW e DENY com prioridade numérica.",
        x: "SG: Allow Inbound TCP 443 → response na porta efêmera retorna automaticamente (stateful). NACL: precisa de regra Allow Inbound TCP 443 E Allow Outbound TCP 1024-65535 (stateless). Defesa em profundidade: NACL + SG.",
      },
      {
        q: "O que é o modelo Zero Trust e como difere da segurança baseada em perímetro?",
        o: [
          "Zero Trust não confia em nenhuma rede por padrão e verifica cada acesso; perímetro confia na rede interna",
          "São abordagens idênticas",
          "Perímetro é mais seguro",
          "Zero Trust só se aplica à nuvem",
        ],
        c: 0,
        e: "Perímetro: 'dentro da rede = confiável' (castelo com fosso). Zero Trust: 'nunca confie, sempre verifique' — cada acesso é autenticado/autorizado independente da rede. Princípios: verificação explícita, menor privilégio, assume breach.",
        x: "Perímetro: VPN conecta → acesso total à rede interna. Zero Trust: login com MFA + dispositivo compliance + localização verificada → acessa APENAS o recurso autorizado via conditional access. Lateral movement bloqueado.",
      },
    ],
    Médio: [
      {
        q: "O que é 'encryption at rest' e como ela se diferencia de 'encryption in transit'?",
        o: [
          "At rest protege dados armazenados em disco; in transit protege dados trafegando pela rede",
          "São sinônimos para criptografia AES",
          "At rest usa TLS e in transit usa AES",
          "At rest é para bancos de dados e in transit é para arquivos",
        ],
        c: 0,
        e: "Encryption at rest criptografa dados armazenados em disco (S3, EBS, RDS) usando chaves como AES-256, protegendo contra acesso físico não autorizado. Encryption in transit usa TLS/SSL para criptografar dados enquanto trafegam pela rede, protegendo contra interceptação.",
        x: "S3 com SSE-S3 = encryption at rest (AES-256 gerenciado pela AWS). HTTPS no ALB com certificado ACM = encryption in transit (TLS 1.3).",
      },
      {
        q: "O que é CSPM (Cloud Security Posture Management) e quais problemas ele detecta?",
        o: [
          "Ferramenta que monitora configurações de nuvem em busca de violações de segurança e compliance",
          "Antivírus para nuvem",
          "Ferramenta de pen test",
          "Backup criptografado",
        ],
        c: 0,
        e: "CSPM monitora continuamente configurações de recursos de nuvem contra best practices e frameworks de compliance (CIS, SOC 2, PCI DSS). Detecta: buckets S3 públicos, security groups abertos (0.0.0.0/0:22), discos sem criptografia, MFA desabilitado, credentials expostas.",
        x: "Azure Defender for Cloud (CSPM): alerta 'Storage Account sem HTTPS obrigatório', 'VM com porta SSH aberta para 0.0.0.0/0', 'SQL Server sem Transparent Data Encryption'. Score de segurança: 72/100.",
      },
      {
        q: "O que é o modelo de responsabilidade compartilhada na nuvem e como ele divide as responsabilidades entre provedor e cliente?",
        o: [
          "Provedor protege a infraestrutura DA nuvem; cliente protege o que coloca NA nuvem",
          "O provedor é responsável por tudo",
          "O cliente é responsável por tudo",
          "Não há divisão",
        ],
        c: 0,
        e: "O provedor protege a infraestrutura física, hypervisor, rede e serviços gerenciados (segurança DA nuvem). O cliente é responsável por: configuração de segurança, IAM, criptografia de dados, OS patching (em IaaS), security groups e compliance (segurança NA nuvem).",
        x: "IaaS (EC2): AWS protege hardware e hypervisor; você patcha o SO e configura firewall. PaaS (RDS): AWS também patcha o SO e banco; você configura security groups e criptografia. SaaS (S3): AWS gerencia quase tudo; você configura permissões de bucket.",
      },
      {
        q: "O que é o AWS KMS (Key Management Service) e qual a diferença entre chaves gerenciadas pelo cliente e pelo serviço?",
        o: [
          "Serviço para criar e gerenciar chaves criptográficas; CMK dá controle total das políticas de chave",
          "Serviço de armazenamento de senhas",
          "Firewall criptografado",
          "Proxy para SSL/TLS",
        ],
        c: 0,
        e: "KMS gerencia chaves de criptografia. AWS-managed keys: AWS cria/gerencia automaticamente (SSE-S3). Customer-managed keys (CMK): você controla políticas, rotação, quem pode usar. CMK do KMS: roteia automaticamente a cada 1 ano (configurável).",
        x: "CMK para S3: você define política 'apenas role X pode Decrypt'. Audit: CloudTrail registra todo uso da chave. Rotation: KMS rotaciona automaticamente. Custo: $1/mês por chave + $0.03/10k requests.",
      },
      {
        q: "O que são security groups e por que são considerados a primeira defesa na nuvem?",
        o: [
          "Firewalls virtuais que controlam tráfego de entrada e saída para recursos na nuvem",
          "Grupos de usuários com permissões",
          "Certificados de segurança",
          "Antivírus gerenciado",
        ],
        c: 0,
        e: "Security groups são firewalls stateful que filtram tráfego por protocolo, porta e IP de origem/destino. Liga-se à instância/recurso. Best practice: menor privilégio — só abrir portas necessárias. Nunca 0.0.0.0/0 para SSH/RDP.",
        x: "SG do web server: Inbound Allow TCP 443 de 0.0.0.0/0 (HTTPS), Inbound Allow TCP 80 de 0.0.0.0/0 (HTTP). SG do banco: Inbound Allow TCP 5432 APENAS do SG do web server. Banco nunca acessível da internet.",
      },
      {
        q: "O que é secrets management e quais ferramentas são utilizadas?",
        o: [
          "Prática de armazenar e rotacionar credenciais de forma segura usando serviços dedicados",
          "Guardar senhas em variáveis de ambiente",
          "Criptografar o código-fonte",
          "Compartilhar senhas via chat",
        ],
        c: 0,
        e: "Secrets (senhas, API keys, tokens) NUNCA devem estar em código ou env vars em plain text. Ferramentas: AWS Secrets Manager (rotação automática), Azure Key Vault, GCP Secret Manager, HashiCorp Vault (multi-cloud). Integram com IAM para controle de acesso.",
        x: "RUIM: DB_PASSWORD=mypass123 no .env commitado no Git. BOM: AWS Secrets Manager armazena a senha, Lambda lê via SDK: const secret = await secretsManager.getSecretValue({ SecretId: 'db/prod' }). Rotação a cada 30 dias automática.",
      },
      {
        q: "O que é o AWS IAM Identity Center (antigo SSO) e para que serve?",
        o: [
          "Serviço que centraliza acesso a múltiplas contas AWS e aplicações SaaS com login único",
          "Centro de gerenciamento de VPCs",
          "Serviço de DNS",
          "Portal de billing",
        ],
        c: 0,
        e: "IAM Identity Center permite SSO para múltiplas contas AWS (Organizations) e apps SaaS (Salesforce, Slack). Integra com Azure AD, Okta, Google Workspace como IdP. Permission Sets definem roles por conta. Um login → acesso a todas as contas autorizadas.",
        x: "Funcionário acessa portal SSO → vê: Conta Dev (PowerUser), Conta Staging (ReadOnly), Conta Prod (ViewOnly). Clica em 'Conta Dev' → assume role DevPowerUser com credenciais temporárias de 1h. Sem IAM users em cada conta.",
      },
    ],
    Difícil: [
      {
        q: "Em uma arquitetura Zero Trust na nuvem, qual componente é responsável por avaliar continuamente o contexto (identidade, dispositivo, localização, risco) antes de conceder acesso a cada recurso?",
        o: [
          "Policy Decision Point (PDP)",
          "Firewall de perímetro",
          "VPN concentrator",
          "Load Balancer",
        ],
        c: 0,
        e: "No modelo Zero Trust, o Policy Decision Point (PDP) avalia cada requisição de acesso com base em múltiplos sinais contextuais: identidade do usuário, postura do dispositivo, localização, horário e nível de risco. Não há confiança implícita baseada na rede. Cada acesso é verificado continuamente.",
        x: "Um PDP (ex.: Azure AD Conditional Access) nega acesso ao SharePoint porque: usuário autenticado via MFA ✓, mas dispositivo sem patch crítico ✗ e localização = país incomum ✗. Risco calculado = Alto → bloqueia.",
      },
      {
        q: "O que é SIEM (Security Information and Event Management) e como ele funciona na nuvem?",
        o: [
          "Sistema que coleta, correlaciona e analisa logs de segurança de múltiplas fontes para detectar ameaças",
          "Firewall de próxima geração",
          "Scanner de vulnerabilidades",
          "Ferramenta de criptografia",
        ],
        c: 0,
        e: "SIEM agrega logs de diversas fontes (firewalls, servidores, aplicações, cloud), correlaciona eventos usando regras e ML para detectar ameaças em tempo real, e gera alertas prioritizados. Na nuvem: Azure Sentinel, AWS Security Hub + GuardDuty, Google Chronicle.",
        x: "Azure Sentinel detecta: 'usuário logou dos EUA às 14h e da Rússia às 14h05 (impossible travel)' → alerta crítico + playbook automático desabilita a conta e notifica a equipe de segurança via Teams.",
      },
      {
        q: "O que é SOAR (Security Orchestration, Automation and Response) e como complementa o SIEM?",
        o: [
          "Plataforma que automatiza respostas a incidentes de segurança com playbooks, integrando-se ao SIEM",
          "Sinônimo de SIEM",
          "Scanner de vulnerabilidades automático",
          "Ferramenta de pen testing",
        ],
        c: 0,
        e: "SOAR recebe alertas do SIEM e executa playbooks automatizados de resposta: bloquear IP no firewall, desabilitar usuário comprometido, isolar instância infectada, criar ticket de incidente, notificar equipe. Reduz tempo de resposta (MTTR) de horas para segundos.",
        x: "Playbook SOAR: alerta 'brute force SSH detectado' → 1) bloquear IP no Security Group (automático) → 2) capturar logs da instância (automático) → 3) criar ticket no Jira (automático) → 4) notificar analista no Slack → 5) analista investiga e fecha. MTTR: 2 minutos.",
      },
      {
        q: "O que é o AWS GuardDuty e como ele detecta ameaças?",
        o: [
          "Serviço de detecção de ameaças que analisa logs (CloudTrail, VPC Flow, DNS) com ML",
          "Firewall gerenciado",
          "Antivírus para EC2",
          "Scanner de vulnerabilidades",
        ],
        c: 0,
        e: "GuardDuty analisa CloudTrail logs, VPC Flow Logs e DNS logs usando machine learning e threat intelligence para detectar atividades maliciosas: API calls suspeitas, comunicação com IPs de C2, port scanning, criptomineração. Ativação em 1 clique.",
        x: "GuardDuty findings: 'UnauthorizedAccess: EC2 instance i-abc comunicando com IP de botnet conhecida'. 'Recon: Port scan detectado de IP externo'. Integra com Security Hub para centralizar findings de múltiplos serviços.",
      },
      {
        q: "O que é o princípio de defense in depth (defesa em profundidade) na nuvem?",
        o: [
          "Aplicar múltiplas camadas de segurança para proteger contra falha de uma camada individual",
          "Usar apenas um firewall forte",
          "Criptografar tudo com a mesma chave",
          "Concentrar toda segurança no perímetro",
        ],
        c: 0,
        e: "Defense in depth: camadas independentes: WAF (L7) → NACL (L3/4 sub-rede) → Security Group (L3/4 instância) → IAM (autenticação/autorização) → Encryption (at rest/in transit) → Monitoring (GuardDuty/SIEM). Se uma camada falhar, as outras ainda protegem.",
        x: "Ataque SQL Injection: WAF bloqueia (camada 1). Se passar: app usa parameterized queries (camada 2). Se explorar: banco encriptado com CMK (camada 3). Se exfiltrar: GuardDuty detecta tráfego anômalo (camada 4).",
      },
      {
        q: "O que é o AWS Organizations com SCPs (Service Control Policies) e como implementam governança multi-conta?",
        o: [
          "SCPs definem o limite máximo de permissões para todas as contas na OU, mesmo para admins",
          "Políticas de custo",
          "Configurações de rede",
          "Templates de CloudFormation",
        ],
        c: 0,
        e: "SCPs são guardrails que limitam o QUE pode ser feito em contas AWS, independente das IAM policies. Exemplo: SCP deny all regions except sa-east-1 — mesmo um admin não consegue criar recursos em outras regiões. SCPs não concedem permissões, apenas restringem.",
        x: "OU 'Produção' com SCP: Deny ec2:TerminateInstances unless mfa-authenticated. Deny iam:CreateUser (usar SSO). Deny s3:PutBucketPublicAccess. Mesmo root da conta filha não pode violar essas restrições.",
      },
      {
        q: "O que é o conceito de 'supply chain security' em cloud e como mitigar riscos?",
        o: [
          "Segurança da cadeia de dependências de software: imagens base, bibliotecas, pipelines CI/CD e artefatos",
          "Segurança de entrega de hardware",
          "Proteção de APIs de fornecedores",
          "Backup de dependências",
        ],
        c: 0,
        e: "Supply chain attacks exploram dependências (npm packages, imagens Docker, GitHub Actions). Mitigações: SCA (scan de dependências: Snyk, Dependabot), imagens base verificadas, SBOM (Software Bill of Materials), signed images (cosign/Sigstore), pins de versão exatas.",
        x: "Ataque: pacote npm 'colors' v1.4.1 introduziu loop infinito (sabotagem). Mitigações: lockfile (package-lock.json), npm audit em CI, Snyk monitora CVEs, Dependabot cria PRs de update. SBOM documenta todas as dependências.",
      },
    ],
  },
};
